<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>physics on Gaffer On Games</title>
    <link>https://gafferongames.com/tags/physics/</link>
    <description>Recent content in physics on Gaffer On Games</description>
    <generator>Source Themes academia (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <copyright>Copyright Â© Glenn Fiedler, 2004 - 2020</copyright>
    <lastBuildDate>Thu, 22 Feb 2018 00:00:00 +0000</lastBuildDate>
    
	    <atom:link href="https://gafferongames.com/tags/physics/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Networked Physics in Virtual Reality</title>
      <link>https://gafferongames.com/post/networked_physics_in_virtual_reality/</link>
      <pubDate>Thu, 22 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://gafferongames.com/post/networked_physics_in_virtual_reality/</guid>
      <description>&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;About a year ago, Oculus approached me and offered to sponsor my research. They asked me, effectively: &amp;ldquo;Hey Glenn, there&amp;rsquo;s a lot of interest in networked physics in VR. You did a cool talk at GDC. Do you think could come up with a networked physics sample in VR that we could share with devs? Maybe you could use the touch controllers?&amp;rdquo;&lt;/p&gt;
&lt;p&gt;I replied &lt;del&gt;&amp;ldquo;F*** yes!&amp;quot;&lt;/del&gt; &lt;strong&gt;cough&lt;/strong&gt; &amp;ldquo;Sure. This could be a lot of fun!&amp;rdquo;. But to keep it real, I insisted on two conditions. One: the source code I developed would be published under a permissive open source licence (for example, BSD) so it would create the most good. Two: when I was finished, I would be able to write an article describing the steps I took to develop the sample.&lt;/p&gt;
&lt;p&gt;Oculus agreed. Welcome to that article! Also, the source for the networked physics sample is &lt;a href=&#34;https://github.com/OculusVR/oculus-networked-physics-sample&#34;&gt;here&lt;/a&gt;, wherein the code that I wrote is released under a BSD licence. I hope the next generation of programmers can learn from my research into networked physics and create some really cool things. Good luck!&lt;/p&gt;
&lt;h1 id=&#34;what-are-we-building&#34;&gt;What are we building?&lt;/h1&gt;
&lt;p&gt;When I first started discussions with Oculus, we imagined creating something like a table where four players could sit around and interact with physically simulated cubes on the table. For example, throwing, catching and stacking cubes, maybe knocking each other&amp;rsquo;s stacks over with a swipe of their hand.&lt;/p&gt;
&lt;p&gt;But after a few days spent learning Unity and C#, I found myself actually &lt;em&gt;inside&lt;/em&gt; the Rift. In VR, scale is &lt;em&gt;so important&lt;/em&gt;. When the cubes were small, everything felt much less interesting, but when the cubes were scaled up to around a meter cubed, everything had this really cool sense of scale. You could make these &lt;em&gt;huge&lt;/em&gt; stacks of cubes, up to 20 or 30 meters high. This felt really cool!&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s impossible to communicate visually what this feels like outside of VR, but it looks something like this&amp;hellip;&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/networked-physics-in-vr/stack-of-cubes.jpg&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;&amp;hellip; where you can select, grab and throw cubes using the touch controller, and any cubes you release from your hand interact with the other cubes in the simulation. You can throw a cube at a stack of cubes and knock them over. You can pick up a cube in each hand and juggle them. You can build a stack of cubes and see how high you can make it go.&lt;/p&gt;
&lt;p&gt;Even though this was a lot of fun, it&amp;rsquo;s not all rainbows and unicorns. Working with Oculus as a client, I had to define tasks and deliverables before I could actually start the work.&lt;/p&gt;
&lt;p&gt;I suggested the following criteria we would use to define success:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Players should be able to pick up, throw and catch cubes without latency.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Players should be able to stack cubes, and these stacks should be stable (come to rest) and be without visible jitter.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When cubes thrown by any player interact with the simulation, wherever possible, these interactions should be without latency.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;At the same time I created a set of tasks to work in order of greatest risk to least, since this was R&amp;amp;D, there was no guarantee we would actually succeed at what we were trying to do.&lt;/p&gt;
&lt;h1 id=&#34;network-models&#34;&gt;Network Models&lt;/h1&gt;
&lt;p&gt;First up, we had to pick a network model. A network model is basically a strategy, exactly &lt;em&gt;how&lt;/em&gt; we are going to hide latency and keep the simulation in sync.&lt;/p&gt;
&lt;p&gt;There are three main network models to choose from:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Deterministic lockstep&lt;/li&gt;
&lt;li&gt;Client/server with client-side prediction&lt;/li&gt;
&lt;li&gt;Distributed simulation with authority scheme&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I was instantly confident of the correct network model: a distributed simulation model where players take over authority of cubes they interact with. But let me share with you my reasoning behind this.&lt;/p&gt;
&lt;p&gt;First, I could trivially rule out a deterministic lockstep network model, since the physics engine inside Unity (PhysX) is not deterministic. Furthermore, even if PhysX was deterministic I could &lt;em&gt;still&lt;/em&gt; rule it out because of the requirement that player interactions with the simulation be without latency.&lt;/p&gt;
&lt;p&gt;The reason for this is that to hide latency with deterministic lockstep I needed to maintain two copies of the simulation and predict the authoritative simulation ahead with local inputs prior to render (GGPO style). At 90HZ simulation rate and with up to 250ms of latency to hide, this meant 25 physics simulation steps for each visual render frame. 25X cost is simply not realistic for a CPU intensive physics simulation.&lt;/p&gt;
&lt;p&gt;This leaves two options: a client/server network model with client-side prediction (perhaps with dedicated server) and a less secure distributed simulation network model.&lt;/p&gt;
&lt;p&gt;Since this was a non-competitive sample, there was little justification to incur the cost of running dedicated servers. Therefore, whether I implemented a client/server model with client-side prediction or distributed simulation model, the security would be effectively the same. The only difference would be if only one of the players in the game could theoretically cheat, or &lt;em&gt;all&lt;/em&gt; of them could.&lt;/p&gt;
&lt;p&gt;For this reason, a distributed simulation model made the most sense. It had effectively the same amount of security, and would not require any expensive rollback and resimulation, since players simply take authority over cubes they interact with and send the state for those cubes to other players.&lt;/p&gt;
&lt;h1 id=&#34;authority-scheme&#34;&gt;Authority Scheme&lt;/h1&gt;
&lt;p&gt;While it makes intuitive sense that taking authority (acting like the server) for objects you interact can hide latency &amp;ndash; since, well if you&amp;rsquo;re the server, you don&amp;rsquo;t experience any lag, right? &amp;ndash; what&amp;rsquo;s not immediately obvious is how to resolve conflicts.&lt;/p&gt;
&lt;p&gt;What if two players interact with the same stack? What if two players, masked by latency, grab the same cube? In the case of conflict: who wins, who gets corrected, and how is this decided?&lt;/p&gt;
&lt;p&gt;My intuition at this point was that because I would be exchanging state for objects rapidly (up to 60 times per-second), that it would be best to implement this as an encoding in the state exchanged between players over my network protocol, rather than as events.&lt;/p&gt;
&lt;p&gt;I thought about this for a while and came up with two key concepts:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Authority&lt;/li&gt;
&lt;li&gt;Ownership&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Each cube would have authority, either set to default (white), or to whatever color of the player that last interacted with it. If another player interacted with an object, authority would switch and update to that player. I planned to use authority for interactions of thrown objects with the scene. I imagined that a cube thrown by player 2 could take authority over any objects it interacted with, and in turn any objects those objects interacted with, recursively.&lt;/p&gt;
&lt;p&gt;Ownership was a bit different. Once a cube is owned by a player, no other player could take ownership until that player reliquished ownership. I planned to use ownership for players grabbing cubes, because I didn&amp;rsquo;t want to make it possible for players to grab cubes out of other player&amp;rsquo;s hands after they picked them up.&lt;/p&gt;
&lt;p&gt;I had an intuition that I could represent and communicate authority and ownership as state by including two different sequence numbers per-cube as I sent them: an authority sequence, and an ownership sequence number. This intuition ultimately proved correct, but turned out to be much more complicated in implementation than I expected. More on this later.&lt;/p&gt;
&lt;h1 id=&#34;state-synchronization&#34;&gt;State Synchronization&lt;/h1&gt;
&lt;p&gt;Trusting I could implement the authority rules described above, my first task was to prove that synchronizing physics in one direction of flow could actually work with Unity and PhysX. In previous work I had networked simulations built with ODE, so really, I had no idea if it was really possible.&lt;/p&gt;
&lt;p&gt;To find out, I setup a loopback scene in Unity where cubes fall into a pile in front of the player. There are two sets of cubes. The cubes on the left represent the authority side. The cubes on the right represent the non-authority side, which we want to be in sync with the cubes on the left.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/networked-physics-in-vr/authority-and-non-authority-cubes.png&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;At the start, without anything in place to keep the cubes in sync, even though both sets of cubes start from the same initial state, they give slightly different end results. You can see this most easily from top-down:&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/networked-physics-in-vr/out-of-sync.png&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;This happens because PhysX is non-deterministic. Rather than tilting at non-determinstic windmills, I &lt;em&gt;fight&lt;/em&gt; non-determinism by grabbing state from the left side (authority) and applying it to the right side (non-authority) 10 times per-second:&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/networked-physics-in-vr/left-to-right.png&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;The state I grab from each cube looks like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;struct CubeState
{
    Vector3 position;
    Quaternion rotation;
    Vector3 linear_velocity;
    Vector3 angular_velocity;
};
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And when I apply this state to the simulation on the right side, I simply &lt;em&gt;snap&lt;/em&gt; the position, rotation, linear and angular velocity of each cube to the state captured from the left side.&lt;/p&gt;
&lt;p&gt;This simple change is enough to keep the left and right simulations in sync. PhysX doesn&amp;rsquo;t even diverge enough in the 1/10th of a second between updates to show any noticeable pops.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/networked-physics-in-vr/in-sync.png&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;This &lt;strong&gt;proves&lt;/strong&gt; that a state synchronization based approach for networking can work with PhysX. &lt;em&gt;(Sigh of relief)&lt;/em&gt;. The only problem of course, is that sending uncompressed physics state uses way too much bandwidth&amp;hellip;&lt;/p&gt;
&lt;h1 id=&#34;bandwidth-optimization&#34;&gt;Bandwidth Optimization&lt;/h1&gt;
&lt;p&gt;To make sure the networked physics sample is playable over the internet, I needed to get bandwidth under control.&lt;/p&gt;
&lt;p&gt;The easiest gain I found was to simply encode the state for at rest cubes more efficiently. For example, instead of repeatedly sending (0,0,0) for linear velocity and (0,0,0) for angular velocity for at rest cubes, I send just one bit:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[position] (vector3)
[rotation] (quaternion)
[at rest] (bool)
&amp;lt;if not at rest&amp;gt;
{
    [linear_velocity] (vector3)
    [angular_velocity] (vector3)
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is &lt;em&gt;lossless&lt;/em&gt; technique because it doesn&amp;rsquo;t change the state sent over the network in any way. It&amp;rsquo;s also extremely effective, since statistically speaking, most of the time the majority of cubes are at rest.&lt;/p&gt;
&lt;p&gt;To optimize bandwidth further we need to use &lt;em&gt;lossy techniques&lt;/em&gt;. For example, we can reduce the precision of the physics state sent over the network by bounding position in some min/max range and quantizing it to a resolution of 1/1000th of a centimeter and sending that quantized position as an integer value in some known range. The same basic approach can be used for linear and angular velocity. For rotation I used the &lt;em&gt;smallest three representation&lt;/em&gt; of a quaternion.&lt;/p&gt;
&lt;p&gt;But while this saves bandwidth, it also adds risk. My concern was that if we are networking a stack of cubes (for example, 10 or 20 cubes placed on top of each other), maybe the quantization would create errors that add jitter to that stack. Perhaps it would even cause the stack to become &lt;em&gt;unstable&lt;/em&gt;, but in a particularly annoying and hard to debug way, where the stack looks fine for you, and is only unstable in the remote view (eg. the non-authority simulation), where another player is watching what you do.&lt;/p&gt;
&lt;p&gt;The best solution to this problem that I found was to quantize the state on &lt;em&gt;both sides&lt;/em&gt;. This means that before each physics simulation step, I capture and quantize the physics state &lt;em&gt;exactly the same way&lt;/em&gt; as when it&amp;rsquo;s sent over the network, then I apply this quantized state back to the local simulation.&lt;/p&gt;
&lt;p&gt;Now the extrapolation from quantized state on the non-authority side &lt;em&gt;exactly&lt;/em&gt; matches the authority simulation, minimizing jitter in large stacks. At least, in theory.&lt;/p&gt;
&lt;h1 id=&#34;coming-to-america-rest&#34;&gt;Coming To &lt;del&gt;America&lt;/del&gt; Rest&lt;/h1&gt;
&lt;p&gt;But quantizing the physics state created some &lt;em&gt;very interesting&lt;/em&gt; side-effects!&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;PhysX doesn&amp;rsquo;t really like you forcing the state of each rigid body at the start of every frame and makes sure you know by taking up a bunch of CPU.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Quantization adds error to position which PhysX tries very hard to correct, snapping cubes immediately out of penetration with huge pops!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Rotations can&amp;rsquo;t be represented exactly either, again causing penetration. Interestingly in this case, cubes can get stuck in a feedback loop where they slide across the floor!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Although cubes in large stacks &lt;em&gt;seem&lt;/em&gt; to be at rest, close inspection in the editor reveals that they are actually jittering by tiny amounts, as cubes are quantized just above surface and falling towards it.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;There&amp;rsquo;s not much I could do about the PhysX CPU usage, but the solution I found for the depenetration was to set &lt;em&gt;maxDepenetrationVelocity&lt;/em&gt; on each rigid body, limiting the velocity that cubes are pushed apart with. I found that one meter per-second works very well.&lt;/p&gt;
&lt;p&gt;Getting cubes to come to rest reliably was much harder. The solution I found was to disable the PhysX at rest calculation entirely and replace it with a ring-buffer of positions and rotations per-cube. If a cube has not moved or rotated significantly in the last 16 frames, I force it to rest. Boom. Perfectly stable stacks &lt;em&gt;with&lt;/em&gt; quantization.&lt;/p&gt;
&lt;p&gt;Now this might seem like a hack, but short of actually getting in the PhysX source code and rewriting the PhysX solver and at rest calculations, which I&amp;rsquo;m certainly not qualified to do, I didn&amp;rsquo;t see any other option. I&amp;rsquo;m happy to be proven wrong though, so if you find a better way to do this, please let me know :)&lt;/p&gt;
&lt;h1 id=&#34;priority-accumulator&#34;&gt;Priority Accumulator&lt;/h1&gt;
&lt;p&gt;The next big bandwidth optimization I did was to send only a subset of cubes in each packet. This gave me fine control over the amount of bandwidth sent, by setting a maximum packet size and sending only the set of updates that fit in each packet.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s how it works in practice:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Each cube has a &lt;em&gt;priority factor&lt;/em&gt; which is calculated each frame. Higher values are more likely to be sent. Negative values mean &lt;em&gt;&amp;ldquo;don&amp;rsquo;t send this cube&amp;rdquo;&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;If the priority factor is positive, it&amp;rsquo;s added to the &lt;em&gt;priority accumulator&lt;/em&gt; value for that cube. This value persists between simulation updates such that the priority accumulator increases each frame, so cubes with higher priority rise faster than cubes with low priority.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Negative priority factors clear the priority accumulator to -1.0.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;When a packet is sent, cubes are sorted in order of highest priority accumulator to lowest. The first n cubes become the set of cubes to potentially include in the packet. Objects with negative priority accumulator values are excluded.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The packet is written and cubes are serialized to the packet in order of importance. Not all state updates will necessarily fit in the packet, since cube updates have a variable encoding depending on their current state (at rest vs. not at rest and so on). Therefore, packet serialization returns a flag per-cube indicating whether it was included in the packet.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Priority accumulator values for cubes sent in the packet are cleared to 0.0, giving other cubes a fair chance to be included in the next packet.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For this demo I found some value in boosting priority for cubes recently involved in high energy collisions, since high energy collision was the largest source of divergence due to non-deterministic results. I also boosted priority for cubes recently thrown by players.&lt;/p&gt;
&lt;p&gt;Somewhat counter-intuitively, reducing priority for at rest cubes gave bad results. My theory is that since the simulation runs on both sides, at rest cubes would get slightly out of sync and not be corrected quickly enough, causing divergence when other cubes collided with them.&lt;/p&gt;
&lt;h1 id=&#34;delta-compression&#34;&gt;Delta Compression&lt;/h1&gt;
&lt;p&gt;Even with all the techniques so far, it still wasn&amp;rsquo;t optimized enough. With four players I really wanted to get the cost per-player down under 256kbps, so the entire simulation could fit into 1mbps for the host.&lt;/p&gt;
&lt;p&gt;I had one last trick remaining: &lt;strong&gt;delta compression&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;First person shooters often implement delta compression by compressing the entire state of the world relative to a previous state. In this technique, a previous complete world state or &amp;lsquo;snapshot&amp;rsquo; acts as the &lt;em&gt;baseline&lt;/em&gt;, and a set of differences, or &lt;em&gt;delta&lt;/em&gt;, between the &lt;em&gt;baseline&lt;/em&gt; and the &lt;em&gt;current&lt;/em&gt; snapshot is generated and sent down to the client.&lt;/p&gt;
&lt;p&gt;This technique is (relatively) easy to implement because the state for all objects are included in each snapshot, thus all the server needs to do is track the most recent snapshot received by each client, and generate deltas from that snapshot to the current.&lt;/p&gt;
&lt;p&gt;However, when a priority accumulator is used, packets don&amp;rsquo;t contain updates for all objects and delta encoding becomes more complicated. Now the server (or authority-side) can&amp;rsquo;t simply encode cubes relative to a previous snapshot number. Instead, the baseline must be specified &lt;em&gt;per-cube&lt;/em&gt;, so the receiver knows which state each cube is encoded relative to.&lt;/p&gt;
&lt;p&gt;The supporting systems and data structures are also much more complicated:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;A reliability system is required that can report back to the sender which packets were received, not just the most recently received snapshot #.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The sender needs to track the states included in each packet sent, so it can map packet level acks to sent states and update the most recently acked state per-cube. The next time a cube is sent, its delta is encoded relative to this state as a baseline.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The receiver needs to store a ring-buffer of received states per-cube, so it can reconstruct the current cube state from a delta by looking up the baseline in this ring-buffer.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;But ultimately, it&amp;rsquo;s worth the extra complexity, because this system combines the flexibility of being able to dynamically adjust bandwidth usage, with the orders of magnitude bandwidth improvement you get from delta encoding.&lt;/p&gt;
&lt;h1 id=&#34;delta-encoding&#34;&gt;Delta Encoding&lt;/h1&gt;
&lt;p&gt;Now that I have the supporting structures in place, I actually have to encode the difference of a cube relative to a previous baseline state. How is this done?&lt;/p&gt;
&lt;p&gt;The simplest way is to encode cubes that haven&amp;rsquo;t changed from the baseline value as just one bit: &lt;em&gt;not changed&lt;/em&gt;. This is also the easiest gain you&amp;rsquo;ll ever see, because at any time most cubes are at rest, and therefore aren&amp;rsquo;t changing state.&lt;/p&gt;
&lt;p&gt;A more advanced strategy is to encode the &lt;em&gt;difference&lt;/em&gt; between the current and baseline values, aiming to encode small differences with fewer bits. For example, delta position could be (-1,+2,+5) from baseline. I found this works well for linear values, but breaks down for deltas of the smallest three quaternion representation, as the largest component of a quaternion is often different between the baseline and current rotation.&lt;/p&gt;
&lt;p&gt;Furthermore, while encoding the difference gives some gains, it didn&amp;rsquo;t provide the order of magnitude improvement I was hoping for. In a desperate, last hope, I came up with a delta encoding strategy that included &lt;em&gt;prediction&lt;/em&gt;. In this approach, I predict the current state from the baseline assuming the cube is moving ballistically under acceleration due to gravity.&lt;/p&gt;
&lt;p&gt;Prediction was complicated by the fact that the predictor must be written in fixed point, because floating point calculations are not necessarily guaranteed to be deterministic. But after a few days of tweaking and experimentation, I was able to write a ballistic predictor for position, linear and angular velocity that matched the PhysX integrator within quantize resolution about 90% of the time.&lt;/p&gt;
&lt;p&gt;These lucky cubes get encoded with another bit: &lt;em&gt;perfect prediction&lt;/em&gt;, leading to another order of magnitude improvement. For cases where the prediction doesn&amp;rsquo;t match exactly, I encoded small error offset relative to the prediction.&lt;/p&gt;
&lt;p&gt;In the time I had to spend, I not able to get a good predictor for rotation. I blame this on the smallest three representation, which is highly numerically unstable, especially in fixed point. In the future, I would not use the smallest three representation for quantized rotations.&lt;/p&gt;
&lt;p&gt;It was also painfully obvious while encoding differences and error offsets that using a bitpacker was not the best way to read and write these quantities. I&amp;rsquo;m certain that something like a range coder or arithmetic compressor that can represent fractional bits, and dynamically adjust its model to the differences would give much better results, but I was already within my bandwidth budget at this point and couldn&amp;rsquo;t justify any further noodling :)&lt;/p&gt;
&lt;h1 id=&#34;synchronizing-avatars&#34;&gt;Synchronizing Avatars&lt;/h1&gt;
&lt;p&gt;After several months of work, I had made the following progress:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Proof that state synchronization works with Unity and PhysX&lt;/li&gt;
&lt;li&gt;Stable stacks in the remote view while quantizing state on both sides&lt;/li&gt;
&lt;li&gt;Bandwidth reduced to the point where all four players can fit in 1mbps&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The next thing I needed to implement was interaction with the simulation via the touch controllers. This part was a lot of fun, and was my favorite part of the project :)&lt;/p&gt;
&lt;p&gt;I hope you enjoy these interactions. There was a lot of experimentation and tuning to make simple things like picking up, throwing, passing from hand to hand feel good, even crazy adjustments to ensure throwing worked great, while placing objects on top of high stacks could still be done with high accuracy.&lt;/p&gt;
&lt;p&gt;But when it comes to networking, in this case the game code doesn&amp;rsquo;t count. All the networking cares about is that avatars are represented by a head and two hands driven by the tracked headset and touch controller positions and orientations.&lt;/p&gt;
&lt;p&gt;To synchronize this I captured the position and orientation of the avatar components in &lt;em&gt;FixedUpdate&lt;/em&gt; along the rest of the physics state, and applied this state to the avatar components in the remote view.&lt;/p&gt;
&lt;p&gt;But when I first tried this it looked &lt;em&gt;absolutely awful&lt;/em&gt;. Why?&lt;/p&gt;
&lt;p&gt;After a bunch of debugging I worked out that the avatar state was sampled from the touch hardware at render framerate in &lt;em&gt;Update&lt;/em&gt;, and was applied on the other machine at &lt;em&gt;FixedUpdate&lt;/em&gt;, causing jitter because the avatar sample time didn&amp;rsquo;t line up with the current time in the remote view.&lt;/p&gt;
&lt;p&gt;To fix this I stored the difference between physics and render time when sampling avatar state, and included this in the avatar state in each packet. Then I added a jitter buffer with 100ms delay to received packets, solving network jitter from time variance in packet delivery and enabling interpolation between avatar states to reconstruct a sample at the correct time.&lt;/p&gt;
&lt;p&gt;To synchronize cubes held by avatars, while a cube is parented to an avatar&amp;rsquo;s hand, I set the cube&amp;rsquo;s &lt;em&gt;priority factor&lt;/em&gt; to -1, stopping it from being sent with regular physics state updates. While a cube is attached to a hand, I include its id and relative position and rotation as part of the avatar state. In the remote view, cubes are attached to the avatar hand when the first avatar state arrives with that cube parented to it, and detached when regular physics state updates resume, corresponding to the cube being thrown or released.&lt;/p&gt;
&lt;h1 id=&#34;bidirectional-flow&#34;&gt;Bidirectional Flow&lt;/h1&gt;
&lt;p&gt;Now that I had player interaction with the scene working with the touch controllers, it was time to start thinking about how the second player can interact with the scene as well.&lt;/p&gt;
&lt;p&gt;To do this without going insane switching between two headsets all the time (!!!), I extended my Unity test scene to be able to switch between the context of player one (left) and player two (right).&lt;/p&gt;
&lt;p&gt;I called the first player the &amp;ldquo;host&amp;rdquo; and the second player the &amp;ldquo;guest&amp;rdquo;. In this model, the host is the &amp;ldquo;real&amp;rdquo; simulation, and by default synchronizes all cubes to the guest player, but as the guest interacts with the world, it takes authority over these objects and sends state for them back to the host player.&lt;/p&gt;
&lt;p&gt;To make this work without inducing obvious conflicts the host and guest both check the local state of cubes before taking authority and ownership. For example, the host won&amp;rsquo;t take ownership over a cube already under ownership of the guest, and vice versa, while authority is allowed to be taken, to let players throw cubes at somebody else&amp;rsquo;s stack and knock it over while it&amp;rsquo;s being built.&lt;/p&gt;
&lt;p&gt;Generalizing further to four players, in the networked physics sample, all packets flow through the host player, making the host the &lt;em&gt;arbiter&lt;/em&gt;. In effect, rather than being truly peer-to-peer, a topology is chosen that all guests in the game communicate only with the host player. This lets the host decide which updates to accept, and which updates to ignore and subsequently correct.&lt;/p&gt;
&lt;p&gt;To apply these corrections I needed some way for the host to override guests and say, no, you don&amp;rsquo;t have authority/ownership over this cube, and you should accept this update. I also needed some way for the host to determine &lt;em&gt;ordering&lt;/em&gt; for guest interactions with the world, so if one client experiences a burst of lag and delivers a bunch of packets late, these packets won&amp;rsquo;t take precedence over more recent actions from other guests.&lt;/p&gt;
&lt;p&gt;As per my hunch earlier, this was achieved with two sequence numbers per-cube:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Authority sequence&lt;/li&gt;
&lt;li&gt;Ownership sequence&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These sequence numbers are sent along with each state update and included in avatar state when cubes are held by players. They are used by the host to determine if it should accept an update from guests, and by guests to determine if the state update from the server is more recent and should be accepted, even when that guest thinks it has authority or ownership over a cube.&lt;/p&gt;
&lt;p&gt;Authority sequence increments each time a player takes authority over a cube and when a cube under authority of a player comes to rest. When a cube has authority on a guest machine, it holds authority on that machine until it receives &lt;em&gt;confirmation&lt;/em&gt; from the host before returning to default authority. This ensures that the final at rest state for cubes under guest authority are committed back to the host, even under significant packet loss.&lt;/p&gt;
&lt;p&gt;Ownership sequence increments each time a player grabs a cube. Ownership is stronger than authority, such that an increase in ownership sequence wins over an increase in authority sequence number. For example, if a player interacts with a cube just before another player grabs it, the player who grabbed it wins.&lt;/p&gt;
&lt;p&gt;In my experience working on this demo I found these rules to be sufficient to resolve conflicts, while letting host and guest players interact with the world lag free. Conflicts requiring corrections are rare in practice even under significant latency, and when they do occur, the simulation quickly converges to a consistent state.&lt;/p&gt;
&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;High quality networked physics with stable stacks of cubes &lt;em&gt;is&lt;/em&gt; possible with Unity and PhysX using a distributed simulation network model.&lt;/p&gt;
&lt;p&gt;This approach is best used for &lt;em&gt;cooperative experiences only&lt;/em&gt;, as it does not provide the security of a server-authoritative network model with dedicated servers and client-side prediction.&lt;/p&gt;
&lt;p&gt;Thanks to Oculus for sponsoring my work and making this research possible!&lt;/p&gt;
&lt;p&gt;The source code for the networked physics sample can be downloaded &lt;a href=&#34;https://github.com/OculusVR/oculus-networked-physics-sample&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Glenn Fiedler&lt;/strong&gt; is the founder and CEO of &lt;strong&gt;&lt;a href=&#34;https://networknext.com&#34;&gt;Network Next&lt;/a&gt;&lt;/strong&gt;.&lt;br&gt;&lt;i&gt;Network Next is fixing the internet for games by creating a marketplace for premium network transit.&lt;/i&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>State Synchronization</title>
      <link>https://gafferongames.com/post/state_synchronization/</link>
      <pubDate>Mon, 05 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>https://gafferongames.com/post/state_synchronization/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Hi, I&amp;rsquo;m &lt;a href=&#34;https://gafferongames.com&#34;&gt;Glenn Fiedler&lt;/a&gt; and welcome to &lt;strong&gt;&lt;a href=&#34;https://gafferongames.com/categories/networked-physics/&#34;&gt;Networked Physics&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In the &lt;a href=&#34;https://gafferongames.com/post/snapshot_compression/&#34;&gt;previous article&lt;/a&gt; we discussed techniques for compressing snapshots.&lt;/p&gt;
&lt;p&gt;In this article we round out our discussion of networked physics strategies with &lt;strong&gt;state synchronization&lt;/strong&gt;, the third and final strategy in this article series.&lt;/p&gt;
&lt;h2 id=&#34;state-synchronization&#34;&gt;State Synchronization&lt;/h2&gt;
&lt;p&gt;What is state synchronization? The basic idea is that, somewhat like deterministic lockstep, we run the simulation on both sides but, &lt;em&gt;unlike&lt;/em&gt; deterministic lockstep, we don&amp;rsquo;t just send input, we send both input &lt;u&gt;and&lt;/u&gt; state.&lt;/p&gt;
&lt;p&gt;This gives state synchronization interesting properties. Because we send state, we don&amp;rsquo;t need perfect determinism to stay in sync, and because the simulation runs on both sides, objects continue moving forward between updates.&lt;/p&gt;
&lt;p&gt;This lets us approach state synchronization differently to snapshot interpolation. Instead of sending state updates for every object in each packet, we can now send updates for only a few, and if we&amp;rsquo;re smart about how we select the objects for each packet, we can save bandwidth by concentrating updates on the most important objects.&lt;/p&gt;
&lt;p&gt;So what&amp;rsquo;s the catch? State synchronization is an approximate and lossy synchronization strategy. In practice, this means you&amp;rsquo;ll spend a lot of time tracking down sources of extrapolation divergence and pops. But other than that, it&amp;rsquo;s a quick and easy strategy to get started with.&lt;/p&gt;
&lt;h2 id=&#34;implementation&#34;&gt;Implementation&lt;/h2&gt;
&lt;p&gt;Here&amp;rsquo;s the state sent over the network per-object:&lt;/p&gt;
&lt;pre&gt;struct StateUpdate
{
    int index;
    vec3f position;
    quat4f orientation;
    vec3f linear_velocity;
    vec3f angular_velocity;
};
&lt;/pre&gt;
&lt;p&gt;Unlike snapshot interpolation, we&amp;rsquo;re not just sending visual quantities like position and orientation, we&amp;rsquo;re also sending &lt;em&gt;non-visual&lt;/em&gt; state such as linear and angular velocity. Why is this?&lt;/p&gt;
&lt;p&gt;The reason is that state synchronization runs the simulation on both sides, so it&amp;rsquo;s &lt;em&gt;always extrapolating&lt;/em&gt; from the last state update applied to each object. If linear and angular velocity aren&amp;rsquo;t synchronized, this extrapolation is done with incorrect velocities, leading to pops when objects are updated.&lt;/p&gt;
&lt;p&gt;While we must send the velocities, there&amp;rsquo;s no point wasting bandwidth sending (0,0,0) over and over while an object is at rest. We can fix this with a trivial optimization, like so:&lt;/p&gt;
&lt;pre&gt;void serialize_state_update( Stream &amp;amp; stream, 
                             int &amp;amp; index, 
                             StateUpdate &amp;amp; state_update )
{
    serialize_int( stream, index, 0, NumCubes - 1 );
    serialize_vector( stream, state_update.position );
    serialize_quaternion( stream, state_update.orientation );
    bool at_rest = stream.IsWriting() ? state_update.AtRest() : false;    
    serialize_bool( stream, at_rest );
    if ( !at_rest )
    {
        serialize_vector( stream, state_update.linear_velocity );
        serialize_vector( stream, state_update.angular_velocity );
    }
    else if ( stream.IsReading() )
    {
        state_update.linear_velocity = vec3f(0,0,0);
        state_update.angular_velocity = vec3f(0,0,0);
    }
}
&lt;/pre&gt;
&lt;p&gt;What you see above is a &lt;em&gt;serialize function&lt;/em&gt;. It&amp;rsquo;s a trick I like to use to unify packet read and write. I like it because it&amp;rsquo;s expressive while at the same time it&amp;rsquo;s difficult to desync read and write. You can read more about them &lt;a href=&#34;https://gafferongames.com/post/serialization_strategies/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;packet-structure&#34;&gt;Packet Structure&lt;/h2&gt;
&lt;p&gt;Now let&amp;rsquo;s look at the overall structure of packets being sent:&lt;/p&gt;
&lt;pre&gt;const int MaxInputsPerPacket = 32;
const int MaxStateUpdatesPerPacket = 64;

struct Packet
{
    uint32_t sequence;
    Input inputs[MaxInputsPerPacket];
    int num_object_updates;
    StateUpdate state_updates[MaxStateUpdatesPerPacket];
};
&lt;/pre&gt;
&lt;p&gt;First we include a sequence number in each packet so we can determine out of order, lost or duplicate packets. I recommend you run the simulation at the same framerate on both sides (for example 60HZ) and in this case the sequence number can work double duty as the frame number.&lt;/p&gt;
&lt;p&gt;Input is included in each packet because it&amp;rsquo;s needed for extrapolation. Like deterministic lockstep we send multiple redundant inputs so in the case of packet loss it&amp;rsquo;s very unlikely that an input gets dropped. Unlike deterministic lockstep, if don&amp;rsquo;t have the next input we don&amp;rsquo;t stop the simulation and wait for it, we continue extrapolating forward with the last input received.&lt;/p&gt;
&lt;p&gt;Next you can see that we only send a maximum of 64 state updates per-packet. Since we have a total of 901 cubes in the simulation so we need some way to select the n most important state updates to include in each packet. We need some sort of prioritization scheme.&lt;/p&gt;
&lt;p&gt;To get started each frame walk over all objects in your simulation and calculate their current priority. For example, in the cube simulation I calculate priority for the player cube as 1000000 because I always want it to be included in every packet, and for interacting (red cubes) I give them a higher priority of 100 while at rest objects have priority of 1.&lt;/p&gt;
&lt;p&gt;Unfortunately if you just picked objects according to their current priority each frame you&amp;rsquo;d only ever send red objects while in a katamari ball and white objects on the ground would never get updated. We need to take a slightly different approach, one that prioritizes sending important objects while also &lt;em&gt;distributing&lt;/em&gt; updates across all objects in the simulation.&lt;/p&gt;
&lt;h2 id=&#34;priority-accumulator&#34;&gt;Priority Accumulator&lt;/h2&gt;
&lt;p&gt;You can do this with a priority accumulator. This is an array of float values, one value per-object, that is remembered from frame to frame. Instead of taking the immediate priority value for the object and sorting on that, each frame we add the current priority for each object to its priority accumulator value then sort objects in order from largest to smallest priority accumulator value. The first n objects in this sorted list are the objects you should send that frame.&lt;/p&gt;
&lt;p&gt;You could just send state updates for all n objects but typically you have some maximum bandwidth you want to support like 256kbit/sec. Respecting this bandwidth limit is easy. Just calculate how large your packet header is and how many bytes of preamble in the packet (sequence, # of objects in packet and so on) and work out conservatively the number of bytes remaining in your packet while staying under your bandwidth target.&lt;/p&gt;
&lt;p&gt;Then take the n most important objects according to their priority accumulator values and as you construct the packet, walk these objects in order and measure if their state updates will fit in the packet. If you encounter a state update that doesn&amp;rsquo;t fit, skip over it and try the next one. After you serialize the packet, reset the priority accumulator to zero for objects that fit but leave the priority accumulator value alone for objects that didn&amp;rsquo;t. This way objects that don&amp;rsquo;t fit are first in line to be included in the next packet.&lt;/p&gt;
&lt;p&gt;The desired bandwidth can even be adjusted on the fly. This makes it really easy to adapt state synchronization to changing network conditions, for example if you detect the connection is having difficulty you can reduce the amount of bandwidth sent (congestion avoidance) and the quality of state synchronization scales back automatically. If the network connection seems like it should be able to handle more bandwidth later on then you can raise the bandwidth limit.&lt;/p&gt;
&lt;h2 id=&#34;jitter-buffer&#34;&gt;Jitter Buffer&lt;/h2&gt;
&lt;p&gt;The priority accumulator covers the sending side, but on the receiver side there is much you need to do when applying these state updates to ensure that you don&amp;rsquo;t see divergence and pops in the extrapolation between object updates.&lt;/p&gt;
&lt;p&gt;The very first thing you need to consider is that network jitter exists. You don&amp;rsquo;t have any guarantee that packets you sent nicely spaced out 60 times per-second arrive that way on the other side. What happens in the real world is you&amp;rsquo;ll typically receive two packets one frame, 0 packets the next, 1, 2, 0 and so on because packets tend to clump up across frames. To handle this situation you need to implement a jitter buffer for your state update packets. If you fail to do this you&amp;rsquo;ll have a poor quality extrapolation and pops in stacks of objects because objects in different state update packets are slightly out of phase with each other with respect to time.&lt;/p&gt;
&lt;p&gt;All you do in a jitter buffer is hold packets before delivering them to the application at the correct time as indicated by the sequence number (frame number) in the packet. The delay you need to hold packets for in this buffer is a much smaller amount of time relative to interpolation delay for snapshot interpolation but it&amp;rsquo;s the same basic idea. You just need to delay packets just enough (say 4-5 frames @ 60HZ) so that they come out of the buffer properly spaced apart.&lt;/p&gt;
&lt;h2 id=&#34;applying-state-updates&#34;&gt;Applying State Updates&lt;/h2&gt;
&lt;p&gt;Once the packet comes out of the jitter how do you apply state updates? My recommendation is that you should snap the physics state hard. This means you apply the values in the state update directly to the simulation.&lt;/p&gt;
&lt;p&gt;I recommend against trying to apply some smoothing between the state update and the current state at the simulation level. This may sound counterintuitive but the reason for this is that the simulation extrapolates from the state update so you want to make sure it extrapolates from a valid physics state for that object rather than some smoothed, total bullshit made-up one. This is especially important when you are networking large stacks of objects.&lt;/p&gt;
&lt;p&gt;Surprisingly, without any smoothing the result is already pretty good:&lt;/p&gt;
&lt;video preload=&#34;auto&#34; controls=&#34;controls&#34; width=&#34;100%&#34;&gt;
&lt;source src=&#34;http://gafferongames.com/videos/state_synchronization_uncompressed.mp4&#34; type=&#34;video/mp4&#34; /&gt;
&lt;source src=&#34;http://gafferongames.com/videos/state_synchronization_uncompressed.webm&#34; type=&#34;video/webm&#34; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;p&gt;As you can see it&amp;rsquo;s already looking quite good and barely any bandwidth optimization has been performed. Contrast this with the first video for snapshot interpolation which was at 18mbit/sec and you can see that using the simulation to extrapolate between state updates is a great way to use less bandwidth.&lt;/p&gt;
&lt;p&gt;Of course we can do a lot better than this and each optimization we do lets us squeeze more state updates in the same amount of bandwidth. The next obvious thing we can do is to apply all the standard quantization compression techniques such as bounding and quantizing position, linear and angular velocity value and using the smallest three compression as described in &lt;a href=&#34;https://gafferongames.com/post/snapshot_compression/&#34;&gt;snapshot compression&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;But here it gets a bit more complex. We are extrapolating from those state updates so if we quantize these values over the network then the state that arrives on the right side is slightly different from the left side, leading to a slightly different extrapolation and a pop when the next state update arrives for that object.&lt;/p&gt;
&lt;video preload=&#34;auto&#34; controls=&#34;controls&#34; width=&#34;100%&#34;&gt;
&lt;source src=&#34;http://gafferongames.com/videos/state_synchronization_compressed.mp4&#34; type=&#34;video/mp4&#34; /&gt;
&lt;source src=&#34;http://gafferongames.com/videos/state_synchronization_compressed.webm&#34; type=&#34;video/webm&#34; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;h2 id=&#34;quantize-both-sides&#34;&gt;Quantize Both Sides&lt;/h2&gt;
&lt;p&gt;The solution is to quantize the state on both sides. This means that on both sides before each simulation step you quantize the entire simulation state as if it had been transmitted over the network. Once this is done the left and right side are both extrapolating from quantized state and their extrapolations are very similar.&lt;/p&gt;
&lt;p&gt;Because these quantized values are being fed back into the simulation, you&amp;rsquo;ll find that much more precision is required than snapshot interpolation where they were just visual quantities used for interpolation. In the cube simulation I found it necessary to have 4096 position values per-meter, up from 512 with snapshot interpolation, and a whopping 15 bits per-quaternion component in smallest three (up from 9). Without this extra precision significant popping occurs because the quantization forces physics objects into penetration with each other, fighting against the simulation which tries to keep the objects out of penetration. I also found that softening the constraints and reducing the maximum velocity which the simulation used to push apart penetrating objects also helped reduce the amount of popping.&lt;/p&gt;
&lt;video preload=&#34;auto&#34; controls=&#34;controls&#34; width=&#34;100%&#34;&gt;
&lt;source src=&#34;http://gafferongames.com/videos/state_synchronization_quantize_both_sides.mp4&#34; type=&#34;video/mp4&#34; /&gt;
&lt;source src=&#34;http://gafferongames.com/videos/state_synchronization_quantize_both_sides.webm&#34; type=&#34;video/webm&#34; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;p&gt;With quantization applied to both sides you can see the result is perfect once again. It may look visually about the same as the uncompressed version but in fact we&amp;rsquo;re able to fit many more state updates per-packet into the 256kbit/sec bandwidth limit. This means we are better able to handle packet loss because state updates for each object are sent more rapidly. If a packet is lost, it&amp;rsquo;s less of a problem because state updates for those objects are being continually included in future packets.&lt;/p&gt;
&lt;p&gt;Be aware that when a burst of packet loss occurs like 1/4 a second with no packets getting through, and this is inevitable that eventually something like this will happen, you will probably get a different result on the left and the right sides. We have to plan for this. In spite of all effort that we have made to ensure that the extrapolation is as close as possible (quantizing both sides and so on) pops can and will occur if the network stops delivering packets.&lt;/p&gt;
&lt;h2 id=&#34;visual-smoothing&#34;&gt;Visual Smoothing&lt;/h2&gt;
&lt;p&gt;We can cover up these pops with smoothing.&lt;/p&gt;
&lt;p&gt;Remember how I said earlier that you should not apply smoothing at the simulation level because it ruins the extrapolation? What we&amp;rsquo;re going to do for smoothing instead is calculating and maintaining position and orientation error offsets that we reduce over time. Then when we render the cubes in the right side we don&amp;rsquo;t render them at the simulation position and orientation, we render them at the simulation position + error offset, and orientation * orientation error.&lt;/p&gt;
&lt;p&gt;Over time we work to reduce these error offsets back to zero for position error and identity for orientation error. For error reduction I use an exponentially smoothed moving average tending towards zero. So in effect, I multiply the position error offset by some factor each frame (eg. 0.9) until it gets close enough to zero for it to be cleared (thus avoiding denormals). For orientation, I slerp a certain amount (0.1) towards identity each frame, which has the same effect for the orientation error.&lt;/p&gt;
&lt;p&gt;The trick to making this all work is that when a state update comes in you take the current simulation position and add the position error to that, and subtract that from the new position, giving the new position error offset which gives an identical result to the current (smoothed) visual position.&lt;/p&gt;
&lt;p&gt;The same process is then applied to the error quaternion (using multiplication by the conjugate instead of subtraction) and this way you effectively calculate on each state update the new position error and orientation error relative to the new state such that the object appears to have not moved at all. Thus state updates are smooth and have no immediate visual effect, and the error reduction smoothes out any error in the extrapolation over time without the player noticing in the common case.&lt;/p&gt;
&lt;p&gt;I find that using a single smoothing factor gives unacceptable results. A factor of 0.95 is perfect for small jitters because it smooths out high frequency jitter really well, but at the same time it is too slow for large position errors, like those that happen after multiple seconds of packet loss:&lt;/p&gt;
&lt;video preload=&#34;auto&#34; controls=&#34;controls&#34; width=&#34;100%&#34;&gt;
&lt;source src=&#34;http://gafferongames.com/videos/state_synchronization_basic_smoothing.mp4&#34; type=&#34;video/mp4&#34; /&gt;
&lt;source src=&#34;http://gafferongames.com/videos/state_synchronization_basic_smoothing.webm&#34; type=&#34;video/webm&#34; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;p&gt;The solution I use is two different scale factors at different error distances, and to make sure the transition is smooth I blend between those two factors linearly according to the amount of positional error that needs to be reduced. In this simulation, having 0.95 for small position errors (25cms or less) while having a tighter blend factor of 0.85 for larger distances (1m error or above) gives a good result. The same strategy works well for orientation using the dot product between the orientation error and the identity matrix. I found that in this case a blend of the same factors between dot 0.1 and 0.5 works well.&lt;/p&gt;
&lt;p&gt;The end result is smooth error reduction for small position and orientation errors combined with a tight error reduction for large pops. As you can see above you don&amp;rsquo;t want to drag out correction of these large pops, they need to be fast and so they&amp;rsquo;re over quickly otherwise they&amp;rsquo;re really disorienting for players, but at the same time you want to have really smooth error reduction when the error is small hence the adaptive error reduction approach works really well.&lt;/p&gt;
&lt;video preload=&#34;auto&#34; controls=&#34;controls&#34; width=&#34;100%&#34;&gt;
&lt;source src=&#34;http://gafferongames.com/videos/state_synchronization_adaptive_smoothing.mp4&#34; type=&#34;video/mp4&#34; /&gt;
&lt;source src=&#34;http://gafferongames.com/videos/state_synchronization_adaptive_smoothing.webm&#34; type=&#34;video/webm&#34; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;h2 id=&#34;delta-compression&#34;&gt;Delta Compression&lt;/h2&gt;
&lt;p&gt;Even though I would argue the result above is probably good enough already it is possible to improve the synchronization considerably from this point. For example to support a world with larger objects or more objects being interacted with. So lets work through some of those techniques and push this technique as far as it can go.&lt;/p&gt;
&lt;p&gt;There is an easy compression that can be performed. Instead of encoding absolute position, if it is within a range of the player cube center, encode position as a relative offset to the player center position. In the common cases where bandwidth is high and state updates need to be more frequent (katamari ball) this provides a large win.&lt;/p&gt;
&lt;p&gt;Next, what if we do want to perform some sort of delta encoding for state synchronization? We can but it&amp;rsquo;s quite different in this case than it is with snapshots because we&amp;rsquo;re not including every cube in every packet, so we can&amp;rsquo;t just track the most recent packet received and say, OK all these state updates in this packet are relative to packet X.&lt;/p&gt;
&lt;p&gt;What you actually have to do is per-object update keep track of the packet that includes the base for that update. You also need to keep track of exactly the set of packets received so that the sender knows which packets are valid bases to encode relative to. This is reasonably complicated and requires a bidirectional ack system over UDP. Such a system is designed for exactly this sort of situation where you need to know exactly which packets definitely got through. You can find a tutorial on how to implement this in &lt;a href=&#34;https://gafferongames.com/post/reliability_and_flow_control/&#34;&gt;this article&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;So assuming that you have an ack system you know with packet sequence numbers get through. What you do then is per-state update write one bit if the update is relative or absolute, if absolute then encode with no base as before, otherwise if relative send the 16 bit sequence number per-state update of the base and then encode relative to the state update data sent in that packet. This adds 1 bit overhead per-update as well as 16 bits to identify the sequence number of the base per-object update. Can we do better?&lt;/p&gt;
&lt;p&gt;Yes. In turns out that of course you&amp;rsquo;re going to have to buffer on the send and receive side to implement this relative encoding and you can&amp;rsquo;t buffer forever. In fact, if you think about it you can only buffer up a couple of seconds before it becomes impractical and in the common case of moving objects you&amp;rsquo;re going to be sending the updates for same object frequently (katamari ball) so practically speaking the base sequence will only be from a short time ago.&lt;/p&gt;
&lt;p&gt;So instead of sending the 16 bit sequence base per-object, send in the header of the packet the most recent acked packet (from the reliability ack system) and per-object encode the offset of the base sequence relative to that value using 5 bits. This way at 60 packets per-second you can identify an state update with a base half a second ago. Any base older than this is unlikely to provide a good delta encoding anyway because it&amp;rsquo;s old, so in that case just drop back to absolute encoding for that update.&lt;/p&gt;
&lt;p&gt;Now lets look at the type of objects that are going to have these absolute encodings rather than relative. They&amp;rsquo;re the objects at rest. What can we do to make them as efficient as possible? In the case of the cube simulation one bad result that can occur is that a cube comes to rest (turns grey) and then has its priority lowered significantly. If that very last update with the position of that object is missed due to packet loss, it can take a long time for that object to have its at rest position updated.&lt;/p&gt;
&lt;p&gt;We can fix this by tracking objects which have recently come to rest and bumping their priority until an ack comes back for a packet they were sent in. Thus they are sent at an elevated priority compared with normal grey cubes (which are at rest and have not moved) and keep resending at that elevated rate until we know that update has been received, thus &amp;ldquo;committing&amp;rdquo; that grey cube to be at rest at the correct position.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;And that&amp;rsquo;s really about it for this technique. Without anything fancy it&amp;rsquo;s already pretty good, and on top of that another order of magnitude improvement is available with delta compression, at the cost of significant complexity!&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Glenn Fiedler&lt;/strong&gt; is the founder and CEO of &lt;strong&gt;&lt;a href=&#34;https://networknext.com&#34;&gt;Network Next&lt;/a&gt;&lt;/strong&gt;.&lt;br&gt;&lt;i&gt;Network Next is fixing the internet for games by creating a marketplace for premium network transit.&lt;/i&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Snapshot Compression</title>
      <link>https://gafferongames.com/post/snapshot_compression/</link>
      <pubDate>Sun, 04 Jan 2015 00:00:00 +0000</pubDate>
      
      <guid>https://gafferongames.com/post/snapshot_compression/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Hi, I&amp;rsquo;m &lt;a href=&#34;https://gafferongames.com&#34;&gt;Glenn Fiedler&lt;/a&gt; and welcome to &lt;strong&gt;&lt;a href=&#34;https://gafferongames.com/categories/networked-physics/&#34;&gt;Networked Physics&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In the &lt;a href=&#34;https://gafferongames.com/post/snapshot_interpolation/&#34;&gt;previous article&lt;/a&gt; we sent snapshots of the entire simulation 10 times per-second over the network and interpolated between them to reconstruct a view of the simulation on the other side.&lt;/p&gt;
&lt;p&gt;The problem with a low snapshot rate like 10HZ is that interpolation between snapshots adds interpolation delay on top of network latency. At 10 snapshots per-second, the minimum interpolation delay is 100ms, and a more practical minimum considering network jitter is 150ms. If protection against one or two lost packets in a row is desired, this blows out to 250ms or 350ms delay.&lt;/p&gt;
&lt;p&gt;This is not an acceptable amount of delay for most games, but when the physics simulation is as unpredictable as ours, the only way to reduce it is to increase the packet send rate. Unfortunately, increasing the send rate also increases bandwidth. So what we&amp;rsquo;re going to do in this article is work through every possible bandwidth optimization &lt;em&gt;(that I can think of at least)&lt;/em&gt; until we get bandwidth under control.&lt;/p&gt;
&lt;p&gt;Our target bandwidth is &lt;strong&gt;256 kilobits per-second&lt;/strong&gt;.&lt;/p&gt;
&lt;h1 id=&#34;starting-point--60hz&#34;&gt;Starting Point @ 60HZ&lt;/h1&gt;
&lt;p&gt;Life is rarely easy, and the life of a network programmer, even less so. As network programmers we&amp;rsquo;re often tasked with the impossible, so in that spirit, let&amp;rsquo;s increase the snapshot send rate from 10 to 60 snapshots per-second and see exactly how far away we are from our target bandwidth.&lt;/p&gt;
&lt;video preload=&#34;auto&#34; controls=&#34;controls&#34; width=&#34;100%&#34;&gt;
  &lt;source src=&#34;http://gafferongames.com/videos/snapshot_compression_uncompressed.mp4&#34; type=&#34;video/mp4&#34;/&gt;
  &lt;source src=&#34;http://gafferongames.com/videos/snapshot_compression_uncompressed.webm&#34; type=&#34;video/webm&#34;/&gt;
&lt;/video&gt;
&lt;p&gt;That&amp;rsquo;s a &lt;em&gt;LOT&lt;/em&gt; of bandwidth: &lt;strong&gt;17.37 megabits per-second!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s break it down and see where all the bandwidth is going.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s the per-cube state sent in the snapshot:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    struct CubeState
    {
        bool interacting;
        vec3f position;
        vec3f linear_velocity;
        quat4f orientation;
    };
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And here&amp;rsquo;s the size of each field:&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;quat orientation: &lt;b&gt;128 bits&lt;/b&gt;&lt;/li&gt;
    &lt;li&gt;vec3 linear_velocity: &lt;b&gt;96 bits&lt;/b&gt;&lt;/li&gt;
    &lt;li&gt;vec3 position: &lt;b&gt;96 bits&lt;/b&gt;&lt;/li&gt;
    &lt;li&gt;bool interacting: &lt;b&gt;1 bit&lt;/b&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This gives a total of 321 bits bits per-cube (or 40.125 bytes per-cube).&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s do a quick calculation to see if the bandwidth checks out. The scene has 901 cubes so &lt;strong&gt;901*40.125 = 36152.625&lt;/strong&gt; bytes of cube data per-snapshot. 60 snapshots per-second so &lt;strong&gt;36152.625 * 60 = 2169157.5&lt;/strong&gt; bytes per-second. Add in packet header estimate: &lt;strong&gt;2169157.5 + 32*60 = 2170957.5&lt;/strong&gt;. Convert bytes per-second to megabits per-second: &lt;strong&gt;2170957.5 * 8 / ( 1000 * 1000 ) = 17.38mbps&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Everything checks out. There&amp;rsquo;s no easy way around this, we&amp;rsquo;re sending a hell of a lot of bandwidth, and we have to reduce that to something around 1-2% of it&amp;rsquo;s current bandwidth to hit our target of 256 kilobits per-second.&lt;/p&gt;
&lt;p&gt;Is this even possible? &lt;em&gt;Of course it is!&lt;/em&gt; Let&amp;rsquo;s get started :)&lt;/p&gt;
&lt;h2 id=&#34;optimizing-orientation&#34;&gt;Optimizing Orientation&lt;/h2&gt;
&lt;p&gt;We&amp;rsquo;ll start by optimizing orientation because it&amp;rsquo;s the largest field. (When optimizing bandwidth it&amp;rsquo;s good to work in the order of greatest to least potential gain where possible&amp;hellip;)&lt;/p&gt;
&lt;p&gt;Many people when compressing a quaternion think: &amp;ldquo;I know. I&amp;rsquo;ll just pack it into 8.8.8.8 with one 8 bit signed integer per-component!&amp;rdquo;. Sure, that works, but with a bit of math you can get much better accuracy with fewer bits using a trick called the &amp;ldquo;smallest three&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;How does the smallest three work? Since we know the quaternion represents a rotation its length must be 1, so x^2+y^2+z^2+w^2 = 1. We can use this identity to drop one component and reconstruct it on the other side. For example, if you send x,y,z you can reconstruct w = sqrt( 1 - x^2 - y^2 - z^2 ). You might think you need to send a sign bit for w in case it is negative, but you don&amp;rsquo;t, because you can make w always positive by negating the entire quaternion if w is negative (in quaternion space (x,y,z,w) and (-x,-y,-z,-w) represent the same rotation.)&lt;/p&gt;
&lt;p&gt;Don&amp;rsquo;t always drop the same component due to numerical precision issues. Instead, find the component with the largest absolute value and encode its index using two bits [0,3] (0=x, 1=y, 2=z, 3=w), then send the index of the largest component and the smallest three components over the network (hence the name). On the other side use the index of the largest bit to know which component you have to reconstruct from the other three.&lt;/p&gt;
&lt;p&gt;One final improvement. If v is the absolute value of the largest quaternion component, the next largest possible component value occurs when two components have the same absolute value and the other two components are zero. The length of that quaternion (v,v,0,0) is 1, therefore v^2 + v^2 = 1, 2v^2 = 1, v = 1/sqrt(2). This means you can encode the smallest three components in [-0.707107,+0.707107] instead of [-1,+1] giving you more precision with the same number of bits.&lt;/p&gt;
&lt;p&gt;With this technique I&amp;rsquo;ve found that minimum sufficient precision for my simulation is 9 bits per-smallest component. This gives a result of 2 + 9 + 9 + 9 = 29 bits per-orientation (down from 128 bits).&lt;/p&gt;
&lt;video controls=&#34;controls&#34; width=&#34;100%&#34;&gt;
&lt;source src=&#34;http://gafferongames.com/videos/snapshot_compression_compressed_orientation.mp4&#34; type=&#34;video/mp4&#34; /&gt;
&lt;source src=&#34;http://gafferongames.com/videos/snapshot_compression_compressed_orientation.webm&#34; type=&#34;video/webm&#34; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;p&gt;This optimization reduces bandwidth by over 5 megabits per-second, and I think if you look at the right side, you&amp;rsquo;d be hard pressed to spot any artifacts from the compression.&lt;/p&gt;
&lt;h2 id=&#34;optimizing-linear-velocity&#34;&gt;Optimizing Linear Velocity&lt;/h2&gt;
&lt;p&gt;What should we optimize next? It&amp;rsquo;s a tie between linear velocity and position. Both are 96 bits. In my experience position is the harder quantity to compress so let&amp;rsquo;s start here.&lt;/p&gt;
&lt;p&gt;To compress linear velocity we need to bound its x,y,z components in some range so we don&amp;rsquo;t need to send full float values. I found that a maximum speed of 32 meters per-second is a nice power of two and doesn&amp;rsquo;t negatively affect the player experience in the cube simulation. Since we&amp;rsquo;re really only using the linear velocity as a &lt;em&gt;hint&lt;/em&gt; to improve interpolation between position sample points we can be pretty rough with compression. 32 distinct values per-meter per-second provides acceptable precision.&lt;/p&gt;
&lt;p&gt;Linear velocity has been bounded and quantized and is now three integers in the range [-1024,1023]. That breaks down as follows: [-32,+31] (6 bits) for integer component and multiply 5 bits fraction precision. I hate messing around with sign bits so I just add 1024 to get the value in range [0,2047] and send that instead. To decode on receive just subtract 1024 to get back to signed integer range before converting to float.&lt;/p&gt;
&lt;p&gt;11 bits per-component gives 33 bits total per-linear velocity. Just over 1/3 the original uncompressed size!&lt;/p&gt;
&lt;p&gt;We can do even better than this because most cubes are stationary. To take advantage of this we just write a single bit &amp;ldquo;at rest&amp;rdquo;. If this bit is 1, then velocity is implicitly zero and is not sent. Otherwise, the compressed velocity follows after the bit (33 bits). Cubes at rest now cost just 127 bits, while cubes that are moving cost one bit more than they previously did: 159 + 1 = 160 bits.&lt;/p&gt;
&lt;video controls=&#34;controls&#34; width=&#34;100%&#34;&gt;
&lt;source src=&#34;http://gafferongames.com/videos/snapshot_compression_at_rest_flag.mp4&#34; type=&#34;video/mp4&#34; /&gt;
&lt;source src=&#34;http://gafferongames.com/videos/snapshot_compression_at_rest_flag.webm&#34; type=&#34;video/webm&#34; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;p&gt;But why are we sending linear velocity at all? In the &lt;a href=&#34;http://gafferongames.com/networked-physics/snapshots-and-interpolation/&#34;&gt;previous article&lt;/a&gt; we decided to send it because it improved the quality of interpolation at 10 snapshots per-second, but now that we&amp;rsquo;re sending 60 snapshots per-second is this still necessary? As you can see below the answer is &lt;em&gt;no&lt;/em&gt;.&lt;/p&gt;
&lt;video controls=&#34;controls&#34; width=&#34;100%&#34;&gt;
&lt;source src=&#34;http://gafferongames.com/videos/snapshot_compression_no_velocity.mp4&#34; type=&#34;video/mp4&#34; /&gt;
&lt;source src=&#34;http://gafferongames.com/videos/snapshot_compression_no_velocity.webm&#34; type=&#34;video/webm&#34; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;p&gt;Linear interpolation is good enough at 60HZ. This means we can avoid sending linear velocity entirely. Sometimes the best bandwidth optimizations aren&amp;rsquo;t about optimizing what you send, they&amp;rsquo;re about what you &lt;em&gt;don&amp;rsquo;t&lt;/em&gt; send.&lt;/p&gt;
&lt;h2 id=&#34;optimizing-position&#34;&gt;Optimizing Position&lt;/h2&gt;
&lt;p&gt;Now we have only position to compress. We&amp;rsquo;ll use the same trick we used for linear velocity: bound and quantize. I chose a position bound of [-256,255] meters in the horizontal plane (xy) and since in the cube simulation the floor is at z=0, I chose a range of [0,32] meters for z.&lt;/p&gt;
&lt;p&gt;Now we need to work out how much precision is required. With experimentation I found that 512 values per-meter (roughly 2mm precision) provides enough precision. This gives position x and y components in [-131072,+131071] and z components in range [0,16383]. That&amp;rsquo;s 18 bits for x, 18 bits for y and 14 bits for z giving a total of 50 bits per-position (originally 96).&lt;/p&gt;
&lt;p&gt;This reduces our cube state to 80 bits, or just 10 bytes per-cube.&lt;/p&gt;
&lt;p&gt;This is approximately 1/4 of the original cost. Definite progress!&lt;/p&gt;
&lt;video controls=&#34;controls&#34; width=&#34;100%&#34;&gt;
&lt;source src=&#34;http://gafferongames.com/videos/snapshot_compression_compressed_position.mp4&#34; type=&#34;video/mp4&#34; /&gt;
&lt;source src=&#34;http://gafferongames.com/videos/snapshot_compression_compressed_position.webm&#34; type=&#34;video/webm&#34; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;p&gt;Now that we&amp;rsquo;ve compressed position and orientation we&amp;rsquo;ve run out of simple optimizations. Any further reduction in precision results in unacceptable artifacts.&lt;/p&gt;
&lt;h2 id=&#34;delta-compression&#34;&gt;Delta Compression&lt;/h2&gt;
&lt;p&gt;Can we optimize further? The answer is yes, but only if we embrace a completely new technique: &lt;strong&gt;delta compression&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Delta compression sounds mysterious. Magical. Hard. Actually, it&amp;rsquo;s not hard at all. Here&amp;rsquo;s how it works: the left side sends packets to the right like this: &amp;ldquo;This is snapshot 110 encoded relative to snapshot 100&amp;rdquo;. The snapshot being encoded relative to is called the baseline. How you do this encoding is up to you, there are many fancy tricks, but the basic, big order of magnitude win comes when you say: &amp;ldquo;Cube n in snapshot 110 is the same as the baseline. One bit: Not changed!&amp;rdquo;&lt;/p&gt;
&lt;p&gt;To implement delta encoding it is of course essential that the sender only encodes snapshots relative to baselines that the other side has received, otherwise they cannot decode the snapshot. Therefore, to handle packet loss the receiver has to continually send &amp;ldquo;ack&amp;rdquo; packets back to the sender saying: &amp;ldquo;the most recent snapshot I have received is snapshot n&amp;rdquo;. The sender takes this most recent ack and if it is more recent than the previous ack updates the baseline snapshot to this value. The next time a packet is sent out the snapshot is encoded relative to this more recent baseline. This process happens continuously such that the steady state becomes the sender encoding snapshots relative to a baseline that is roughly RTT (round trip time) in the past.&lt;/p&gt;
&lt;p&gt;There is one slight wrinkle: for one round trip time past initial connection the sender doesn&amp;rsquo;t have any baseline to encode against because it hasn&amp;rsquo;t received an ack from the receiver yet. I handle this by adding a single flag to the packet that says: &amp;ldquo;this snapshot is encoded relative to the initial state of the simulation&amp;rdquo; which is known on both sides. Another option if the receiver doesn&amp;rsquo;t know the initial state is to send down the initial state using a non-delta encoded path, eg. as one large data block, and once that data block has been received delta encoded snapshots are sent first relative to the initial baseline in the data block, then eventually converge to the steady state of baselines at RTT.&lt;/p&gt;
&lt;video controls=&#34;controls&#34; width=&#34;100%&#34;&gt;
&lt;source src=&#34;http://gafferongames.com/videos/snapshot_compression_delta_not_changed.mp4&#34; type=&#34;video/mp4&#34; /&gt;
&lt;source src=&#34;http://gafferongames.com/videos/snapshot_compression_delta_not_changed.webm&#34; type=&#34;video/webm&#34; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;p&gt;As you can see above this is a big win. We can refine this approach and lock in more gains but we&amp;rsquo;re not going to get another order of magnitude improvement past this point. From now on we&amp;rsquo;re going to have to work pretty hard to get a number of small, cumulative gains to reach our goal of 256 kilobits per-second.&lt;/p&gt;
&lt;h2 id=&#34;incremental-improvements&#34;&gt;Incremental Improvements&lt;/h2&gt;
&lt;p&gt;First small improvement. Each cube that isn&amp;rsquo;t sent costs 1 bit (not changed). There are 901 cubes so we send 901 bits in each packet even if no cubes have changed. At 60 packets per-second this adds up to 54kbps of bandwidth. Seeing as there are usually significantly less than 901 changed cubes per-snapshot in the common case, we can reduce bandwidth by sending only changed cubes with a cube index [0,900] identifying which cube it is. To do this we need to add a 10 bit index per-cube to identify it.&lt;/p&gt;
&lt;p&gt;There is a cross-over point where it is actually more expensive to send indices than not-changed bits. With 10 bit indices, the cost of indexing is 10*n bits. Therefore it&amp;rsquo;s more efficient to use indices if we are sending 90 cubes or less (900 bits). We can evaluate this per-snapshot and send a single bit in the header indicating which encoding we are using: 0 = indexing, 1 = changed bits. This way we can use the most efficient encoding for the number of changed cubes in the snapshot.&lt;/p&gt;
&lt;p&gt;This reduces the steady state bandwidth when all objects are stationary to around 15 kilobits per-second. This bandwidth is composed entirely of our own packet header (uint16 sequence, uint16 base, bool initial) plus IP and UDP headers (28 bytes).&lt;/p&gt;
&lt;p&gt;Next small gain. What if we encoded the cube index relative to the previous cube index? Since we are iterating across and sending changed cube indices in-order: cube 0, cube 10, cube 11, 50, 52, 55 and so on we could easily encode the 2nd and remaining cube indices relative to the previous changed index, e.g.: +10, +1, +39, +2, +3. If we are smart about how we encode this index offset we should be able to, on average, represent a cube index with less than 10 bits.&lt;/p&gt;
&lt;p&gt;The best encoding depends on the set of objects you interact with. If you spend a lot of time moving horizontally while blowing cubes from the initial cube grid then you hit lots of +1s. If you move vertically from initial state you hit lots of +30s (sqrt(900)). What we need then is a general purpose encoding capable of representing statistically common index offsets with less bits.&lt;/p&gt;
&lt;p&gt;After a small amount of experimentation I came up with this simple encoding:&lt;/p&gt;
&lt;ul&gt;
    &lt;li&gt;[1,8] =&amp;gt; 1 + 3 (4 bits)&lt;/li&gt;
    &lt;li&gt;[9,40] =&amp;gt; 1 + 1 + 5 (7 bits)&lt;/li&gt;
    &lt;li&gt;[41,900] =&amp;gt; 1 + 1 + 10 (12 bits)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Notice how large relative offsets are actually more expensive than 10 bits. It&amp;rsquo;s a statistical game. The bet is that we&amp;rsquo;re going to get a much larger number of small offsets so that the win there cancels out the increased cost of large offsets. It works. With this encoding I was able to get an average of 5.5 bits per-relative index.&lt;/p&gt;
&lt;p&gt;Now we have a slight problem. We can no longer easily determine whether changed bits or relative indices are the best encoding. The solution I used is to run through a mock encoding of all changed cubes on packet write and count the number of bits required to encode relative indices. If the number of bits required is larger than 901, fallback to changed bits.&lt;/p&gt;
&lt;p&gt;Here is where we are so far, which is a significant improvement:&lt;/p&gt;
&lt;video controls=&#34;controls&#34; width=&#34;100%&#34;&gt;
&lt;source src=&#34;http://gafferongames.com/videos/snapshot_compression_delta_relative_index.mp4&#34; type=&#34;video/mp4&#34; /&gt;
&lt;source src=&#34;http://gafferongames.com/videos/snapshot_compression_delta_relative_index.webm&#34; type=&#34;video/webm&#34; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;p&gt;Next small improvement. Encoding position relative to (offset from) the baseline position. Here there are a lot of different options. You can just do the obvious thing, eg. 1 bit relative position, and then say 8-10 bits per-component if all components have deltas within the range provided by those bits, otherwise send the absolute position (50 bits).&lt;/p&gt;
&lt;p&gt;This gives a decent encoding but we can do better. If you think about it then there will be situations where one position component is large but the others are small. It would be nice if we could take advantage of this and send these small components using less bits.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s a statistical game and the best selection of small and large ranges per-component depend on the data set. I couldn&amp;rsquo;t really tell looking at a noisy bandwidth meter if I was making any gains so I captured the position vs. position base data set and wrote it to a text file for analysis.&lt;/p&gt;
&lt;p&gt;I wrote a short ruby script to find the best encoding with a greedy search. The best bit-packed encoding I found for the data set works like this: 1 bit small per delta component followed by 5 bits if small [-16,+15] range, otherwise the delta component is in [-256,+255] range and is sent with 9 bits. If any component delta values are outside the large range, fallback to absolute position. Using this encoding I was able to obtain on average 26.1 bits for changed positions values.&lt;/p&gt;
&lt;h2 id=&#34;delta-encoding-smallest-three&#34;&gt;Delta Encoding Smallest Three&lt;/h2&gt;
&lt;p&gt;Next I figured that relative orientation would be a similar easy big win. Problem is that unlike position where the range of the position offset is quite small relative to the total position space, the change in orientation in 100ms is a much larger percentage of total quaternion space.&lt;/p&gt;
&lt;p&gt;I tried a bunch of stuff without good results. I tried encoding the 4D vector of the delta orientation directly and recomposing the largest component post delta using the same trick as smallest 3. I tried calculating the relative quaternion between orientation and base orientation, and since I knew that w would be large for this (rotation relative to identity) I could avoid sending 2 bits to identify the largest component, but in turn would need to send one bit for the sign of w because I don&amp;rsquo;t want to negate the quaternion. The best compression I could find using this scheme was only 90% of the smallest three. Not very good.&lt;/p&gt;
&lt;p&gt;I was about to give up but I run some analysis over the smallest three representation. I found that 90% of orientations in the smallest three format had the same largest component index as their base orientation 100ms ago. This meant that it could be profitable to delta encode the smallest three format directly. What&amp;rsquo;s more I found that there would be no additional precision loss with this method when reconstructing the orientation from its base. I exported the quaternion values from a typical run as a data set in smallest three format and got to work trying the same multi-level small/large range per-component greedy search that I used for position.&lt;/p&gt;
&lt;p&gt;The best encoding found was: 5-8, meaning [-16,+15] small and [-128,+127] large. One final thing: as with position the large range can be extended a bit further by knowing that if the component value is not small the value cannot be in the [-16,+15] range. I leave the calculation of how to do this as an exercise for the reader. Be careful not to collapse two values onto zero.&lt;/p&gt;
&lt;p&gt;The end result is an average of 23.3 bits per-relative quaternion. That&amp;rsquo;s 80.3% of the absolute smallest three.&lt;/p&gt;
&lt;p&gt;That&amp;rsquo;s just about it but there is one small win left. Doing one final analysis pass over the position and orientation data sets I noticed that 5% of positions are unchanged from the base position after being quantized to 0.5mm resolution, and 5% of orientations in smallest three format are also unchanged from base.&lt;/p&gt;
&lt;p&gt;These two probabilities are mutually exclusive, because if both are the same then the cube would be unchanged and therefore not sent, meaning a small statistical win exists for 10% of cube state if we send one bit for position changing, and one bit for orientation changing. Yes, 90% of cubes have 2 bits overhead added, but the 10% of cubes that save 20+ bits by sending 2 bits instead of 23.3 bit orientation or 26.1 bits position make up for that providing a small overall win of roughly 2 bits per-cube.&lt;/p&gt;
&lt;video controls=&#34;controls&#34; width=&#34;100%&#34;&gt;
&lt;source src=&#34;http://gafferongames.com/videos/snapshot_compression_delta_end_result.mp4&#34; type=&#34;video/mp4&#34; /&gt;
&lt;source src=&#34;http://gafferongames.com/videos/snapshot_compression_delta_end_result.webm&#34; type=&#34;video/webm&#34; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;p&gt;As you can see the end result is pretty good.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;And that&amp;rsquo;s about as far as I can take it using traditional hand-rolled bit-packing techniques. You can find source code for my implementation of all compression techniques mentioned in this article &lt;a href=&#34;https://gist.github.com/gafferongames/bb7e593ba1b05da35ab6&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s possible to get even better compression using a different approach. Bit-packing is inefficient because not all bit values have equal probability of 0 vs 1. No matter how hard you tune your bit-packer a context aware arithmetic encoding can beat your result by more accurately modeling the probability of values that occur in your data set. This &lt;a href=&#34;https://github.com/rygorous/gaffer_net/blob/master/main.cpp&#34;&gt;implementation&lt;/a&gt; by Fabian Giesen beat my best bit-packed result by 25%.&lt;/p&gt;
&lt;p&gt;It&amp;rsquo;s also possible to get a much better result for delta encoded orientations using the previous baseline orientation values to estimate angular velocity and predict future orientations rather than delta encoding the smallest three representation directly.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NEXT ARTICLE:&lt;/strong&gt; &lt;a href=&#34;https://gafferongames.com/post/state_synchronization/&#34;&gt;State Synchronization&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Glenn Fiedler&lt;/strong&gt; is the founder and CEO of &lt;strong&gt;&lt;a href=&#34;https://networknext.com&#34;&gt;Network Next&lt;/a&gt;&lt;/strong&gt;.&lt;br&gt;&lt;i&gt;Network Next is fixing the internet for games by creating a marketplace for premium network transit.&lt;/i&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Snapshot Interpolation</title>
      <link>https://gafferongames.com/post/snapshot_interpolation/</link>
      <pubDate>Sun, 30 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://gafferongames.com/post/snapshot_interpolation/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Hi, I&amp;rsquo;m &lt;a href=&#34;https://gafferongames.com&#34;&gt;Glenn Fiedler&lt;/a&gt; and welcome to &lt;strong&gt;&lt;a href=&#34;https://gafferongames.com/categories/networked-physics/&#34;&gt;Networked Physics&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In the &lt;a href=&#34;https://gafferongames.com/post/deterministic_lockstep/&#34;&gt;previous article&lt;/a&gt; we networked a physics simulation using deterministic lockstep. Now, in this article we&amp;rsquo;re going to network the same simulation with a completely different technique: &lt;strong&gt;snapshot interpolation&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;p&gt;While deterministic lockstep is very efficient in terms of bandwidth, it&amp;rsquo;s not always possible to make your simulation deterministic. Floating point determinism across platforms is &lt;a href=&#34;https://gafferongames.com/post/floating_point_determinism/&#34;&gt;hard&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Also, as the player counts increase, deterministic lockstep becomes problematic: you can&amp;rsquo;t simulate frame n until you receive input from &lt;em&gt;all&lt;/em&gt; players for that frame, so players end up waiting for the most lagged player. Because of this, I recommend deterministic lockstep for 2-4 players at most.&lt;/p&gt;
&lt;p&gt;So if your simulation is not deterministic or you want higher player counts then you need a different technique. Snapshot interpolation fits the bill nicely. It is in many ways the polar opposite of deterministic lockstep: instead of running two simulations, one on the left and one on the right, and using perfect determinism and synchronized inputs keep them in sync, snapshot interpolation doesn&amp;rsquo;t run any simulation on the right side at all!&lt;/p&gt;
&lt;h2 id=&#34;snapshots&#34;&gt;Snapshots&lt;/h2&gt;
&lt;p&gt;Instead, we capture a &lt;strong&gt;snapshot&lt;/strong&gt; of all relevant state from the simulation on the left and transmit it to the right, then on the right side we use those snapshots to reconstruct a visual approximation of the simulation, all without running the simulation itself.&lt;/p&gt;
&lt;p&gt;As a first pass, let&amp;rsquo;s send across the state required to render each cube:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    struct CubeState
    {
        bool interacting;
        vec3f position;
        quat4f orientation;
    };
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I&amp;rsquo;m sure you&amp;rsquo;ve worked out by now that the cost of this technique is increased bandwidth usage. Greatly increased bandwidth usage. Hold on to your neckbeards, because a snapshot contains the visual state for the entire simulation. With a bit of math we can see that each cube serializes down to 225 bits or 28.1 bytes. Since there are 900 cubes in our simulation that means each snapshot is roughly 25 kilobytes. That&amp;rsquo;s pretty big!&lt;/p&gt;
&lt;p&gt;At this point I would like everybody to relax, take a deep breath, and imagine we live in a world where I can actually send a packet this large 60 times per-second over the internet and not have everything explode. Imagine I have FIOS &lt;em&gt;(I do)&lt;/em&gt;, or I&amp;rsquo;m sitting over a backbone link to another computer that is also on the backbone. Imagine I live in South Korea. Do whatever you need to do to suspend disbelief, but most of all, don&amp;rsquo;t worry, because I&amp;rsquo;m going to spend the entire next article showing you how to optimize snapshot bandwidth.&lt;/p&gt;
&lt;p&gt;When we send snapshot data in packets, we include at the top a 16 bit sequence number. This sequence number starts at zero and increases with each packet sent. We use this sequence number on receive to determine if the snapshot in a packet is newer or older than the most recent snapshot received. If it&amp;rsquo;s older then it&amp;rsquo;s thrown away.&lt;/p&gt;
&lt;p&gt;Each frame we just render the most recent snapshot received on the right:&lt;/p&gt;
&lt;video preload=&#34;auto&#34; autoplay=&#34;autoplay&#34; loop=&#34;loop&#34; width=&#34;100%&#34;&gt;
  &lt;source src=&#34;http://gafferongames.com/videos/snapshot_interpolation_60pps_jitter.mp4&#34; type=&#34;video/mp4&#34;/&gt;
  &lt;source src=&#34;http://gafferongames.com/videos/snapshot_interpolation_60pps_jitter.webm&#34; type=&#34;video/webm&#34;/&gt;
&lt;/video&gt;
&lt;p&gt;Look closely though, and even though we&amp;rsquo;re sending the data as rapidly as possible (one packet per-frame) you can still see hitches on the right side. This is because the internet makes no guarantee that packets sent 60 times per-second arrive nicely spaced 1/60 of a second apart. Packets are jittered. Some frames you receive two snapshot packets. Other frames you receive none.&lt;/p&gt;
&lt;h1 id=&#34;jitter-and-hitches&#34;&gt;Jitter and Hitches&lt;/h1&gt;
&lt;p&gt;This is actually a really common thing when you first start networking. You start out playing your game over LAN and notice you can just slam out packets really fast (60pps) and most of the time your game looks great because over the LAN those packets actually do tend to arrive at the same rate they were sent&amp;hellip; and then you start trying to play your game over wireless or the internet and you start seeing hitches. Don&amp;rsquo;t worry. There are ways to handle this!&lt;/p&gt;
&lt;p&gt;First, let&amp;rsquo;s look at how much bandwidth we&amp;rsquo;re sending with this naive approach. Each packet is 25312.5 bytes plus 28 bytes for IP + UDP header and 2 bytes for sequence number. That&amp;rsquo;s 25342.5 bytes per-packet and at 60 packets per-second this gives a total of 1520550 bytes per-second or 11.6 megabit/sec. Now there are certainly internet connections out there that can support that amount of traffic&amp;hellip; but since, let&amp;rsquo;s be honest, we&amp;rsquo;re not really getting a lot of benefit blasting packets out 60 times per-second with all the jitter, let&amp;rsquo;s pull it back a bit and send only 10 snapshots per-second:&lt;/p&gt;
&lt;video preload=&#34;auto&#34; autoplay=&#34;autoplay&#34; loop=&#34;loop&#34; width=&#34;100%&#34;&gt;
  &lt;source src=&#34;http://gafferongames.com/videos/snapshot_interpolation_10pps_no_interpolation.mp4&#34; type=&#34;video/mp4&#34;/&gt;
  &lt;source src=&#34;http://gafferongames.com/videos/snapshot_interpolation_10pps_no_interpolation.webm&#34; type=&#34;video/webm&#34;/&gt;
&lt;/video&gt;
&lt;p&gt;You can see how this looks above. Not so great on the right side but at least we&amp;rsquo;ve reduced bandwidth by a factor of six to around 2 megabit/sec. We&amp;rsquo;re definitely headed in the right direction.&lt;/p&gt;
&lt;h2 id=&#34;linear-interpolation&#34;&gt;Linear Interpolation&lt;/h2&gt;
&lt;p&gt;Now for the trick with snapshots. What we do is instead of immediately rendering snapshot data received is that we buffer snapshots for a short amount of time in an interpolation buffer. This interpolation buffer holds on to snapshots for a period of time such that you have not only the snapshot you want to render but also, statistically speaking, you are very likely to have the next snapshot as well. Then as the right side moves forward in time we interpolate between the position and orientation for the two slightly delayed snapshots providing the illusion of smooth movement. In effect, we&amp;rsquo;ve traded a small amount of added latency for smoothness.&lt;/p&gt;
&lt;p&gt;You may be surprised at just how good it looks with linear interpolation @ 10pps:&lt;/p&gt;
&lt;video preload=&#34;auto&#34; autoplay=&#34;autoplay&#34; loop=&#34;loop&#34; width=&#34;100%&#34;&gt;
  &lt;source src=&#34;http://gafferongames.com/videos/snapshot_interpolation_10pps_linear_interpolation.mp4&#34; type=&#34;video/mp4&#34;/&gt;
  &lt;source src=&#34;http://gafferongames.com/videos/snapshot_interpolation_10pps_linear_interpolation.webm&#34; type=&#34;video/webm&#34;/&gt;
&lt;/video&gt;
&lt;p&gt;Look closely though and you can see some artifacts on the right side. The first is a subtle position jitter when the player cube is hovering in the air. This is your brain detecting 1st order discontinuity at the sample points of position interpolation. The other artifact occurs when a bunch of cubes are in a katamari ball, you can see a sort of &amp;ldquo;pulsing&amp;rdquo; as the speed of rotation increases and decreases. This occurs because attached cubes interpolate linearly between two sample points rotating around the player cube, effectively interpolating &lt;em&gt;through&lt;/em&gt; the player cube as they take the shortest linear path between two points on a circle.&lt;/p&gt;
&lt;h2 id=&#34;hermite-interpolation&#34;&gt;Hermite Interpolation&lt;/h2&gt;
&lt;p&gt;I find these artifacts unacceptable but I don&amp;rsquo;t want to increase the packet send rate to fix them. Let&amp;rsquo;s see what we can do to make it look better at the same send rate instead. One thing we can try is upgrading to a more accurate interpolation scheme for position, one that interpolates between position samples while considering the linear velocity at each sample point.&lt;/p&gt;
&lt;p&gt;This can be done with an &lt;a href=&#34;http://en.wikipedia.org/wiki/Hermite_interpolation&#34;&gt;hermite spline&lt;/a&gt; (pronounced &amp;ldquo;air-mitt&amp;rdquo;)&lt;/p&gt;
&lt;p&gt;Unlike other splines with control points that affect the curve indirectly, the hermite spline is guaranteed to pass through the start and end points while matching the start and end velocities. This means that velocity is smooth across sample points and cubes in the katamari ball tend to rotate around the cube rather than interpolate through it at speed.&lt;/p&gt;
&lt;video preload=&#34;auto&#34; autoplay=&#34;autoplay&#34; loop=&#34;loop&#34; width=&#34;100%&#34;&gt;
  &lt;source src=&#34;http://gafferongames.com/videos/snapshot_interpolation_10pps_hermite_interpolation.mp4&#34; type=&#34;video/mp4&#34;/&gt;
  &lt;source src=&#34;http://gafferongames.com/videos/snapshot_interpolation_10pps_hermite_interpolation.webm&#34; type=&#34;video/webm&#34;/&gt;
&lt;/video&gt;
&lt;p&gt;Above you can see hermite interpolation for position @ 10pps. Bandwidth has increased slightly because we need to include linear velocity with each cube in the snapshot, but we&amp;rsquo;re able to significantly increase the quality at the same send rate. I can no longer see any artifacts. Go back and compare this with the raw, non-interpolated 10pps version. It really is amazing that we&amp;rsquo;re able to reconstruct the simulation with this level of quality at such a low send rate.&lt;/p&gt;
&lt;p&gt;As an aside, I found it was not necessary to perform higher order interpolation for orientation quaternions to get smooth interpolation. This is great because I did a lot of research into exactly interpolating between orientation quaternions with a specified angular velocity at sample points and it seemed difficult. All that was needed to achieve an acceptable result was to switch from linear interpolation + normalize (nlerp) to spherical linear interpolation (slerp) to ensure constant angular speed for orientation interpolation.&lt;/p&gt;
&lt;p&gt;I believe this is because cubes in the simulation tend to have mostly constant angular velocity while in the air and large angular velocity changes occur only discontinuously when collisions occur. It could also be because orientation tends to change slowly while in the air vs. position which changes rapidly relative to the number of pixels affected on screen. Either way, it seems that slerp is good enough and that&amp;rsquo;s great because it means we don&amp;rsquo;t need to send angular velocity in the snapshot.&lt;/p&gt;
&lt;h2 id=&#34;handling-real-world-conditions&#34;&gt;Handling Real World Conditions&lt;/h2&gt;
&lt;p&gt;Now we have to deal with packet loss. After the discussion of UDP vs. TCP in the previous article I&amp;rsquo;m sure you can see why we would never consider sending snapshots over TCP.&lt;/p&gt;
&lt;p&gt;Snapshots are time critical but unlike inputs in deterministic lockstep snapshots don&amp;rsquo;t need to be reliable. If a snapshot is lost we can just skip past it and interpolate towards a more recent snapshot in the interpolation buffer. We don&amp;rsquo;t ever want to stop and wait for a lost snapshot packet to be resent. This is why you should always use UDP for sending snapshots.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ll let you in on a secret. Not only were the linear and hermite interpolation videos above recorded at a send rate of 10 packets per-second, they were also recorded at 5% packet loss with +/- 2 frames of jitter @ 60fps. How I handled packet loss and jitter for those videos is by simply ensuring that snapshots are held in the interpolation buffer for an appropriate amount of time before interpolation.&lt;/p&gt;
&lt;p&gt;My rule of thumb is that the interpolation buffer should have enough delay so that I can lose two packets in a row and still have something to interpolate towards. Experimentally I&amp;rsquo;ve found that the amount of delay that works best at 2-5% packet loss is 3X the packet send rate. At 10 packets per-second this is 300ms. I also need some extra delay to handle jitter, which in my experience is typically only one or two frames @ 60fps, so the interpolation videos above were recorded with a delay of 350ms.&lt;/p&gt;
&lt;p&gt;Adding 350 milliseconds delay seems like a lot. And it is. But, if you try to skimp you end up hitching for 1/10th of a second each time a packet is lost. One technique that people often use to hide the delay added by the interpolation buffer in other areas (such as FPS, flight simulator, racing games and so on) is to use extrapolation. But in my experience, extrapolation doesn&amp;rsquo;t work very well for rigid bodies because their motion is non-linear and unpredictable. Here you can see an extrapolation of 200ms, reducing overall delay from 350 ms to just 150ms:&lt;/p&gt;
&lt;video preload=&#34;auto&#34; autoplay=&#34;autoplay&#34; loop=&#34;loop&#34; width=&#34;100%&#34;&gt;
  &lt;source src=&#34;http://gafferongames.com/videos/snapshot_interpolation_10pps_extrapolation.mp4&#34; type=&#34;video/mp4&#34;/&gt;
  &lt;source src=&#34;http://gafferongames.com/videos/snapshot_interpolation_10pps_extrapolation.webm&#34; type=&#34;video/webm&#34;/&gt;
&lt;/video&gt;
&lt;p&gt;Problem is it&amp;rsquo;s just not very good. The reason is that the extrapolation doesn&amp;rsquo;t know anything about the physics simulation. Extrapolation doesn&amp;rsquo;t know about collision with the floor so cubes extrapolate down through the floor and then spring back up to correct. Prediction doesn&amp;rsquo;t know about the spring force holding the player cube up in the air so it the cube moves slower initially upwards than it should and has to snap to catch up. It also doesn&amp;rsquo;t know anything about collision and how collision response works, so the cube rolling across the floor and other cubes are also mispredicted. Finally, if you watch the katamari ball you&amp;rsquo;ll see that the extrapolation predicts the attached cubes as continuing to move along their tangent velocity when they should rotate with the player cube.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;You could conceivably spend a great deal of time to improve the quality of this extrapolation and make it aware of various movement modes for the cubes. You could take each cube and make sure that at minimum the cube doesn&amp;rsquo;t go through the floor. You could add some approximate collision detection or response using bounding spheres between cubes. You could even take the cubes in the katamari ball and make them predict motion to rotate around with the player cube.&lt;/p&gt;
&lt;p&gt;But even if you do all this there will still be misprediction because you simply can&amp;rsquo;t accurately match a physics simulation with an approximation. If your simulation is mostly linear motion, eg. fast moving planes, boats, space ships &amp;ndash; you may find that a simple extrapolation works well for short time periods (50-250ms or so), but in my experience as soon as objects start colliding with other non-stationary objects, extrapolation starts to break down.&lt;/p&gt;
&lt;p&gt;How can we reduce the amount of delay added for interpolation? 350ms still seems unacceptable and we can&amp;rsquo;t use extrapolation to reduce this delay without adding a lot of inaccuracy. The solution is simple: &lt;em&gt;increase the send rate!&lt;/em&gt; If we send 30 snapshots per-second we can get the same amount of packet loss protection with a delay of 150ms. 60 packets per-second needs only 85ms.&lt;/p&gt;
&lt;p&gt;In order to increase the send rate we&amp;rsquo;re going to need some pretty good bandwidth optimizations. But don&amp;rsquo;t worry, there&amp;rsquo;s a &lt;em&gt;lot&lt;/em&gt; we can do to optimize bandwidth. So much so that there was too much stuff to fit in this article and I had to insert an extra unplanned article just to cover all of it!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NEXT ARTICLE&lt;/strong&gt;: &lt;a href=&#34;https://gafferongames.com/post/snapshot_compression/&#34;&gt;Snapshot Compression&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Glenn Fiedler&lt;/strong&gt; is the founder and CEO of &lt;strong&gt;&lt;a href=&#34;https://networknext.com&#34;&gt;Network Next&lt;/a&gt;&lt;/strong&gt;.&lt;br&gt;&lt;i&gt;Network Next is fixing the internet for games by creating a marketplace for premium network transit.&lt;/i&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deterministic Lockstep</title>
      <link>https://gafferongames.com/post/deterministic_lockstep/</link>
      <pubDate>Sat, 29 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://gafferongames.com/post/deterministic_lockstep/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Hi, I&amp;rsquo;m &lt;a href=&#34;https://gafferongames.com&#34;&gt;Glenn Fiedler&lt;/a&gt; and welcome to &lt;strong&gt;&lt;a href=&#34;https://gafferongames.com/categories/networked-physics/&#34;&gt;Networked Physics&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In the &lt;a href=&#34;https://gafferongames.com/post/introduction_to_networked_physics/&#34;&gt;previous article&lt;/a&gt; we explored the physics simulation we&amp;rsquo;re going to network in this article series. In this article specifically, we&amp;rsquo;re going to network this physics simulation using &lt;strong&gt;deterministic lockstep&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Deterministic lockstep is a method of networking a system from one computer to another by sending only the &lt;em&gt;inputs&lt;/em&gt; that control that system, rather than the &lt;em&gt;state&lt;/em&gt; of that system. In the context of networking a physics simulation, this means we send across a small amount of input, while avoiding sending state like position, orientation, linear velocity and angular velocity per-object.&lt;/p&gt;
&lt;p&gt;The benefit is that bandwidth is proportional to the size of the input, not the number of objects in the simulation. Yes, with deterministic lockstep you can network a physics simulation of one million objects with the same bandwidth as just one.&lt;/p&gt;
&lt;p&gt;While this sounds great in theory, in practice it&amp;rsquo;s difficult to implement deterministic lockstep because most physics simulations are not deterministic. Differences in floating point behavior between compilers, OS&amp;rsquo;s and even instruction sets make it almost impossible to guarantee determinism for floating point calculations.&lt;/p&gt;
&lt;h2 id=&#34;determinism&#34;&gt;Determinism&lt;/h2&gt;
&lt;p&gt;Determinism means that given the same initial condition and the same set of inputs your simulation gives exactly the same result. And I do mean &lt;em&gt;exactly&lt;/em&gt; the same result.&lt;/p&gt;
&lt;p&gt;Not close. Not near enough. &lt;strong&gt;Exactly the same&lt;/strong&gt;. Exact down to the bit-level. So exact, you could take a checksum of your entire physics state at the end of each frame and it would be identical.&lt;/p&gt;
&lt;video preload=&#34;auto&#34; autoplay=&#34;autoplay&#34; loop=&#34;loop&#34; width=&#34;100%&#34;&gt;
  &lt;source src=&#34;http://gafferongames.com/videos/deterministic_lockstep_desync.mp4&#34; type=&#34;video/mp4&#34;/&gt;
  &lt;source src=&#34;http://gafferongames.com/videos/deterministic_lockstep_desync.webm&#34; type=&#34;video/webm&#34;/&gt;
&lt;/video&gt;
&lt;p&gt;Above you can see a simulation that is &lt;em&gt;almost&lt;/em&gt; deterministic. The simulation on the left is controlled by the player. The simulation on the right has exactly the same inputs applied with a two second delay starting from the same initial condition. Both simulations step forward with the same delta time (a necessary precondition to ensure exactly the same result) and both simulations apply the same inputs. Notice how after the smallest divergence the simulation gets further and further out of sync. This simulation is &lt;strong&gt;non-deterministic&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;What&amp;rsquo;s going on is that the physics engine I&amp;rsquo;m using (&lt;a href=&#34;http://www.ode.org/&#34;&gt;Open Dynamics Engine&lt;/a&gt;) uses a random number generator inside its solver to randomize the order of constraint processing to improve stability. It&amp;rsquo;s open source. Take a look and see! Unfortunately this breaks determinism because the simulation on the left processes constraints in a different order to the simulation on the right, leading to slightly different results.&lt;/p&gt;
&lt;p&gt;Luckily all that is required to make ODE deterministic on the same machine, with the same complied binary and on the same OS (is that enough qualifications?) is to set its internal random seed to the current frame number before running the simulation via dSetRandomSeed. Once this is done ODE gives exactly the same result and the left and right simulations stay in sync.&lt;/p&gt;
&lt;video preload=&#34;auto&#34; autoplay=&#34;autoplay&#34; loop=&#34;loop&#34; width=&#34;100%&#34;&gt;
  &lt;source src=&#34;http://gafferongames.com/videos/deterministic_lockstep.mp4&#34; type=&#34;video/mp4&#34;/&gt;
  &lt;source src=&#34;http://gafferongames.com/videos/deterministic_lockstep.webm&#34; type=&#34;video/webm&#34;/&gt;
&lt;/video&gt;
&lt;p&gt;And now a word of warning. Even though the simulation above is deterministic on the same machine, that does &lt;em&gt;not&lt;/em&gt; necessarily mean it would also be deterministic across different compilers, a different OS or different machine architectures (eg. PowerPC vs. Intel). In fact, it&amp;rsquo;s probably not even deterministic between debug and release builds due to floating point optimizations.&lt;/p&gt;
&lt;p&gt;Floating point determinism is a complicated subject and there&amp;rsquo;s no silver bullet.&lt;/p&gt;
&lt;p&gt;For more information please refer to this &lt;a href=&#34;https://gafferongames.com/post/floating_point_determinism/&#34;&gt;article&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;networking-inputs&#34;&gt;Networking Inputs&lt;/h2&gt;
&lt;p&gt;Now let&amp;rsquo;s get down to implementation.&lt;/p&gt;
&lt;p&gt;Our example physics simulation is driven by keyboard input: arrow keys apply forces to make the player cube move, holding space lifts the cube up and blows other cubes around, and holding &amp;lsquo;z&amp;rsquo; enables katamari mode.&lt;/p&gt;
&lt;p&gt;How can we network these inputs? Must we send the entire state of the keyboard? No. It&amp;rsquo;s not necessary to send the entire keyboard state, only the state of the keys that affect the simulation. What about key press and release events then? No. This is also not a good strategy. We need to ensure that exactly the same input is applied on the right side, at exactly the same time, so we can&amp;rsquo;t just send &amp;lsquo;key pressed&amp;rsquo;, and &amp;lsquo;key released&amp;rsquo; events over TCP.&lt;/p&gt;
&lt;p&gt;What we do instead is represent the input with a struct and at the beginning of each simulation frame on the left side, sample this struct from the keyboard:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    struct Input
    {
        bool left;
        bool right;
        bool up;
        bool down;
        bool space;
        bool z;
    };
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next we send that input from the left simulation to the right simulation in a way that the simulation on the right side knows that the input belongs to frame n.&lt;/p&gt;
&lt;p&gt;And here&amp;rsquo;s the key part: the simulation on the right can only simulate frame n when it has the input for that frame. If it doesn&amp;rsquo;t have the input, it has to wait.&lt;/p&gt;
&lt;p&gt;For example, if you were sending across using TCP you could simply send the inputs and nothing else, and on the other side you could read the packets coming in, and each input received corresponds to one frame for the simulation to step forward. If no input arrives for a given render frame, the right side can&amp;rsquo;t advance forward, it has to wait for the next input to arrive.&lt;/p&gt;
&lt;p&gt;So let&amp;rsquo;s move forward with TCP, you&amp;rsquo;ve disabled &lt;a href=&#34;http://en.wikipedia.org/wiki/Nagle&#39;s_algorithm&#34;&gt;Nagle&amp;rsquo;s Algorithm&lt;/a&gt;, and you&amp;rsquo;re sending inputs from the left to the right simulation once per-frame (60 times per-second).&lt;/p&gt;
&lt;p&gt;Here it gets a little complicated. Since we can&amp;rsquo;t simulate forward unless we have the input for the next frame, it&amp;rsquo;s not enough to just take whatever inputs arrive over the network and then run the simulation on inputs as they arrive because the result would be very jittery. Data sent across the network at 60HZ doesn&amp;rsquo;t typically arrive nicely spaced, 1/60th of a second between each packet.&lt;/p&gt;
&lt;p&gt;If you want this sort of behavior, you have to implement it yourself.&lt;/p&gt;
&lt;h2 id=&#34;playout-delay-buffer&#34;&gt;Playout Delay Buffer&lt;/h2&gt;
&lt;p&gt;Such a device is called a playout delay buffer.&lt;/p&gt;
&lt;p&gt;Unfortunately, the subject of playout delay buffers is a patent minefield. I would not advise searching for &amp;ldquo;playout delay buffer&amp;rdquo; or &amp;ldquo;adaptive playout delay&amp;rdquo; while at work. But in short, what you want to do is buffer packets for a short amount of time so they &lt;em&gt;appear&lt;/em&gt; to be arriving at a steady rate even though in reality they arrive somewhat jittered.&lt;/p&gt;
&lt;p&gt;What you&amp;rsquo;re doing here is similar to what Netflix does when you stream a video. You pause a little bit initially so you have a buffer in case some packets arrive late and then once the delay has elapsed video frames are presented spaced the correct time apart. If your buffer isn&amp;rsquo;t large enough then the video playback will be hitchy. With deterministic lockstep your simulation behaves exactly the same way: showing hitches when the buffer isn&amp;rsquo;t large enough to smooth out the jitter. Of course, the cost of increasing the buffer size is additional latency, so you can&amp;rsquo;t just buffer your way out of all problems. At some point the user says enough! That&amp;rsquo;s too much latency added. No sir, I will &lt;em&gt;not&lt;/em&gt; play your game with 1 second of extra delay :)&lt;/p&gt;
&lt;p&gt;My playout delay buffer implementation is really simple. You add inputs to it indexed by frame, and when the very first input is received, it stores the current local time on the receiver machine and from that point on delivers packets assuming they should play at that time + 100ms. You&amp;rsquo;ll likely need to something more complex for a real world situation, perhaps something that handles clock drift, and detecting when the simulation should slightly speed up or slow down to maintain a nice amount of buffering safety (being &amp;ldquo;adaptive&amp;rdquo;) while minimizing overall latency, but this is reasonably complicated and probably worth an article in itself.&lt;/p&gt;
&lt;p&gt;The goal is that under average conditions the playout delay buffer provides a steady stream of inputs for frame n, n+1, n+2 and so on, nicely spaced 1/60th of a second apart with no drama. In the worst case the time arrives for frame n and the input hasn&amp;rsquo;t arrived yet it returns null and the simulation is forced to wait. If packets get bunched up and delivered late, it&amp;rsquo;s possibly to have multiple inputs ready to dequeue per-frame. In this case I limit to 4 simulated frames per-render frame so the simulation has a chance to catch up, but doesn&amp;rsquo;t simulate for so long that it falls further behind, aka. the &amp;ldquo;spiral of death&amp;rdquo;.&lt;/p&gt;
&lt;h2 id=&#34;is-tcp-good-enough&#34;&gt;Is TCP good enough?&lt;/h2&gt;
&lt;p&gt;Using this playout buffer strategy and sending inputs across TCP we ensure that all inputs arrive reliably and in-order. This is convenient, and after all, TCP is designed for exactly this situation: reliable-ordered data.&lt;/p&gt;
&lt;p&gt;In fact, It&amp;rsquo;s a common thing out there on the Internet for pundits to say stuff like:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;http://www.reddit.com/r/gamedev/comments/1tvbe0/is_it_just_me_or_is_networking_really_hard/&#34;&gt;If you need reliable-ordered, you can&amp;rsquo;t do better than TCP!&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://thoughtstreams.io/glyph/your-game-doesnt-need-udp-yet/&#34;&gt;Your game doesn&amp;rsquo;t need UDP (yet)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;But I&amp;rsquo;m here to tell you this kind of thinking is &lt;strong&gt;dead wrong&lt;/strong&gt;.&lt;/p&gt;
&lt;video autoplay preload=&#34;auto&#34; loop=&#34;true&#34; width=&#34;100%&#34;&gt;
&lt;source src=&#34;http://gafferongames.com/videos/deterministic_lockstep_tcp_100ms_1pc.mp4&#34; type=&#34;video/mp4&#34;/&gt;
&lt;source src=&#34;http://gafferongames.com/videos/deterministic_lockstep_tcp_100ms_1pc.webm&#34; type=&#34;video/webm&#34;/&gt;
&lt;/video&gt;
&lt;p&gt;Above you can see the simulation networked using deterministic lockstep over TCP at 100ms latency and 1% packet loss. If you look closely on the right side you can see hitches every few seconds. What&amp;rsquo;s happening here is that each time a packet is lost, TCP has to wait RTT*2 while it is resent (actually it can be much worse, but I&amp;rsquo;m being generous&amp;hellip;). The hitches happen because with deterministic lockstep the right simulation can&amp;rsquo;t simulate frame n without input n, so it has to pause to wait for input n to be resent!&lt;/p&gt;
&lt;p&gt;That&amp;rsquo;s not all. It gets significantly worse as latency and packet loss increase. Here is the same simulation networked using deterministic lockstep over TCP at 250ms latency and 5% packet loss:&lt;/p&gt;
&lt;video autoplay preload=&#34;auto&#34; loop=&#34;true&#34; width=&#34;100%&#34;&gt;
  &lt;source src=&#34;http://gafferongames.com/videos/deterministic_lockstep_tcp_250ms_5pc.mp4&#34; type=&#34;video/mp4&#34;/&gt;
  &lt;source src=&#34;http://gafferongames.com/videos/deterministic_lockstep_tcp_250ms_5pc.webm&#34; type=&#34;video/webm&#34;/&gt;
&lt;/video&gt;
&lt;p&gt;Now I will concede that if you have no packet loss and/or a very small amount of latency then you very well may get acceptable results with TCP. But please be aware that if you use TCP it behaves &lt;em&gt;terribly&lt;/em&gt; under bad network conditions.&lt;/p&gt;
&lt;h2 id=&#34;can-we-do-better-than-tcp&#34;&gt;Can we do better than TCP?&lt;/h2&gt;
&lt;p&gt;Can we beat TCP at its own game. Reliable-ordered delivery?&lt;/p&gt;
&lt;p&gt;The answer is an emphatic &lt;b&gt;YES&lt;/b&gt;. But &lt;em&gt;only&lt;/em&gt; if we change the rules of the game.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s the trick. We need to ensure that all inputs arrive reliably and in order. But if we send inputs in UDP packets, some of those packets will be lost. What if, instead of detecting packet loss after the fact and resending lost packets, we redundantly include &lt;em&gt;all inputs&lt;/em&gt; in each UDP packet until we know for sure the other side has received them?&lt;/p&gt;
&lt;p&gt;Inputs are very small (6 bits). Let&amp;rsquo;s say we&amp;rsquo;re sending 60 inputs per-second (60fps simulation) and round trip time we know is going the be somewhere in 30-250ms range. Let&amp;rsquo;s say just for fun that it could be up to 2 seconds worst case and at this point we&amp;rsquo;ll time out the connection (screw that guy). This means that on average we only need to include between 2-15 frames of input and worst case we&amp;rsquo;ll need 120 inputs. Worst case is 120*6 = 720 bits. That&amp;rsquo;s only 90 bytes of input! That&amp;rsquo;s totally reasonable.&lt;/p&gt;
&lt;p&gt;We can do even better. It&amp;rsquo;s not common for inputs to change every frame. What if when we send our packet instead we start with the sequence number of the most recent input, and the 6 bits of the first (oldest) input, and the number of un-acked inputs. Then as we iterate across these inputs to write them to the packet we can write a single bit (1) if the next input is different to the previous, and (0) if the input is the same. So if the input is different from the previous frame we write 7 bits (rare). If the input is identical we write just one (common). Where inputs change infrequently this is a big win and in the worst case this really isn&amp;rsquo;t that bad. 120 bits of extra data sent. Just 15 bytes overhead worst case.&lt;/p&gt;
&lt;p&gt;Of course another packet is required from the right simulation to the left so the left side knows which inputs have been received. Each frame the right simulation reads input packets from the network before adding them to the playout delay buffer and keeps track of the most recent input it has received and sends this back to the left as an &amp;ldquo;ack&amp;rdquo; or acknowledgment for inputs.&lt;/p&gt;
&lt;p&gt;When the left side receives this ack it discards any inputs older than the most recent received input. This way we have only a small number of inputs in flight proportional to the round trip time between the two simulations.&lt;/p&gt;
&lt;h2 id=&#34;flawless-victory&#34;&gt;Flawless Victory&lt;/h2&gt;
&lt;p&gt;We have beaten TCP by changing the rules of the game.&lt;/p&gt;
&lt;p&gt;Instead of &amp;ldquo;implementing 95% of TCP on top of UDP&amp;rdquo; we have implemented something &lt;em&gt;totally different&lt;/em&gt; and better suited to our requirements. A protocol that redundantly sends inputs because we know they are small, so we never have to wait for retransmission.&lt;/p&gt;
&lt;p&gt;So exactly how much better is this approach than sending inputs over TCP?&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s take a look&amp;hellip;&lt;/p&gt;
&lt;video autoplay preload=&#34;auto&#34; loop=&#34;true&#34; width=&#34;100%&#34;&gt;
  &lt;source src=&#34;http://gafferongames.com/videos/deterministic_lockstep_udp_2sec_25pc.mp4&#34; type=&#34;video/mp4&#34;/&gt;
  &lt;source src=&#34;http://gafferongames.com/videos/deterministic_lockstep_udp_2sec_25pc.webm&#34; type=&#34;video/webm&#34;/&gt;
&lt;/video&gt;
&lt;p&gt;The video above shows deterministic lockstep synchronized over UDP using this technique with &lt;strong&gt;2 seconds&lt;/strong&gt; of latency and &lt;strong&gt;25% packet loss&lt;/strong&gt;. Imagine how awful TCP would look under these conditions.&lt;/p&gt;
&lt;p&gt;So in conclusion, even where TCP should have the most advantage, in the only networking model that relies on reliable-ordered data, we can still easily whip its ass with a simple protocol built on top of UDP.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NEXT ARTICLE:&lt;/strong&gt; &lt;a href=&#34;https://gafferongames.com/post/snapshot_interpolation/&#34;&gt;Snapshot Interpolation&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Glenn Fiedler&lt;/strong&gt; is the founder and CEO of &lt;strong&gt;&lt;a href=&#34;https://networknext.com&#34;&gt;Network Next&lt;/a&gt;&lt;/strong&gt;.&lt;br&gt;&lt;i&gt;Network Next is fixing the internet for games by creating a marketplace for premium network transit.&lt;/i&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to Networked Physics</title>
      <link>https://gafferongames.com/post/introduction_to_networked_physics/</link>
      <pubDate>Fri, 28 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>https://gafferongames.com/post/introduction_to_networked_physics/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Hi, I&amp;rsquo;m &lt;a href=&#34;https://gafferongames.com&#34;&gt;Glenn Fiedler&lt;/a&gt; and welcome to the first article in &lt;strong&gt;&lt;a href=&#34;https://gafferongames.com/categories/networked-physics/&#34;&gt;Networked Physics&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In this article series we&amp;rsquo;re going to network a physics simulation three different ways: deterministic lockstep, snapshot interpolation and state synchronization.&lt;/p&gt;
&lt;p&gt;But before we get to this, let&amp;rsquo;s spend some time exploring the physics simulation weâre going to network in this article series:&lt;/p&gt;
&lt;video preload=&#34;auto&#34; autoplay=&#34;autoplay&#34; loop=&#34;loop&#34; width=&#34;100%&#34;&gt;
&lt;source src=&#34;http://gafferongames.com/videos/the_physics_simulation_cube.mp4&#34; type=&#34;video/mp4&#34; /&gt;
&lt;source src=&#34;http://gafferongames.com/videos/the_physics_simulation_cube.webm&#34; type=&#34;video/webm&#34; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;p&gt;Here Iâve setup a simple simulation of a cube in the open source physics engine &lt;a href=&#34;http://www.ode.org&#34;&gt;ODE&lt;/a&gt;. The player moves around by applying forces at its center of mass. The physics simulation takes this linear motion and calculates friction as the cube collides with the ground, inducing a rolling and tumbling motion.&lt;/p&gt;
&lt;p&gt;This is why I chose a cube instead a sphere. I &lt;em&gt;want&lt;/em&gt; this complex, unpredictable motion because rigid bodies in general move in interesting ways according to their shape.&lt;/p&gt;
&lt;h2 id=&#34;an-interactive-world&#34;&gt;An Interactive World&lt;/h2&gt;
&lt;p&gt;Networked physics get interesting when the player interacts with other physically simulated objects, &lt;em&gt;especially&lt;/em&gt; when those objects push back and affect the motion of the player.&lt;/p&gt;
&lt;p&gt;So let&amp;rsquo;s add some more cubes to the simulation:&lt;/p&gt;
&lt;video preload=&#34;auto&#34; autoplay=&#34;autoplay&#34; loop=&#34;loop&#34; width=&#34;100%&#34;&gt;
&lt;source src=&#34;http://gafferongames.com/videos/the_physics_simulation_cubes_roll.mp4&#34; type=&#34;video/mp4&#34; /&gt;
&lt;source src=&#34;http://gafferongames.com/videos/the_physics_simulation_cubes_roll.webm&#34; type=&#34;video/webm&#34; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;p&gt;When the player interacts with a cube it turns red. When that cube comes to rest it turns back to grey (non-interacting).&lt;/p&gt;
&lt;p&gt;While itâs cool to roll around and interact with other cubes, what I really wanted was a way to push &lt;em&gt;lots&lt;/em&gt; of cubes around. What I came up with is this:&lt;/p&gt;
&lt;video preload=&#34;auto&#34; autoplay=&#34;autoplay&#34; loop=&#34;loop&#34; width=&#34;100%&#34;&gt;
&lt;source src=&#34;http://gafferongames.com/videos/the_physics_simulation_cubes_blow.mp4&#34; type=&#34;video/mp4&#34; /&gt;
&lt;source src=&#34;http://gafferongames.com/videos/the_physics_simulation_cubes_blow.webm&#34; type=&#34;video/webm&#34; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;p&gt;As you can see, interactions arenât just direct. Red cubes pushed around by the player turn other cubes they touch red as well. This way, interactions fan out to cover all affected objects.&lt;/p&gt;
&lt;h2 id=&#34;a-complicated-case&#34;&gt;A Complicated Case&lt;/h2&gt;
&lt;p&gt;I also wanted a very complex coupled motion between the player and non-player cubes such they become one system: a group of rigid bodies joined together by constraints.&lt;/p&gt;
&lt;p&gt;To implement this I thought it would be cool if the player could roll around and create a ball of cubes, like in one of my favorite games &lt;a href=&#34;https://en.wikipedia.org/wiki/Katamari_Damacy&#34;&gt;Katamari Damacy&lt;/a&gt;.&lt;/p&gt;
&lt;video preload=&#34;auto&#34; autoplay=&#34;autoplay&#34; loop=&#34;loop&#34; width=&#34;100%&#34;&gt;
&lt;source src=&#34;http://gafferongames.com/videos/the_physics_simulation_cubes_katamari.mp4&#34; type=&#34;video/mp4&#34; /&gt;
&lt;source src=&#34;http://gafferongames.com/videos/the_physics_simulation_cubes_katamari.webm&#34; type=&#34;video/webm&#34; /&gt;
Your browser does not support the video tag.
&lt;/video&gt;
&lt;p&gt;Cubes within a certain distance of the player have a force applied towards the center of the cube. These cubes remain physically simulated while in the katamari ball, they are not just âstuckâ to the player like in the original game.&lt;/p&gt;
&lt;p&gt;This is a very difficult situation for networked physics!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NEXT ARTICLE:&lt;/strong&gt; &lt;a href=&#34;https://gafferongames.com/post/deterministic_lockstep/&#34;&gt;Deterministic Lockstep&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Glenn Fiedler&lt;/strong&gt; is the founder and CEO of &lt;strong&gt;&lt;a href=&#34;https://networknext.com&#34;&gt;Network Next&lt;/a&gt;&lt;/strong&gt;.&lt;br&gt;&lt;i&gt;Network Next is fixing the internet for games by creating a marketplace for premium network transit.&lt;/i&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Collision Response and Coulomb Friction</title>
      <link>https://gafferongames.com/post/collision_response_and_coulomb_friction/</link>
      <pubDate>Sun, 24 Feb 2013 00:00:00 +0000</pubDate>
      
      <guid>https://gafferongames.com/post/collision_response_and_coulomb_friction/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Hi, I&amp;rsquo;m &lt;a href=&#34;https://gafferongames.com&#34;&gt;Glenn Fiedler&lt;/a&gt;. Welcome to &lt;a href=&#34;https://gafferongames.com/categories/virtual-go/&#34;&gt;&lt;strong&gt;Virtual Go&lt;/strong&gt;&lt;/a&gt;, my project to create a physically accurate computer simulation of a Go board and stones.&lt;/p&gt;
&lt;p&gt;So far in this series, we have mathematically defined the go stone, rendered it, determined how it moves and rotates, and discussed how its shape affects how it responds to collisions.&lt;/p&gt;
&lt;p&gt;Now in this article we reach our first milestone:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;A go stone bouncing and coming to rest on the go board&lt;/strong&gt;.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/board-side-on-swirling-wood-grain.jpg&#34; alt=&#34;stones at rest on board&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;We&amp;rsquo;re going do this using a technique called &lt;a href=&#34;https://en.wikipedia.org/wiki/Collision_response#Impulse-Based_Contact_Model&#34;&gt;impulse-based collision response&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The concept is simple. To handle a collision we apply an impulse, an instantaneous change in momentum, at the point of impact to make the go stone bounce.&lt;/p&gt;
&lt;h2 id=&#34;linear-collision-response&#34;&gt;Linear Collision Response&lt;/h2&gt;
&lt;p&gt;We now pick up where we left off at the end of the &lt;a href=&#34;https://gafferongames.com/post/go_stone_vs_go_board/&#34;&gt;collision detection article&lt;/a&gt;.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/contact-point-linear.png&#34; alt=&#34;contact point linear&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;We have a contact point and a contact normal for the collision.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s start by calculating a collision response impulse without rotation.&lt;/p&gt;
&lt;p&gt;First, take the dot product of the linear momentum of the go stone with the contact normal. If this value is less than zero, it means the go stone is moving towards the go board, and we need to apply an impulse.&lt;/p&gt;
&lt;p&gt;To calculate the impulse we need the concept of &amp;rsquo;elasticity&amp;rsquo;. If the collision is perfectly elastic, the go stone bounces off the board without losing any energy:&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/linear-collision-response-elastic.png&#34; alt=&#34;linear collision response elastic&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;If the collision is inelastic then the go stone loses all its vertical motion post-collision and slides along the surface of the board:&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/linear-collision-response-inelastic.png&#34; alt=&#34;linear collision response inelastic&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;What we really want is something in between:&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/linear-collision-response-coefficient-of-restitution.png&#34; alt=&#34;linear collision response coefficient of restitution&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;To support this we introduce a new concept called the &amp;lsquo;coefficient of restitution&amp;rsquo;. When this value is 1 the collision is perfectly elastic, when it is 0 the collision is inelastic. At 0.5, it&amp;rsquo;s halfway between.&lt;/p&gt;
&lt;p&gt;This gives the following formula:&lt;/p&gt;
&lt;p&gt;[latex]j = -( 1 + e ) \boldsymbol{p} \cdot \boldsymbol{n}[/latex]&lt;/p&gt;
&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;j is the magnitude of the collision impulse&lt;/li&gt;
&lt;li&gt;e is the coefficient of restitution [0,1]&lt;/li&gt;
&lt;li&gt;p is the linear momentum of the go stone&lt;/li&gt;
&lt;li&gt;n in the contact normal for the collision&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that the direction of the collision impulse is &lt;u&gt;always&lt;/u&gt; along the contact normal, so to apply the impulse just multiply the contact normal by j and add it to the linear momentum vector.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s the code that does this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    void ApplyLinearCollisionImpulse( StaticContact &amp;amp; contact, float e )
    {
        float mass = contact.rigidBody-&amp;gt;mass;
        float d = dot( contact.rigidBody-&amp;gt;linearMomentum, contact.normal );
        float j = max( - ( 1 + e ) * d, 0 );
        contact.rigidBody-&amp;gt;linearMomentum += j * contact.normal;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And here&amp;rsquo;s the result:&lt;/p&gt;
&lt;div class=&#34;video_container&#34;&gt;
&lt;iframe src=&#34;//www.youtube.com/embed/kveh3fgPg6I&#34; 
frameborder=&#34;0&#34; allowfullscreen class=&#34;video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;p&gt;Now the stone is definitely bouncing, but in the real world stones don&amp;rsquo;t usually hit the board perfectly flat like this. In the common case, they hit at an angle and the collision makes the stone rotate.&lt;/p&gt;
&lt;h2 id=&#34;collision-response-with-rotation&#34;&gt;Collision Response With Rotation&lt;/h2&gt;
&lt;p&gt;To capture this effect we need to calculate collision response with rotation.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/collision-response-rotation.png&#34; alt=&#34;collision response rotation&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;Above you can see the effect that we want. If a stone were to collide with the board like this, we know from experience that it would rotate in response.&lt;/p&gt;
&lt;p&gt;We start by calculating the velocity of the stone at the contact point, and take the dot product of this vs. the contact normal to check if the stone is moving towards the board. This is necessary because when the stone is rotating, different points on the stone have different velocities.&lt;/p&gt;
&lt;p&gt;Next, we apply a collision impulse along the contact normal with magnitude j except this impulse is applied at the contact point instead of the center of mass of the stone. This gives the collision response its rotational effect.&lt;/p&gt;
&lt;p&gt;Here is the general equation for the magnitude of this collision impulse.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/impulse-j-general-case.png&#34; alt=&#34;impulse j general case&#34; width=&#34;75%&#34;/&gt;
&lt;p&gt;You can find a derivation of this result on &lt;a href=&#34;https://en.wikipedia.org/wiki/Collision_response#Impulse-Based_Reaction_Model&#34;&gt;wikipedia&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Understandably this is quite complex, but in our case the go board never moves, so we can simplify the equation by assigning zero velocity and infinite mass to the second body. This leads to the following, simpler equation:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;todo: need a solution to convert across all the latex equations&amp;hellip;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;[latex]j = \dfrac{ -( 1 + e ) \boldsymbol{v} \cdot \boldsymbol{n} } { m^{-1} + ( \boldsymbol{I^{-1}} ( \boldsymbol{r} \times \boldsymbol{n} ) \times \boldsymbol{r} ) \cdot \boldsymbol{n} }[/latex]&lt;/p&gt;
&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;j is the magnitude of the collision impulse&lt;/li&gt;
&lt;li&gt;e is the coefficient of restitution [0,1]&lt;/li&gt;
&lt;li&gt;n in the contact normal for the collision&lt;/li&gt;
&lt;li&gt;v is the the go stone velocity at the contact point&lt;/li&gt;
&lt;li&gt;r is the contact point minus the center of the go stone&lt;/li&gt;
&lt;li&gt;I is the inertia tensor of the go stone&lt;/li&gt;
&lt;li&gt;m is the mass of the go stone&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here is the result of our collision response with rotational effects:&lt;/p&gt;
&lt;div class=&#34;video_container&#34;&gt;
&lt;iframe src=&#34;//www.youtube.com/embed/SCckKzO_280&#34; 
frameborder=&#34;0&#34; allowfullscreen class=&#34;video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;p&gt;As you can see, collision response working properly and induces rotation when the go stone hits the board at an angle. It is also able to handle the stone hitting the board while rotating.&lt;/p&gt;
&lt;h2 id=&#34;coulomb-friction&#34;&gt;Coulomb Friction&lt;/h2&gt;
&lt;p&gt;We don&amp;rsquo;t often get to see friction-less collisions in the real world so the video above looks a bit strange. To get realistic behavior out of the go stone, we need to add friction.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ll model sliding friction using the Coulomb friction model.&lt;/p&gt;
&lt;p&gt;In this model, the friction impulse is proportional the magnitude of the normal impulse j and is limited by a friction cone defined by the coefficient of friction u:&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/coulomb-friction-model.png&#34; alt=&#34;coulomb friction model&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;Lower friction coefficient values mean less friction, higher values mean more friction. Typical values for the coefficient of friction are in the range [0,1].&lt;/p&gt;
&lt;p&gt;Calculation of the Coulomb friction impulse is performed much like the calculation of the normal impulse except this time the impulse is in the tangent direction against the direction of sliding.&lt;/p&gt;
&lt;p&gt;Here is the formula for calculating the magnitude of the friction impulse:&lt;/p&gt;
&lt;p&gt;[latex]j_t = \dfrac{ - \boldsymbol{v} \cdot \boldsymbol{t} } { m^{-1} + ( \boldsymbol{I^{-1}} ( \boldsymbol{r} \times \boldsymbol{t} ) \times \boldsymbol{r} ) \cdot \boldsymbol{t} }[/latex]&lt;/p&gt;
&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;j&lt;sub&gt;t&lt;/sub&gt; is the magnitude of the friction impulse (pre-cone limit)&lt;/li&gt;
&lt;li&gt;u is the coefficient of friction [0,1]&lt;/li&gt;
&lt;li&gt;t in the tangent vector in the direction of sliding&lt;/li&gt;
&lt;li&gt;v is the the go stone velocity at the contact point&lt;/li&gt;
&lt;li&gt;r is the contact point minus the center of the go stone&lt;/li&gt;
&lt;li&gt;I is the inertia tensor of the go stone&lt;/li&gt;
&lt;li&gt;m is the mass of the go stone&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Which gives the following result:&lt;/p&gt;
&lt;div class=&#34;video_container&#34;&gt;
&lt;iframe src=&#34;//www.youtube.com/embed/XXMBHkjPdzM&#34; 
frameborder=&#34;0&#34; allowfullscreen class=&#34;video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;p&gt;Which looks much more realistic!&lt;/p&gt;
&lt;h2 id=&#34;rolling-friction&#34;&gt;Rolling Friction&lt;/h2&gt;
&lt;p&gt;Due to its shape (and the inertia tensor from the previous article), the go stone really prefers to rotate about axes on the xz plane instead of around the y axis.&lt;/p&gt;
&lt;p&gt;I was able to reproduct this effect in the simulation. Adding a torque that spins go stone around the y axis made it stand up and spin like a coin:&lt;/p&gt;
&lt;div class=&#34;video_container&#34;&gt;
&lt;iframe src=&#34;//www.youtube.com/embed/bF6kHscHbyw&#34; 
frameborder=&#34;0&#34; allowfullscreen class=&#34;video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;p&gt;This is pretty cool and is totally emergent from the shape of the go stone. The only problem is that it spins like this &lt;u&gt;forever&lt;/u&gt;.&lt;/p&gt;
&lt;p&gt;Why is it spinning for so long? Shouldn&amp;rsquo;t coulomb friction handle this for us?&lt;/p&gt;
&lt;p&gt;No. Coulomb friction only handles friction when the two surfaces are sliding relative to each other. Here at the point of contact, the stone is spinning about that point, not sliding, so from coulomb friction point of view, the contact point is stationary and no friction is applied.&lt;/p&gt;
&lt;p&gt;It turns out that sliding friction is just one type of friction and there are &lt;a href=&#34;https://en.wikipedia.org/wiki/Friction&#34;&gt;many others&lt;/a&gt;. What we have in this case is a combination of rolling and spinning friction.&lt;/p&gt;
&lt;p&gt;I had very little patience at this point so I came up with my own hack approximation of spinning and rolling friction that gives me the result that I want: vibrant motion at high energies but slightly damped so the stone slows down, collapses from spinning, wobbles a bit and then come to rest.&lt;/p&gt;
&lt;p&gt;My hack was to apply exponential decay (eg. linearVelocity *= factor [0.9990-0.9999] each frame) to linear and angular velocity. The decay factor was linear interpolated between two key speeds such that there was more damping at low speeds and much less at high speeds. There is no physical basis for this, it&amp;rsquo;s just a hack to get the behavior I want.&lt;/p&gt;
&lt;p&gt;With a bit of tuning, it seems to work reasonably well:&lt;/p&gt;
&lt;div class=&#34;video_container&#34;&gt;
&lt;iframe src=&#34;//www.youtube.com/embed/1eG2xTubRJY&#34; 
frameborder=&#34;0&#34; allowfullscreen class=&#34;video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Glenn Fiedler&lt;/strong&gt; is the founder and CEO of &lt;strong&gt;&lt;a href=&#34;https://networknext.com&#34;&gt;Network Next&lt;/a&gt;&lt;/strong&gt;.&lt;br&gt;&lt;i&gt;Network Next is fixing the internet for games by creating a marketplace for premium network transit.&lt;/i&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Rotation &amp; Inertia Tensors</title>
      <link>https://gafferongames.com/post/rotation_and_inertia_tensors/</link>
      <pubDate>Sat, 23 Feb 2013 00:00:00 +0000</pubDate>
      
      <guid>https://gafferongames.com/post/rotation_and_inertia_tensors/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Hi, I&amp;rsquo;m &lt;a href=&#34;https://gafferongames.com&#34;&gt;Glenn Fiedler&lt;/a&gt;. Welcome to &lt;a href=&#34;https://gafferongames.com/categories/virtual-go/&#34;&gt;&lt;strong&gt;Virtual Go&lt;/strong&gt;&lt;/a&gt;, my project to create a physically accurate computer simulation of a Go board and stones.&lt;/p&gt;
&lt;p&gt;In the &lt;a href=&#34;https://gafferongames.com/post/go_stone_vs_go_board/&#34;&gt;previous article&lt;/a&gt; we detected collision between the go stone and the go board. Now we&amp;rsquo;re working up to calculating collision response so the stone bounces and wobbles before coming to rest on the board.&lt;/p&gt;
&lt;p&gt;But in order to reach this goal we first need to lay some groundwork. It turns out that irregularly shaped objects, like go stones, are easier to rotate about some axes than others and this has a large effect on how they react to collisions.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/placing-a-stone-on-the-board.jpg&#34; alt=&#34;placing a stone on the board&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;This is the reason go stones wobble in such an interesting way when placed on the go board, and why thick go stones wobble differently to thin ones.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s study this effect so we can reproduce it in Virtual Go.&lt;/p&gt;
&lt;h2 id=&#34;rotation-in-3d&#34;&gt;Rotation in 3D&lt;/h2&gt;
&lt;p&gt;Consider the following case in two dimensions:&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/rotation-in-2d.png&#34; alt=&#34;rotation in 2d&#34; width=&#34;75%&#34;/&gt;
&lt;p&gt;It&amp;rsquo;s easy because there is only one possible axis for rotation around the center of mass: clockwise or counter-clockwise.&lt;/p&gt;
&lt;p&gt;It follows that we can represent the orientation of an object in 2D around its center of mass with a single theta value, angular velocity with a scalar radians per-second, and a scalar &amp;lsquo;moment of inertia&amp;rsquo; that works just like an angular equivalent of mass: how hard it is to rotate that object.&lt;/p&gt;
&lt;p&gt;But when we move to three dimensions suddenly rotation can occur about any axis. Orientation becomes a quaternion, angular velocity a vector, and now for irregular shaped objects like go stones, we need a way to indicate that certain axes of rotation are easier to rotate about than others.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/rotation-in-3d.png&#34; alt=&#34;rotation in 3d&#34; width=&#34;75%&#34;/&gt;
&lt;p&gt;But how can we represent an angular mass that depends on the shape of the object and the axis of rotation?&lt;/p&gt;
&lt;h2&gt;Inertia Tensor&lt;/h2&gt;
&lt;p&gt;The solution is to use an &lt;a href=&#34;https://en.wikipedia.org/wiki/Moment_of_inertia#Moment_of_inertia_tensor&#34;&gt;inertia tensor&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;An inertia tensor is a 3x3 matrix with different rules to a normal matrix. It rotates and translates differently, but otherwise behaves like a 3x3 matrix and is used to transform angular velocity to angular momentum, and the inverse of the inertia tensor transforms angular momentum to angular velocity.&lt;/p&gt;
&lt;p&gt;Now this becomes quite interesting because Newton&amp;rsquo;s laws guarantee that in a perfectly elastic collision angular momentum is conserved but angular velocity is not necessarily.&lt;/p&gt;
&lt;p&gt;Why is this? Because angular velocity now depends on the axis of rotation, so even if the angular momentum has exactly the same magnitude post-collision the angular velocity can be different if the axis of rotation changes and the inertia tensor is non-uniform.&lt;/p&gt;
&lt;p&gt;Because of this we&amp;rsquo;ll switch to angular momentum as the primary quantity in our physics simulation and we&amp;rsquo;ll derive angular velocity from it. For consistency we&amp;rsquo;ll also switch from linear velocity to linear momentum.&lt;/p&gt;
&lt;h2 id=&#34;calculating-the-inertia-tensor&#34;&gt;Calculating The Inertia Tensor&lt;/h2&gt;
&lt;p&gt;Now we need a way to calculate the inertia tensor of our go stone.&lt;/p&gt;
&lt;p&gt;The general case is quite complicated because inertia tensors are capable of representing shapes that are non-symmetrical about the axis of rotation.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;todo: yes, need to sort out the latex equations&amp;hellip;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;[latex]I = \begin{bmatrix} I_{xx} &amp;amp; I_{xy} &amp;amp; I_{xz} \ I_{yx} &amp;amp; I_{yy} &amp;amp; I_{yz} \ I_{zx} &amp;amp; I_{zy} &amp;amp; I_{zz} \end{bmatrix}[/latex]&lt;/p&gt;
&lt;p&gt;For example, think of an oddly shaped object attached to a drill bit off-center and wobbling about crazily as the drill spins. Fantastic. But the good news is that we get to dodge this bullet because we are always rotating about the center of mass of the go stone, our inertia tensor is much simpler:&lt;/p&gt;
&lt;p&gt;[latex]I = \begin{bmatrix} I_{x} &amp;amp; 0 &amp;amp; 0 \ 0 &amp;amp; I_{y} &amp;amp; 0 \ 0 &amp;amp; 0 &amp;amp; I_{z} \end{bmatrix}[/latex]&lt;/p&gt;
&lt;p&gt;All we need to do in our case is to determine the I&lt;sub&gt;x&lt;/sub&gt;, I&lt;sub&gt;y&lt;/sub&gt; and I&lt;sub&gt;z&lt;/sub&gt; values.&lt;/p&gt;
&lt;p&gt;They represent how difficult it is to rotate the go stone about the x,y and z axes.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/inertia-tensor-ix.png&#34; alt=&#34;inertia tensor x&#34; width=&#34;100%&#34;/&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/inertia-tensor-iy.png&#34; alt=&#34;inertia tensor y&#34; width=&#34;100%&#34;/&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/inertia-tensor-iz.png&#34; alt=&#34;inertia tensor z&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;Interestingly, due to symmetry of the go stone, all axes on the xz plane are identical. So really, we only need to calculate I&lt;sub&gt;x&lt;/sub&gt; and I&lt;sub&gt;y&lt;/sub&gt; because I&lt;sub&gt;z&lt;/sub&gt; = I&lt;sub&gt;x&lt;/sub&gt;.&lt;/p&gt;
&lt;h2 id=&#34;numerical-integration&#34;&gt;Numerical Integration&lt;/h2&gt;
&lt;p&gt;Let&amp;rsquo;s first calculate the inertia tensor via numerical integration.&lt;/p&gt;
&lt;p&gt;To do this we just need to know is how difficult it is rotate a point about an axis.&lt;/p&gt;
&lt;p&gt;Once we know this we can approximate the moment of inertia of a go stone by breaking it up into a discrete number of points and summing up the moments of inertia of all these points.&lt;/p&gt;
&lt;p&gt;It turns out that the difficulty of rotating a point mass about an axis is proportional to the &lt;em&gt;square&lt;/em&gt; of the distance of that point from the axis and the mass of the point. [latex]I = mr^2[/latex]. This is quite interesting because it indicates that the distribution of mass has a significant effect on how difficult it is to rotate an object about an axis.&lt;/p&gt;
&lt;p&gt;One consequence of this is that a hollow pipe is actually more difficult to rotate than a solid pipe of the same mass. Of course, this is not something we deal with in real life often, because a solid pipe of the same material would be much heavier, and therefore harder to rotate due to increased mass, but if you could find a second material of lower density such that the solid pipe was exactly the same mass as the hollow pipe, you would be able to observe this effect. Obscure.&lt;/p&gt;
&lt;p&gt;In our case we know the go stone is solid not hollow, and we can go one step further and assume that the go stone has completely uniform density throughout. This means if we know the mass of the go stone we can divide it by the volume of the go stone to find its density. Then we can divide space around the go stone into a grid, and using this density we can assign a mass to each point in the grid proportional to the density of the go stone.&lt;/p&gt;
&lt;p&gt;Now integration is just a triple for loop summing up the moments of inertia for points that are inside the go stone. This gives us an approximation of the inertia tensor for the go stone that becomes more accurate the more points we use.&lt;/p&gt;
&lt;h2 id=&#34;interpreting-the-inertia-tensor&#34;&gt;Interpreting The Inertia Tensor&lt;/h2&gt;
&lt;p&gt;A size 33 japanese go stone has width 22mm and height 9.2mm:&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/clam-shell-stone-size-33.jpg&#34; alt=&#34;size 33 go stone&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;Using our point-based approximation to calculate its inertia tensor gives the following result:&lt;/p&gt;
&lt;p&gt;[latex]I = \begin{bmatrix} 0.177721 &amp;amp; 0 &amp;amp; 0 \ 0 &amp;amp; 0.304776 &amp;amp; 0 \ 0 &amp;amp; 0 &amp;amp; 0.177721 \end{bmatrix}[/latex]&lt;/p&gt;
&lt;p&gt;As expected, I&lt;sub&gt;x&lt;/sub&gt; = I&lt;sub&gt;z&lt;/sub&gt; due to the symmetry of the go stone.&lt;/p&gt;
&lt;p&gt;The inertia tensor indicates that its much harder to rotate the go stone about the y axis than axes on the xz plane.&lt;/p&gt;
&lt;p&gt;Why is this?&lt;/p&gt;
&lt;p&gt;You can see looking top-down at the go stone when rotating about the y axis a ring of mass around the edge of the stone is multiplied by a large r&lt;sup&gt;2&lt;/sup&gt; and is therefore difficult to rotate.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/top-down-y-rotation.png&#34; alt=&#34;top down y rotation&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;Contrast this with the rotation about the z axis, which has a much smaller portion of mass far away from the axis:&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/top-down-z-rotation.png&#34; alt=&#34;top down z rotation&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;As you can see the distribution of mass around the axis tends to dominate the inertia tensor due to the r&lt;sup&gt;2&lt;/sup&gt; term. The same mass, twice the distance from the axis, is four times more difficult to rotate!&lt;/p&gt;
&lt;h2&gt;Closed Form Solution&lt;/h2&gt;
&lt;p&gt;Exact equations are known for the moments of inertia of many &lt;a href=&#34;http://www.livephysics.com/physical-constants/mechanics-pc/moment-inertia-uniform-objects/&#34;&gt;common objects&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;With a bit of math we can calculate closed form solutions for the moments of inertia of a go stone.&lt;/p&gt;
&lt;p&gt;To determine the exact equation for I&lt;sub&gt;y&lt;/sub&gt; we start with the moment of inertia for a solid disc:&lt;/p&gt;
&lt;p&gt;[latex]I = 1/2mr^2[/latex]&lt;/p&gt;
&lt;p&gt;Then we integrate again, effectively summing up the moments of inertia of an infinite number of thin discs making up the top half of the go stone.&lt;/p&gt;
&lt;p&gt;This leads to the following integral:&lt;/p&gt;
&lt;p&gt;[latex]\int_0^{h/2} (r^2-(y+r-h/2)^2)^2,dy[/latex]&lt;/p&gt;
&lt;p&gt;With a little help from &lt;a href=&#34;http://wolframalpha.com&#34;&gt;Wolfram Alpha&lt;/a&gt; we get the following result:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    float CalculateIy( const Biconvex &amp;amp; biconvex )
    {
        const float h = height;
        const float r = biconvex.GetSphereRadius();
        const float h2 = h * h;
        const float h3 = h2 * h;
        const float h4 = h3 * h;
        const float h5 = h4 * h;
        const float r2 = r * r;
        const float r3 = r2 * r;
        const float r4 = r3 * r;
        return pi * p * 
            ( 1/480.0f * h3 * 
              ( 3*h2 - 30*h*r + 80*r2 ) );
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Plugging in the values for a size 33 stone, we get 0.303588 which is close to the approximate solution 0.304776.&lt;/p&gt;
&lt;p&gt;Verifying exact solutions against numeric ones is a fantastic way to check your calculations.&lt;/p&gt;
&lt;p&gt;Can &lt;u&gt;you&lt;/u&gt; derive the equation for I&lt;sub&gt;x&lt;/sub&gt;?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NEXT ARTICLE:&lt;/strong&gt; &lt;a href=&#34;https://gafferongames.com/post/collision_response_and_coulomb_friction/&#34;&gt;Collision Response and Coulomb Friction&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Glenn Fiedler&lt;/strong&gt; is the founder and CEO of &lt;strong&gt;&lt;a href=&#34;https://networknext.com&#34;&gt;Network Next&lt;/a&gt;&lt;/strong&gt;.&lt;br&gt;&lt;i&gt;Network Next is fixing the internet for games by creating a marketplace for premium network transit.&lt;/i&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Go Stone vs. Go Board</title>
      <link>https://gafferongames.com/post/go_stone_vs_go_board/</link>
      <pubDate>Fri, 22 Feb 2013 00:00:00 +0000</pubDate>
      
      <guid>https://gafferongames.com/post/go_stone_vs_go_board/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Hi, I&amp;rsquo;m &lt;a href=&#34;https://gafferongames.com&#34;&gt;Glenn Fiedler&lt;/a&gt;. Welcome to &lt;a href=&#34;https://gafferongames.com/categories/virtual-go/&#34;&gt;&lt;strong&gt;Virtual Go&lt;/strong&gt;&lt;/a&gt;, my project to create a physically accurate computer simulation of a Go board and stones.&lt;/p&gt;
&lt;p&gt;In this series so far we&amp;rsquo;ve defined the shape of a go stone, rendered it using 3D graphics hardware and simulated how it moves in three dimensions.&lt;/p&gt;
&lt;p&gt;Our next goal is for the go stone to bounce and come to rest on the go board.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/corner-with-slate-and-shell-stones.jpg&#34; alt=&#34;slate and shell go stones&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;Understandably, this is quite complicated, so in this article we&amp;rsquo;ll focus on the first step: detecting collisions between a go stone and the go board.&lt;/p&gt;
&lt;h2 id=&#34;voronoi-regions-and-the-minkowski-difference&#34;&gt;Voronoi Regions and The Minkowski Difference&lt;/h2&gt;
&lt;p&gt;First, lets assume that the go board is axis aligned and does not move.&lt;/p&gt;
&lt;p&gt;Next, because go stones are small relative to the go board, we can break down collision detection into regions which are treated differently.&lt;/p&gt;
&lt;p&gt;The common case is with the primary surface, the actual playing surface of the go board, so lets start by looking top-down at the go board and breaking it up into 2D voronoi regions.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/voronoi-regions.png&#34; alt=&#34;voronoi regions&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;Each voronoi region corresponds to a subspace where all points (x,z) in that region map to the same nearest feature on the go board. This gives us one region that maps points to the top surface of the go board, four regions that map to the sides, and four corner regions.&lt;/p&gt;
&lt;p&gt;If we were testing an infinitely small point against the go board, this would be enough, but we are colliding a go stone of a certain width and height.&lt;/p&gt;
&lt;p&gt;One simple way to incorporate the dimensions of the go stone is to offset the regions from the edge of the go board by the the go stone&amp;rsquo;s bounding sphere radius.&lt;/p&gt;
&lt;p&gt;This creates something like a poor man&amp;rsquo;s version of a minkowski difference:&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/minkowski-difference.png&#34; alt=&#34;minkowski difference&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;We can now test the center of the go stone against these regions to quickly to categorize the type of &lt;i&gt;&lt;u&gt;potential&lt;/u&gt;&lt;/i&gt; collision.&lt;/p&gt;
&lt;h2 id=&#34;go-board-collision-cases&#34;&gt;Go Board Collision Cases&lt;/h2&gt;
&lt;p&gt;Although the go board has nine different regions there only three unique types:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Primary&lt;/li&gt;
&lt;li&gt;Edge&lt;/li&gt;
&lt;li&gt;Corner&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Primary is the common case.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/board-primary-case.png&#34; alt=&#34;primary collision&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;It&amp;rsquo;s also the easiest to handle. The only possible collision is between the stone and the playing surface of the go board.&lt;/p&gt;
&lt;p&gt;Since the go board rests on the floor and cannot move we do not need to worry about collisions with the bottom surface. This means that we can consider the go board to be infinitely thick. This is extremely useful because it removes the possibility of fast moving go stones tunneling vertically through the board.&lt;/p&gt;
&lt;p&gt;Next is the edge case. This is more complicated because there is more than one way to collide in edge regions. Tests must be done between the go stone and the top plane, the side plane, and the side edge.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/board-side-case.png&#34; alt=&#34;side collision&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;The corner case is more complicated still. Potential collisions include the top plane, the two side planes, the side edges adjacent to the corner, the vertical corner edge, and the corner point.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/board-corner-case.png&#34; alt=&#34;corner collision&#34; width=&#34;100%&#34;/&gt;
&lt;h2 id=&#34;go-stone-collision-cases&#34;&gt;Go Stone Collision Cases&lt;/h2&gt;
&lt;p&gt;When a go stone collides with another object there are three collision cases.&lt;/p&gt;
&lt;p&gt;The first is a collision on the top surface of the biconvex. This corresponds to a collision with a portion of the &lt;u&gt;bottom&lt;/u&gt; sphere that generated the go stone.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/biconvex-collision-top.png&#34; alt=&#34;biconvex collision top&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;Next is the bottom surface of the biconvex. This corresponds to the &lt;u&gt;top&lt;/u&gt; sphere.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/biconvex-collision-bottom.png&#34; alt=&#34;biconvex collision bottom&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;Finally, the collision point can be on the circle ring at the intersection of the two sphere surfaces.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/biconvex-collision-side.png&#34; alt=&#34;biconvex collision side&#34; width=&#34;100%&#34;/&gt;
&lt;h2 id=&#34;separating-axis-test-sat&#34;&gt;Separating Axis Test (SAT)&lt;/h2&gt;
&lt;p&gt;We have 3 ways a stone can collide with any convex object, and 9 different regions that must be treated differently when testing vs. the go board. Within each region we have up to 7 different features on the go board that must be tested against 3 different features on the go stone.&lt;/p&gt;
&lt;p&gt;This is all rather complicated. How can we simplify it?&lt;/p&gt;
&lt;p&gt;The solution is to use the &lt;a href=&#34;https://gamedevelopment.tutsplus.com/tutorials/collision-detection-using-the-separating-axis-theorem--gamedev-169&#34;&gt;separating axis test&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The basic idea is that if we can find a plane that separates the stone and the board then they must not be colliding. This gives us a robust way of thinking about collision detection and makes testing for collision between objects more general and less prone to combinatorial explosion.&lt;/p&gt;
&lt;h2 id=&#34;calculating-the-support&#34;&gt;Calculating The Support&lt;/h2&gt;
&lt;p&gt;In order to use the separating axis test we must first write a function that determines the support of the go stone.&lt;/p&gt;
&lt;p&gt;The support is the projection of an object on to an axis. This can be difficult to think about in 3D, but for me it makes it easier to think of the axis not as a line, but as the normal of a plane.&lt;/p&gt;
&lt;p&gt;Then what we are really asking is: given this plane normal, what two planes from either side tightly bound the object like book-ends on a shelf?&lt;/p&gt;
&lt;p&gt;To calculate the support of a biconvex solid we must consider two cases.&lt;/p&gt;
&lt;p&gt;The first is when the go stone is vertical relative to the axis. Here it is reasonably easy. To calculate the support you simply calculate the intersection of the supports of the spheres used to generate the go stone. This makes a nice sort of intuitive sense seeing as the go stone is itself the intersection of two spheres.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/biconvex-support-1.png&#34; alt=&#34;biconvex support case 1&#34; width=&#34;75%&#34;/&gt;
&lt;p&gt;Unfortunately, this technique breaks down when the stone is horizontal relative to the axis because it fails to exclude the portion of the spheres that don&amp;rsquo;t contribute to the biconvex solid.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/biconvex-support-wrong.png&#34; alt=&#34;biconvex support wrong&#34; width=&#34;50%&#34;/&gt;
&lt;p&gt;What you need to do instead is to calculate the support of the circle edge.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/biconvex-support-correct.png&#34; alt=&#34;biconvex support correct&#34; width=&#34;50%&#34;/&gt;
&lt;p&gt;The tricky part is detecting when the transition between these two cases occur. Here&amp;rsquo;s a diagram I created a while back when I first tried to work this out. If you look closely you can see the exact point where my head exploded:&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/biconvex-support-head-explode.jpg&#34; alt=&#34;head explode&#34; width=&#34;75%&#34;/&gt;
&lt;p&gt;And here&amp;rsquo;s a visualization of the end result:&lt;/p&gt;
&lt;div class=&#34;video_container&#34;&gt;
&lt;iframe src=&#34;//www.youtube.com/embed/_fkLcJPJ6Wg&#34; 
frameborder=&#34;0&#34; allowfullscreen class=&#34;video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;p&gt;Now we are ready to continue with the SAT for detecting collisions.&lt;/p&gt;
&lt;h2 id=&#34;primary-case&#34;&gt;Primary Case&lt;/h2&gt;
&lt;p&gt;With this support we can use a one-sided variant of the SAT to detect collision with the primary surface. We&amp;rsquo;re doing one-sided because we&amp;rsquo;re treating the go board as &amp;lsquo;infinitely thick&amp;rsquo; to avoid tunneling in the common case.&lt;/p&gt;
&lt;p&gt;First, we take the normal of the primary surface which is (0,1,0) and find the support for the go stone using this normal as the axis: s&lt;sub&gt;1&lt;/sub&gt; and s&lt;sub&gt;2&lt;/sub&gt;.&lt;/p&gt;
&lt;p&gt;Next, we calculate the projection of the board surface along the normal: t&lt;/p&gt;
&lt;p&gt;Then, if s&lt;sub&gt;1&lt;/sub&gt; &amp;lt;= t then the go stone is colliding with the go board:&lt;/p&gt;
&lt;div class=&#34;video_container&#34;&gt;
&lt;iframe src=&#34;//www.youtube.com/embed/br3wVa0CIis&#34; 
frameborder=&#34;0&#34; allowfullscreen class=&#34;video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;p&gt;Unfortunately, we detect the collision after the go stone has already penetrated the go board. There are many solutions for this problem: &lt;a href=&#34;http://jitter-physics.com/wordpress/?tag=continuous-collision-detection&#34;&gt;continuous collision detection&lt;/a&gt;, and &lt;a href=&#34;http://jitter-physics.com/wordpress/?tag=continuous-collision-detection&#34;&gt;speculative contacts&lt;/a&gt; being interesting avenues I may explore later on.&lt;/p&gt;
&lt;p&gt;But for now I just do the simplest and most pragmatic thing I can think of.&lt;/p&gt;
&lt;p&gt;I just push the stone out of the board along the axis.&lt;/p&gt;
&lt;div class=&#34;video_container&#34;&gt;
&lt;iframe src=&#34;//www.youtube.com/embed/98YB1ZE9gfQ&#34; 
frameborder=&#34;0&#34; allowfullscreen class=&#34;video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;p&gt;After I push the stone out, I recalculate the nearest point between the stone and board and use this as the contact point.&lt;/p&gt;
&lt;h2 id=&#34;edge-and-corner-cases&#34;&gt;Edge and Corner Cases&lt;/h2&gt;
&lt;p&gt;The primary surface case is easy because only one axis needs to be tested, but in corner and edge regions multiple axes must be tested for collision.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/multiple-axes-SAT.png&#34; alt=&#34;multiple axis SAT&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;This is where the SAT really starts to shine. Now instead of combinatorial explosion testing each of the features of the go stone vs. each of the features on the go board, we flatten both the go stone and the go board into support and test for collision one axis at a time.&lt;/p&gt;
&lt;p&gt;The separating axis test as applied as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Test all features in the region and determine if there is any separating axis&lt;/li&gt;
&lt;li&gt;If a separating axis exists then the go stone is not colliding with the board&lt;/li&gt;
&lt;li&gt;Otherwise the stone must be colliding with the board&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If the stone is colliding we must now work out what direction to push the stone out. I thought about this for a while and tried to come up with a simple pattern that worked.&lt;/p&gt;
&lt;p&gt;First, I tried pushing the stone out along the axis with the greatest amount of penetration, but this breaks down pretty severely in the case where a go stone approaches the go board from the side:&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/multiple-axes-push-out-most-penetration.png&#34; alt=&#34;push out most penetration&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;Next, I thought that perhaps I could use the previous position of the go stone and try to determine the direction that the stone is approaching from. But then I thought about go stones that were rotating rapidly and how this wouldn&amp;rsquo;t always be correct. Then I started thinking about corner and edge cases, and the longer I thought the more this approach seemed too complicated, like I was trying to invent my own half-assed continuous collision detection method that would probably only work half the time and be almost impossible to test.&lt;/p&gt;
&lt;p&gt;In the end I settled on the simplest solution I could come up with: push the go stone out along the axis with the &lt;u&gt;least&lt;/u&gt; amount of penetration.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/multiple-axes-push-out-least-penetration.png&#34; alt=&#34;push out least penetration&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;This seems counter-intuitive at first, but it has some nice parallels with other physical laws. Nature is lazy and always takes the shortest path. Nature does the &lt;em&gt;least amount of work&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;We should probably do the same :)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NEXT ARTICLE:&lt;/strong&gt; &lt;a href=&#34;https://gafferongames.com/post/rotation_and_inertia_tensors/&#34;&gt;Rotation and Inertia Tensors&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Glenn Fiedler&lt;/strong&gt; is the founder and CEO of &lt;strong&gt;&lt;a href=&#34;https://networknext.com&#34;&gt;Network Next&lt;/a&gt;&lt;/strong&gt;.&lt;br&gt;&lt;i&gt;Network Next is fixing the internet for games by creating a marketplace for premium network transit.&lt;/i&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How The Go Stone Moves</title>
      <link>https://gafferongames.com/post/how_the_go_stone_moves/</link>
      <pubDate>Thu, 21 Feb 2013 00:00:00 +0000</pubDate>
      
      <guid>https://gafferongames.com/post/how_the_go_stone_moves/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Hi, I&amp;rsquo;m &lt;a href=&#34;https://gafferongames.com&#34;&gt;Glenn Fiedler&lt;/a&gt;. Welcome to &lt;a href=&#34;https://gafferongames.com/categories/virtual-go/&#34;&gt;&lt;strong&gt;Virtual Go&lt;/strong&gt;&lt;/a&gt;, my project to create a physically accurate computer simulation of a Go board and stones.&lt;/p&gt;
&lt;p&gt;In previous articles we mathematically defined the shape of a go stone and tessellated its shape so it can be drawn with 3D graphics hardware.&lt;/p&gt;
&lt;p&gt;Now we want to make the go stone move, obeying Newton&amp;rsquo;s laws of motion so the simulation is physically accurate. The stone should be accelerated by gravity and fall downwards. I also want the stone to rotate so it tumbles as it falls through the air.&lt;/p&gt;
&lt;h2 id=&#34;the-rigid-body-assumption&#34;&gt;The Rigid Body Assumption&lt;/h2&gt;
&lt;p&gt;Try biting down on a go stone and you&amp;rsquo;ll agree: go stones are very, very hard.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/slate-and-shell-corner-up-close.jpg&#34; alt=&#34;slate and shell go stones&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;Golf balls are pretty hard too, but if you look at a golf ball being hit by a club in super-slow motion, you&amp;rsquo;ll see that it deforms considerably during impact.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/golf-ball-compression-during-impact.jpg&#34; alt=&#34;golf ball compression during impact&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;The same thing happens to all objects in the real world to some degree. Nothing is truly rigid. No real material is so hard that it never deforms.&lt;/p&gt;
&lt;p&gt;But this is not the real world. This is Virtual Go :) It&amp;rsquo;s a simulation and here we are free to make whatever assumptions we want. And the smartest simplification we can make at this point is to assume that the go stone is perfectly rigid and does not deform under any circumstance.&lt;/p&gt;
&lt;p&gt;This is known as the &lt;a href=&#34;https://en.wikipedia.org/wiki/Rigid_body&#34;&gt;rigid body&lt;/a&gt; assumption.&lt;/p&gt;
&lt;h2 id=&#34;working-in-three-dimensions&#34;&gt;Working in Three Dimensions&lt;/h2&gt;
&lt;p&gt;Because the go stones are rigid, all we need to represent their current position is the position of the center. As the center moves, so does the rest of the stone.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/biconvex-rigid-body-center-P.png&#34; alt=&#34;biconvex go stone rigid body center&#34; width=&#34;75%&#34;/&gt;
&lt;p&gt;We&amp;rsquo;ll represent this position using a three dimensional vector &lt;b&gt;P&lt;/b&gt;.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s define the axes so we know what the x,y,z components of P mean:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Positive x is to the right&lt;/li&gt;
&lt;li&gt;Positive y is up&lt;/li&gt;
&lt;li&gt;Positive z is into the screen&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is what is known as a left-handed coordinate system. So called because I can use the fingers on my left hand to point out each positive axis direction without breaking them.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/coordinate-systems-left-and-right-handed.png&#34; alt=&#34;left and right handed coordinate systems&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;I&amp;rsquo;ve chosen a left-handed coordinate system purely on personal preference. Also, I&amp;rsquo;m left-handed and I like my fingers :)&lt;/p&gt;
&lt;h2 id=&#34;linear-motion&#34;&gt;Linear Motion&lt;/h2&gt;
&lt;p&gt;Now we want to make the stone move.&lt;/p&gt;
&lt;p&gt;To do this we need the concept of velocity. Velocity is also a vector but it&amp;rsquo;s not a point like P. Think of it more like a direction and a length. The direction of the velocity vector is the direction the stone is moving and the length is the speed it&amp;rsquo;s moving in some unit per-second. Here I&amp;rsquo;ll use centimeters per-second because go stones are small.&lt;/p&gt;
&lt;p&gt;For example, if we the stone to move to the right at a rate of 5 centimeters per-second then the velocity vector is (5,0,0).&lt;/p&gt;
&lt;p&gt;To make the stone move, all we have to do is add the velocity to the position once per-second:&lt;/p&gt;
&lt;div class=&#34;video_container&#34;&gt;
&lt;iframe src=&#34;//www.youtube.com/embed/d7H8MSrOBko&#34; 
frameborder=&#34;0&#34; allowfullscreen class=&#34;video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;p&gt;While this works, it&amp;rsquo;s not particularly exciting. We&amp;rsquo;d like the stone to move much more smoothly. Instead of updating once per-second, let&amp;rsquo;s update 60 times per-second or 60 fps (frames per-second). Rather than taking one big step, we&amp;rsquo;ll take 60 smaller steps per-second, each step being 1/60 of the velocity.&lt;/p&gt;
&lt;div class=&#34;video_container&#34;&gt;
&lt;iframe src=&#34;//www.youtube.com/embed/yK_Zh2u3D0w&#34; 
frameborder=&#34;0&#34; allowfullscreen class=&#34;video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;p&gt;You can generalize this to any framerate with the concept of delta time or &amp;ldquo;dt&amp;rdquo;. To calculate delta time invert frames per second: dt = 1/fps and you have the amount of time per-frame in seconds. Next, multiply velocity by delta time and you have the change in position per-frame.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    const float fps = 60.0f;
    const float dt = 1 / fps;
    while ( !quit )
    {
        stone.rigidBody.position += stone.rigidBody.velocity * dt;
        RenderStone( stone );
        UpdateDisplay();
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is actually a very simple type of &lt;a href=&#34;https://en.wikipedia.org/wiki/Euler_method&#34;&gt;numerical integration&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;gravitational-acceleration&#34;&gt;Gravitational Acceleration&lt;/h2&gt;
&lt;p&gt;Next we want to add gravity.&lt;/p&gt;
&lt;p&gt;To do this we need to change velocity each frame by some amount downwards due to gravity. Change in velocity is known as acceleration. Gravity provides a constant acceleration of 9.8 meters per-second, per-second, or in our case, 98 centimeters per-second, per-second because we&amp;rsquo;re working in centimeters.&lt;/p&gt;
&lt;p&gt;Acceleration due to gravity is also a vector. Since gravity pulls objects down, the acceleration vector is (0,-98,0). Remember, +y axis is up, so -y is down.&lt;/p&gt;
&lt;p&gt;So how much does gravity accelerate the go stone in 1/60th of a second? Well, 98 * 1/60 = 1.633&amp;hellip; Hey wait. This is exactly what we did with velocity to get position!&lt;/p&gt;
&lt;p&gt;Yes it is. It&amp;rsquo;s exactly the same. Acceleration integrates to velocity just like velocity integrates to position. And both are multiplied by dt to find the amount to add per-frame, where dt = 1/fps.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s the code:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    float gravity = 9.8f * 10;
    float fps = 60.0f;
    float dt = 1 / fps;
    while ( !quit )
    {
        stone.rigidBody.velocity += vec3f( 0, -gravity, 0 ) * dt;
        stone.rigidBody.position += stone.rigidBody.velocity * dt;
        RenderStone( stone );
        UpdateDisplay();
    }    
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And here&amp;rsquo;s the result:&lt;/p&gt;
&lt;div class=&#34;video_container&#34;&gt;
&lt;iframe src=&#34;//www.youtube.com/embed/nIMK8V6b84I&#34; 
frameborder=&#34;0&#34; allowfullscreen class=&#34;video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;p&gt;As you can see, now that we&amp;rsquo;ve added acceleration due to gravity the go stone moves in a parabola just like it does in the real world when it&amp;rsquo;s thrown.&lt;/p&gt;
&lt;h2 id=&#34;angular-motion&#34;&gt;Angular Motion&lt;/h2&gt;
&lt;p&gt;Now let&amp;rsquo;s make the stone rotate!&lt;/p&gt;
&lt;p&gt;First we have to define how we represent the orientation of the stone. For this we&amp;rsquo;ll use a &lt;a href=&#34;https://en.wikipedia.org/wiki/Quaternions_and_spatial_rotation&#34;&gt;quaternion&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Next we need the angular equivalent of velocity known as&amp;hellip; wait for it&amp;hellip; angular velocity. This too is a vector aka a direction and a length. It&amp;rsquo;s direction is the axis of rotation and the length is the rate of rotation in radians per-second. One full rotation is 2&lt;em&gt;pi radians or 360 degrees so if the length of the angular velocity vector is 2&lt;/em&gt;pi the object rotates around the axis once per-second.&lt;/p&gt;
&lt;p&gt;Because we&amp;rsquo;re using a left handed coordinate system the direction of rotation is clockwise about the positive axis. You can remember this by sticking your thumb of your left hand in the direction of the axis of rotation and curling your fingers. The direction your fingers curl is the direction of rotation. Notice if you do the same thing with your right hand the rotation is the other way.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/rotation-direction-hand-thumb.png&#34; alt=&#34;rotation direction left and right hands&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;How do we integrate orientation from angular velocity? Orientation is a quaternion and angular velocity is a vector. We can&amp;rsquo;t just add them together.&lt;/p&gt;
&lt;p&gt;The solution requires a reasonably solid understanding of quaternion math and how it relates to complex numbers. Long story short, we need to convert our angular velocity into a quaternion form and then we can integrate that just like we integrate any other vector. For a full derivation of this result please refer to &lt;a href=&#34;https://fgiesen.wordpress.com/2012/08/24/quaternion-differentiation/&#34;&gt;this excellent article&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here is the code I use to convert angular velocity into quaternion form:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    inline quat4f AngularVelocityToSpin( quat4f orientation, vec3f angularVelocity )
    {
        const float x = angularVelocity.x();
        const float y = angularVelocity.y();
        const float z = angularVelocity.z();
        return 0.5f * quat4f( 0, x, y, z ) * 
            orientation;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And once I have this spin quaternion, I can integrate it to find the change in the orientation quaternion just like any other vector.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    const float fps = 60.0f;
    const float dt = 1 / fps;
    while ( !quit )
    {
        quat4f spin = AngularVelocityToSpin( 
            stone.rigidBody.orientation, 
            stone.rigidBody.angularVelocity );
        stone.rigidBody.orientation += spin * iteration_dt;
        stone.rigidBody.orientation = normalize( stone.rigidBody.orientation );
        RenderStone( stone );
        UpdateDisplay();
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The only difference is that after integration I renormalize the quaternion to ensure it doesn&amp;rsquo;t drift from unit length, otherwise it stops representing a rotation.&lt;/p&gt;
&lt;div class=&#34;video_container&#34;&gt;
&lt;iframe src=&#34;//www.youtube.com/embed/sR4G-_wIeuc&#34; 
frameborder=&#34;0&#34; allowfullscreen class=&#34;video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;p&gt;Yep. That go stone is definitely rotating.&lt;/p&gt;
&lt;h2 id=&#34;why-quaternions&#34;&gt;Why Quaternions?&lt;/h2&gt;
&lt;p&gt;Graphics cards typically represent rotations with matrices, so why are we using quaternions when calculating physics instead of 4x4 matrices? Aren&amp;rsquo;t we bucking the trend a bit here?&lt;/p&gt;
&lt;p&gt;Not really. There are many good reasons to work with quaternions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;It&amp;rsquo;s easier to integrate angular velocity using a quaternion than a 3x3 matrix&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Normalizing a quaternion is faster than orthonormalizing a 3x3 matrix&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It&amp;rsquo;s really easy to interpolate between two quaternions&lt;/li&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We&amp;rsquo;ll still use matrices but as a secondary quantity. This means that each frame after we integrate we convert the quaternion into a 3x3 rotation matrix and combine it with the position into a 4x4 rigid body matrix and its inverse like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    mat4f RigidBodyMatrix( vec3f position, 
                           quat4f rotation )
    {
        mat4f matrix;
        rotation.toMatrix( matrix );
        matrix.value.w = simd4f_create( position.x(), 
                                        position.y(), 
                                        position.z(), 
                                        1 );
        return matrix;
    }

    mat4f RigidBodyInverse( const mat4f &amp;amp; matrix )
    {
        mat4f inverse = matrix;
        vec4f translation = matrix.value.w;
        inverse.value.w = simd4f_create(0,0,0,1);
        simd4x4f_transpose_inplace( &amp;amp;inverse.value );
        vec4f x = matrix.value.x;
        vec4f y = matrix.value.y;
        vec4f z = matrix.value.z;
        inverse.value.w = 
            simd4f_create( -dot( x, translation ),
                           -dot( y, translation ),
                           -dot( z, translation ),
                           1.0f );
        return inverse;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now whenever we transform vectors want to go in/out of stone body space we&amp;rsquo;ll use this matrix and its inverse. It&amp;rsquo;s the best of both worlds.&lt;/p&gt;
&lt;h2 id=&#34;bringing-it-all-together&#34;&gt;Bringing It All Together&lt;/h2&gt;
&lt;p&gt;The best thing about rigid body motion is that you can calculate linear and angular motion separately and combine them together and it just works.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s the final code with linear and angular motion combined:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;const float gravity = 9.8f * 10;
const float fps = 60.0f;
const float dt = 1 / fps;

while ( !quit )
{
    stone.rigidBody.velocity += vec3f( 0, -gravity, 0 ) * dt;

    stone.rigidBody.position += stone.rigidBody.velocity * dt;

    quat4f spin = 
        AngularVelocityToSpin( 
            stone.rigidBody.orientation, 
            stone.rigidBody.angularVelocity );

    stone.rigidBody.orientation += spin * dt;
    stone.rigidBody.orientation = normalize( stone.rigidBody.orientation );

    RenderStone( stone );

    UpdateDisplay();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And here is the end result:&lt;/p&gt;
&lt;div class=&#34;video_container&#34;&gt;
&lt;iframe src=&#34;//www.youtube.com/embed/gmZGktbTAGA&#34; 
frameborder=&#34;0&#34; allowfullscreen class=&#34;video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;p&gt;I think this is fairly convincing. The go stone is moving quite realistically!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NEXT ARTICLE:&lt;/strong&gt; &lt;a href=&#34;https://gafferongames.com/post/go_stone_vs_go_board/&#34;&gt;Go Stone vs. Go Board&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Glenn Fiedler&lt;/strong&gt; is the founder and CEO of &lt;strong&gt;&lt;a href=&#34;https://networknext.com&#34;&gt;Network Next&lt;/a&gt;&lt;/strong&gt;.&lt;br&gt;&lt;i&gt;Network Next is fixing the internet for games by creating a marketplace for premium network transit.&lt;/i&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tessellating The Go Stone</title>
      <link>https://gafferongames.com/post/tessellating_the_go_stone/</link>
      <pubDate>Wed, 20 Feb 2013 00:00:00 +0000</pubDate>
      
      <guid>https://gafferongames.com/post/tessellating_the_go_stone/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Hi, I&amp;rsquo;m &lt;a href=&#34;https://gafferongames.com&#34;&gt;Glenn Fiedler&lt;/a&gt;. Welcome to &lt;a href=&#34;https://gafferongames.com/categories/virtual-go/&#34;&gt;&lt;strong&gt;Virtual Go&lt;/strong&gt;&lt;/a&gt;, my project to create a physically accurate computer simulation of a Go board and stones.&lt;/p&gt;
&lt;p&gt;In this article we want to draw the go stone using &lt;a href=&#34;http://www.opengl.org&#34;&gt;OpenGL&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Unfortunately we can&amp;rsquo;t just tell the graphics card, &amp;ldquo;Hey! Please draw the intersection of two spheres with radius r and d apart with a bevel torus r&lt;sub&gt;1&lt;/sub&gt; and r&lt;sub&gt;2&lt;/sub&gt;!&amp;rdquo;, because modern 3D graphics cards work by drawing triangles. We have to take our mathematical definition of the go stone and turn it into a set of triangles that the graphics card can render.&lt;/p&gt;
&lt;p&gt;This is called tessellation and there are several different ways to do it.&lt;/p&gt;
&lt;h2 id=&#34;longitude-and-lattitude&#34;&gt;Longitude And Lattitude&lt;/h2&gt;
&lt;p&gt;The first way that I tried was to consider sphere rendering like a globe with longitude/latitude. I started with a ring around the &amp;rsquo;equator&amp;rsquo; of the go stone, stepping these rings up to the top of the sphere like the north pole on a globe.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/naive-tesselation-side-view.gif&#34; alt=&#34;naive tesselation side view&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;Unfortunately, just like longitude/latitude on a globe, tessellating this way leads to very distorted mapping around the pole and a lot of wasted triangles:&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/inefficient-tesselation-at-pole.gif&#34; alt=&#34;inefficient tesselation at pole&#34; width=&#34;100%&#34;/&gt;
&lt;h2 id=&#34;triangle-subdivision&#34;&gt;Triangle Subdivision&lt;/h2&gt;
&lt;p&gt;The next method is triangle subdivision. You start with an approximate shape then subdivide each triangle into four smaller triangles recursively like this:&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/sphere-tessellation.gif&#34; alt=&#34;sphere tessellation&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;Since the go stone only needs the top 1/3 or 1/4 of a sphere, I didn&amp;rsquo;t want to subdivide a whole sphere only to throw most of it away. So I designed my own subdivision algorithm to generate only the top section of a sphere.&lt;/p&gt;
&lt;p&gt;After some trial and error I found that a pentagon plus a center vertex at the pole of the sphere was a good initial generator that minimized the distortion that occurs during subdivision. The only tricky part is that when subdividing you need to keep track of whether the edge is a sphere edge or a circle edge, as the subdivided vertex must be projected differently.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/generating-shape.gif&#34; alt=&#34;generating shape&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;With this technique I was able to generate a much more efficient tessellation:&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/regular-tessellation.gif&#34; alt=&#34;regular tessellation&#34; width=&#34;100%&#34;/&gt;
&lt;h2 id=&#34;tessellating-the-bevel&#34;&gt;Tessellating The Bevel&lt;/h2&gt;
&lt;p&gt;Now we need to tesselate the bevel. To do this I take the vertices which form the circle edge at the bottom of the top sphere surface and calculate the angle of each vertex about the y axis. I then use these angles to sweep around the torus ensuring that the torus vertices weld perfectly with the top and bottom sphere sections.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/go-stone-with-bevel.gif&#34; alt=&#34;go stone with bevel&#34; width=&#34;100%&#34;/&gt;
&lt;h2 id=&#34;vertex-welding&#34;&gt;Vertex Welding&lt;/h2&gt;
&lt;p&gt;Due to how recursive subdivision works a lot of duplicate vertices are generated.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;d rather not have the graphics card waste time transforming the same vertex over and over, so as I add vertices to the mesh I hash vertex positions into a 3D grid (~1mm cells) and reuse an existing vertex if the position and normals match within some small epsilon value.&lt;/p&gt;
&lt;p&gt;With vertex welding the reduction in vertices is dramatic: 53000 to just 6500.&lt;/p&gt;
&lt;p&gt;For more information on vertex welding please refer to the discussion in &lt;a href=&#34;http://www.amazon.com/Real-Time-Collision-Detection-Interactive-Technology/dp/1558607323/ref=sr_1_1?ie=UTF8&amp;qid=1363029675&amp;sr=8-1&amp;keywords=real+time+collision+detection&#34;&gt;Real-Time Collision Detection&lt;/a&gt; by &lt;a href=&#34;http://realtimecollisiondetection.net/blog/&#34;&gt;Christer Ericson&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NEXT ARTICLE:&lt;/strong&gt; &lt;a href=&#34;https://gafferongames.com/post/how_the_go_stone_moves/&#34;&gt;How The Go Stone Moves&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Glenn Fiedler&lt;/strong&gt; is the founder and CEO of &lt;strong&gt;&lt;a href=&#34;https://networknext.com&#34;&gt;Network Next&lt;/a&gt;&lt;/strong&gt;.&lt;br&gt;&lt;i&gt;Network Next is fixing the internet for games by creating a marketplace for premium network transit.&lt;/i&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Shape of The Go Stone</title>
      <link>https://gafferongames.com/post/shape_of_the_go_stone/</link>
      <pubDate>Tue, 19 Feb 2013 00:00:00 +0000</pubDate>
      
      <guid>https://gafferongames.com/post/shape_of_the_go_stone/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Hi, I&amp;rsquo;m &lt;a href=&#34;https://gafferongames.com&#34;&gt;Glenn Fiedler&lt;/a&gt;. Welcome to &lt;a href=&#34;https://gafferongames.com/categories/virtual-go/&#34;&gt;&lt;strong&gt;Virtual Go&lt;/strong&gt;&lt;/a&gt;, my project to create a physically accurate computer simulation of a Go board and stones.&lt;/p&gt;
&lt;p&gt;If you play Go, you know that a biconvex go stone has an interesting wobble when it&amp;rsquo;s placed on the board. This wobble is a direct consequence of its unique shape.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;d like to reproduce this wobble in Virtual Go, so let&amp;rsquo;s to spend some time studying go stone&amp;rsquo;s shape, so we can capture this wobble and simulate it on a computer :)&lt;/p&gt;
&lt;h2 id=&#34;slate-and-shell&#34;&gt;Slate And Shell&lt;/h2&gt;
&lt;p&gt;In Japan, Go stones are traditionally made out of slate and clam shell.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/slate-and-shell-in-ko.jpg&#34; alt=&#34;slate and shell in ko&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;Clam shell stones come in several grades of quality. The highest being yuki or &amp;ldquo;snow&amp;rdquo; grade with fine, regularly spaced lines.&lt;/p&gt;
&lt;p&gt;Go stones also come in different sizes. In general, the thicker the stone, the more expensive it is, as only a small portion of the clam shell is suitable for making them.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/go-stone-side-profile-sizes.png&#34; alt=&#34;go stone side profile sizes&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;At first glance the go stone looks like an ellipse, but side-on you can see this is not the case. This shape is called a &lt;em&gt;biconvex solid&lt;/em&gt;. I find this shape interesting because it is the intersection of two spheres.&lt;/p&gt;
&lt;p&gt;We can study this shape by looking at the intersection of two circles:&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/biconvex.gif&#34; alt=&#34;biconvex&#34; width=&#34;75%&#34;/&gt;
&lt;p&gt;I quickly noticed that by varying the radius of the circles and the distance between their centers, I could generate go stones of different sizes.&lt;/p&gt;
&lt;p&gt;But when creating a go stone I don&amp;rsquo;t really want it to be parameterized this way.&lt;/p&gt;
&lt;p&gt;Instead I&amp;rsquo;d like to say, &amp;ldquo;Hey, I would like a stone of this width and height&amp;rdquo; and have a function that calculates the radius of the circles and how far apart they should be to generate that stone.&lt;/p&gt;
&lt;p&gt;To write this function we first need to do some math:&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/biconvex-unknowns.png&#34; alt=&#34;biconvex unknowns&#34; width=&#34;75%&#34;/&gt;
&lt;p&gt;First notice that the point Q lies on the generating circle, so the line CQ has length r:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;todo: obviously I have a bunch of work to get the latex equations ported across to Hugo. I&amp;rsquo;m researching different options&amp;hellip;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;[latex size=&amp;ldquo;2&amp;rdquo;]d + h/2 = r[/latex]
[latex size=&amp;ldquo;2&amp;rdquo;]d = r - h/2[/latex]&lt;/p&gt;
&lt;p&gt;The point P is also on the generating circle so the green line CP has length r as well. Using Pythagoras theorem and substituting for d:&lt;/p&gt;
&lt;p&gt;[latex size=&amp;ldquo;2&amp;rdquo;]r^2 = d^2 + (w/2)^2[/latex]
[latex size=&amp;ldquo;2&amp;rdquo;]r^2 = ( r - h/2 )^2 + (w/2)^2[/latex]
[latex size=&amp;ldquo;2&amp;rdquo;]r^2 = ( h^2/4 - hr + r^2 ) + w^2/4[/latex]
[latex size=&amp;ldquo;2&amp;rdquo;]r^2 = h^2/4 - hr + r^2 + w^2/4[/latex]
[latex size=&amp;ldquo;2&amp;rdquo;]0 = h^2/4 - hr + 0 + w^2/4[/latex]
[latex size=&amp;ldquo;2&amp;rdquo;]hr = h^2/4 + w^2/4[/latex]
[latex size=&amp;ldquo;2&amp;rdquo;]r = ( h^2 + w^2 ) / 4h[/latex]&lt;/p&gt;
&lt;p&gt;Which gives us everything we need to write the function:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    void calculateBiconvex( float w,  
                            float h, 
                            float &amp;amp; r, 
                            float &amp;amp; d )
    {
        r = ( w*w + h*h ) / ( 4*h );
        d = r - h/2;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can mathematically define a go stone parameterized by its width and height. There is just one problem: the edge is very sharp!&lt;/p&gt;
&lt;p&gt;To make our stone aesthetically pleasing, lets round the edge with a bevel. Otherwise, you might cut yourself virtually when you play with it:&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/go-stone-smooth-bevel.jpg&#34; alt=&#34;go stone smooth bevel&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;Let&amp;rsquo;s parameterize the bevel by its height b:&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/bevel-b.gif&#34; alt=&#34;torus bevel height b&#34; width=&#34;75%&#34;/&gt;
&lt;p&gt;In three dimensions the bevel is actually a torus (donut) around the edge of the go stone. We need to calculate the major and minor radii r&lt;sub&gt;1&lt;/sub&gt; and r&lt;sub&gt;2&lt;/sub&gt; of the torus as a function of b and the dimensions of the go stone:&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/bevel-math-1.gif&#34; alt=&#34;bevel math part 1&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;The key to solving this is to realize that if the go stone and the bevel are to match perfectly then the tangent of the two circles must be equal at the point P.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;em&gt;Update&lt;/em&gt;: A few years later and it occurs to me that it would be even more beautiful if the second derivative matched at this intersection as well. Is this possible in general, or must the generating spheres become to ellipses in order to make this happen? I suspect this is the case. Mathematicians who play Go, &lt;a href=&#34;https://gafferongames.com/contact&#34;&gt;let me know your thoughts&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/virtualgo/bevel-math-2.gif&#34; alt=&#34;bevel math part 2&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;If the tangent is equal then the normal must be equal as well. This means that the center of the bevel circle lies at the intersection of the line CP and the x axis.&lt;/p&gt;
&lt;p&gt;We already know C so if we can find the point P then we can find this intersection point. Once we know the intersection point we can find r&lt;sub&gt;1&lt;/sub&gt; and r&lt;sub&gt;2&lt;/sub&gt;.&lt;/p&gt;
&lt;p&gt;Since P is at the start of the bevel:&lt;/p&gt;
&lt;p&gt;[latex size=&amp;ldquo;2&amp;rdquo;]P_y = b/2[/latex]&lt;/p&gt;
&lt;p&gt;Because P lies on the biconvex circle with center C and radius r we can use the equation of the circle to find x as a function of y:&lt;/p&gt;
&lt;p&gt;[latex size=&amp;ldquo;2&amp;rdquo;]x^2 + y^2 = r^2[/latex]
[latex size=&amp;ldquo;2&amp;rdquo;]x = \sqrt{ r^2 - y^2 }[/latex]&lt;/p&gt;
&lt;p&gt;We need y relative to the circle center C, not in go stone coordinates, so we add d and substitute y&amp;rsquo; for y:&lt;/p&gt;
&lt;p&gt;[latex size=&amp;ldquo;2&amp;rdquo;]y&amp;rsquo; = b/2 + d[/latex]
[latex size=&amp;ldquo;2&amp;rdquo;]P_x = \sqrt{ r^2 - ( b/2 + d )^2 }[/latex]&lt;/p&gt;
&lt;p&gt;We can now find r&lt;sub&gt;1&lt;/sub&gt; by similar triangles:&lt;/p&gt;
&lt;p&gt;[latex size=&amp;ldquo;2&amp;rdquo;]r_1/P_x = d / ( d + b/2 )[/latex]
[latex size=&amp;ldquo;2&amp;rdquo;]r_1 = P_x d / ( d + b/2 )[/latex]&lt;/p&gt;
&lt;p&gt;and q by Pythagoras theorem:&lt;/p&gt;
&lt;p&gt;[latex size=&amp;ldquo;2&amp;rdquo;]q^2 = d^2 + r_1^2[/latex]
[latex size=&amp;ldquo;2&amp;rdquo;]q = \sqrt{ d^2 + r_1^2 }[/latex]&lt;/p&gt;
&lt;p&gt;Because line CP has length r and substituting for q:&lt;/p&gt;
&lt;p&gt;[latex size=&amp;ldquo;2&amp;rdquo;]q + r_2 = r[/latex]
[latex size=&amp;ldquo;2&amp;rdquo;]r_2 = r - q[/latex]
[latex size=&amp;ldquo;2&amp;rdquo;]r_2 = r - \sqrt{ d^2 + r_1^2 }[/latex]&lt;/p&gt;
&lt;p&gt;Now we have everything we need to write the function:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    void calculate_bevel( float r, float d, float b, 
                          float &amp;amp; r1, float &amp;amp; r2 )
    {
        const float y = b/2 + d;
        const float px = sqrt( r*r - y*y );
        r1 = px * d / ( d + b/2 ); 
        r2 = r - sqrt( d*d + r1*r1 );
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can calculate the bevel torus to round off any go stone we create as the intersection of two spheres.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NEXT ARTICLE:&lt;/strong&gt; &lt;a href=&#34;https://gafferongames.com/post/tessellating_the_go_stone&#34;&gt;Tessellating The Go Stone&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Glenn Fiedler&lt;/strong&gt; is the founder and CEO of &lt;strong&gt;&lt;a href=&#34;https://networknext.com&#34;&gt;Network Next&lt;/a&gt;&lt;/strong&gt;.&lt;br&gt;&lt;i&gt;Network Next is fixing the internet for games by creating a marketplace for premium network transit.&lt;/i&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to Virtual Go</title>
      <link>https://gafferongames.com/post/introduction_to_virtual_go/</link>
      <pubDate>Mon, 18 Feb 2013 00:00:00 +0000</pubDate>
      
      <guid>https://gafferongames.com/post/introduction_to_virtual_go/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Hi, I&amp;rsquo;m &lt;a href=&#34;https://gafferongames.com&#34;&gt;Glenn Fiedler&lt;/a&gt;. Welcome to &lt;a href=&#34;https://gafferongames.com/categories/virtual-go/&#34;&gt;&lt;strong&gt;Virtual Go&lt;/strong&gt;&lt;/a&gt;, my project to create a physically accurate computer simulation of a Go board and stones.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m a professional game programmer with 15 years experience in the game industry. Over the years I&amp;rsquo;ve worked for Irrational Games, Team Bondi, Pandemic Studios, Sony Santa Monica and most recently Respawn Entertainment. During my career I&amp;rsquo;m extremely proud to have worked on such games as &amp;lsquo;Freedom Force&amp;rsquo;, &amp;lsquo;L.A. Noire&amp;rsquo;, &amp;lsquo;Journey&amp;rsquo;, &amp;lsquo;God of War: Ascension&amp;rsquo; and &amp;lsquo;Titanfall&amp;rsquo;.&lt;/p&gt;
&lt;p&gt;In my spare time I&amp;rsquo;m also an avid player of the board game &lt;a href=&#34;https://en.wikipedia.org/wiki/Go_(game)&#34;&gt;Go&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gafferongames.com/img/virtualgo/go-board-outside-cafe.jpg&#34; width=&#34;100%&#34;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A personal project I&amp;rsquo;ve always dreamed of combines the things I love: the game of Go, graphics programming, physics simulation and network programming.&lt;/p&gt;
&lt;p&gt;The end result I hope to achieve is a beautiful real-time computer rendering of a go board and stones with photorealistic visuals and the laws of physics defining all interactions between the go stones and the board. To Go players reading this, yes, I do aim to reproduce that unique &amp;lsquo;wobble&amp;rsquo; and feel you are familiar with when placing a stone on the board.&lt;/p&gt;
&lt;p&gt;During the course of this article series I&amp;rsquo;m going to build this project entirely from scratch and include &lt;u&gt;you&lt;/u&gt; in on all the details of building it as a tutorial. I believe in sharing knowledge and my hope is you can follow this project and understand the passion I bring to it and perhaps learn a few things along the way.&lt;/p&gt;
&lt;p&gt;If you already play Go and want to get right in to the details of building the simulation, I would recommend skipping ahead to the next article in the series: &lt;a href=&#34;https://gafferongames.com/post/shape_of_the_go_stone/&#34;&gt;Shape Of The Go Stone&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Otherwise, if you would like a quick introduction to Go, please read on!&lt;/p&gt;
&lt;h2 id=&#34;the-game-of-go&#34;&gt;The Game of Go&lt;/h2&gt;
&lt;p&gt;Go is a board game that originated in ancient China.&lt;/p&gt;
&lt;p&gt;Today it is played worldwide but has a particularly strong following in China, Japan and Korea. It is not particularly well known in the West, although it has featured in popular culture in the movie &amp;ldquo;A Beautiful Mind&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gafferongames.com/img/virtualgo/old-men-playing-go.jpg&#34; width=&#34;100%&#34;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Go is played on a grid with black and white stones. It is played by two people, each taking turns to place a stone of their color at one of the intersection points on the grid. Once placed on the board, stones do not move.&lt;/p&gt;
&lt;p&gt;Each stone on the board has a number of liberties equal to the number of lines radiating out from it on the grid. A stone in the middle of the board has four liberties, a stone on the side has three, a stone in the corner has just two.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gafferongames.com/img/virtualgo/go-board-liberties-9x9.jpg&#34; width=&#34;100%&#34;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If the opponent is able to surround all the liberties with stones of the opposite color, the stone is removed from the board.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gafferongames.com/img/virtualgo/capture-stones-9x9.jpg&#34; width=&#34;100%&#34;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;When stones of the same color are placed horizontally or vertically next to each other they become logically connected and form a &amp;ldquo;group&amp;rdquo; with its own set of liberties. For example, a group of two stones in the center has 6 liberties, while the same group on the side has only 4.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gafferongames.com/img/virtualgo/go-board-group-of-two-liberties-9x9.jpg&#34; width=&#34;100%&#34;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;A group may be captured if all of its liberties are blocked with stones of the opposite color. When a group is captured it is removed from the board as a unit.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gafferongames.com/img/virtualgo/capture-groups-of-two-9x9.jpg&#34; width=&#34;100%&#34;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Of course it is not so easy to surround your opponents stones because they get to place stones too :)&lt;/p&gt;
&lt;p&gt;For example, a single black stone in the center with just one liberty remaining is in a situation known as &amp;ldquo;Atari&amp;rdquo;, but black can escape by extending to form a group of two stones. Now the black group has three liberties and can extend to create more liberties faster than they can be taken away.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://gafferongames.com/img/virtualgo/atari-run-away-9x9.jpg&#34; width=&#34;100%&#34;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;It follows that it&amp;rsquo;s not really possible to capture all of your opponents stones or for them to capture all of yours. Instead, you must coexist on the board with stones of the other color and find a way to surround more points of territory than your opponent.&lt;/p&gt;
&lt;p&gt;It sounds simple but as you play Go you&amp;rsquo;ll notice beautiful complexity emerging like a fractal: life and death - stones living even though surrounded, liberty races, seki or &amp;ldquo;dual life&amp;rdquo;, the ladder, ko, the snapback, playing under the stones, the monkey jump, the bamboo joint, the tiger mouth.&lt;/p&gt;
&lt;p&gt;So many beautiful properties from such simple rules. Truly an amazing game!&lt;/p&gt;
&lt;p&gt;Please visit &lt;a href=&#34;http://playgo.to/iwtg/en/&#34;&gt;The Interactive Way To Go&lt;/a&gt; if you would like to learn more.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NEXT ARTICLE:&lt;/strong&gt; &lt;a href=&#34;https://gafferongames.com/post/shape_of_the_go_stone/&#34;&gt;Shape of The Go Stone&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Glenn Fiedler&lt;/strong&gt; is the founder and CEO of &lt;strong&gt;&lt;a href=&#34;https://networknext.com&#34;&gt;Network Next&lt;/a&gt;&lt;/strong&gt;.&lt;br&gt;&lt;i&gt;Network Next is fixing the internet for games by creating a marketplace for premium network transit.&lt;/i&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Networked Physics (2004)</title>
      <link>https://gafferongames.com/post/networked_physics_2004/</link>
      <pubDate>Sat, 04 Sep 2004 00:00:00 +0000</pubDate>
      
      <guid>https://gafferongames.com/post/networked_physics_2004/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Hi, I&amp;rsquo;m &lt;a href=&#34;https://gafferongames.com&#34;&gt;Glenn Fiedler&lt;/a&gt; and welcome to &lt;strong&gt;&lt;a href=&#34;https://gafferongames.com/categories/game-physics/&#34;&gt;Game Physics&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In the &lt;a href=&#34;https://gafferongames.com/post/spring_physics&#34;&gt;previous article&lt;/a&gt; we discussed how to use spring-like forces to model basic collision response, joints and motors.&lt;/p&gt;
&lt;p&gt;In this article we&amp;rsquo;re going to discuss how to network a physics simulation.&lt;/p&gt;
&lt;h2 id=&#34;first-person-shooters&#34;&gt;First Person Shooters&lt;/h2&gt;
&lt;p&gt;First person shooter physics are usually very simple. The world is static and players are limited to running around and jumping and shooting.&lt;/p&gt;
&lt;p&gt;Because of cheating, first person shooters typically operate on a client-server model where the server is authoritative over physics. This means that the true physics simulation runs on the server and the clients display an approximation of the server physics to the player.&lt;/p&gt;
&lt;p&gt;The problem then is how to allow each client to control his own character while displaying a reasonable approximation of the motion of the other players.&lt;/p&gt;
&lt;p&gt;In order to do this elegantly and simply, we structure the physics simulation as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Character physics are completely driven from input data.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Physics state is fully encapsulated in a state structure.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;To do this we need to gather all the user input that drives the physics simulation into a single structure and the state representing each player character into another.&lt;/p&gt;
&lt;p&gt;Here is an example from a simple run and jump shooter:&lt;/p&gt;
&lt;pre&gt;
    struct Input
    {
         bool left;
         bool right;
         bool forward;
         bool back;
         bool jump;
    };

    struct State
    {
         Vector position;
         Vector velocity;
    };
&lt;/pre&gt;
&lt;p&gt;Next we need to make sure that the simulation gives the same result given the same initial state and inputs over time. Or at least, that the results are as close as possible. I&amp;rsquo;m not talking about perfect floating point determinism here, just a reasonable 1/2 second prediction giving approximately the same result.&lt;/p&gt;
&lt;h2 id=&#34;network-fundamentals&#34;&gt;Network Fundamentals&lt;/h2&gt;
&lt;p&gt;I will briefly discuss actually networking issues in this section before moving on to the important information of what to send over the pipe. It is after all just a pipe after all, networking is nothing special right? Beware! Ignorance of how the pipe works will really bite you. Here are the two networking fundamentals that you absolutely need to know:&lt;/p&gt;
&lt;p&gt;Number one. If your network programmer is any good at all he will use UDP, which is an unreliable data protocol, and build some sort of application specific networking layer on top of this. The important thing that you as the physics programmer need to know is that you absolutely must design your physics communication over the network so that you can receive the most recent input and state without waiting for lost packets to be resent. This is important because otherwise your physics simulation will stall out under bad networking conditions.&lt;/p&gt;
&lt;p&gt;Two. You will be very limited in what can be sent across the network due to bandwidth limitations. Compression is a fact of life when sending data across the network. As physics programmer you need to be very careful what data is compressed and how it is done. For the sake of determinism, some data must not be compressed, while other data is safe. Any data that is compressed in a lossy fashion should have the same quantization applied locally where possible, so that the result is the same on both machines. Bottom line you&amp;rsquo;ll need to be involved in this compression in order to make it as efficient as possible without breaking your simulation.&lt;/p&gt;
&lt;h2 id=&#34;physics-runs-on-the-server&#34;&gt;Physics Runs On The Server&lt;/h2&gt;
&lt;p&gt;The fundamental primitive we will use when sending data between the client and the server is an unreliable data block, or if you prefer, an unreliable non-blocking remote procedure call (rpc). Non-blocking means that the client sends the rpc to the server then continues immediately executing other code, it does not wait for the rpc to execute on the server! Unreliable means that if you call the rpc is continuously on the the server from a client, some of these calls will not reach the server, and others will arrive in a different order than they were called. We design our communications around this primitive because it suits the transport layer (UDP).&lt;/p&gt;
&lt;p&gt;The communication between the client and the server is then structured as what I call a &amp;ldquo;stream of input&amp;rdquo; sent via repeated rpc calls. The key to making this input stream tolerant of packet loss and out of order delivery is the inclusion of a floating point time in seconds value with every input rpc sent. The server keeps track of the current time on the server and ignores any input received with a time value less than the current time. This effectively drops any input that is received out of order. Lost packets are ignored.&lt;/p&gt;
&lt;p&gt;Thinking in terms of our standard first person shooter, the input we send from client to server is the input structure that we defined earlier:&lt;/p&gt;
&lt;pre&gt;
    struct Input
    {
         bool left;
         bool right;
         bool forward;
         bool back;
         bool jump;
    };

    class Character
    {
    public:

         void processInput( double time,
                            Input input );
    };
&lt;/pre&gt;
&lt;p&gt;Thats the bare minimum data required for sending a simple ground based movement plus jumping across the network. If you are going to allow your clients to shoot you&amp;rsquo;ll need to add mouse input as part of the input structure as well because weapon firing needs to be done server side.&lt;/p&gt;
&lt;p&gt;Notice how I define the rpc as a method inside an object? I assume your network programmer has a channel structure built on top of UDP, eg. some way to indicate that a certain rpc call is directed as a specific object instance on the remote machine.&lt;/p&gt;
&lt;p&gt;So how does the server process these rpc calls? It basically sits in a loop waiting for input from each of the clients. Each character object has its physics advanced ahead in time individually as input rpcs are received from the client that owns it. This means that the physics state of different client characters are slightly out of phase on the server, some clients being a little bit ahead and others a little bit behind in time. Overall however, the different client characters advance ahead roughly in sync with each other.&lt;/p&gt;
&lt;p&gt;Lets see how this rpc call is implemented in code on the server:&lt;/p&gt;
&lt;pre&gt;    void processInput( double time, Input input )
    {
        if ( time &amp;lt; currentTime )
            return;

        float deltaTime = currentTime - time;

        updatePhysics( currentTime, deltaTime, input );
    }&lt;/pre&gt;
&lt;p&gt;The key to the code above is that by advancing the server physics simulation for the client character is performed only as we receive input from that client. This makes sure that the simulation is tolerant of random delays and jitter when sending the input rpc across the network.&lt;/p&gt;
&lt;h2 id=&#34;clients-approximate-physics-locally&#34;&gt;Clients Approximate Physics Locally&lt;/h2&gt;
&lt;p&gt;Now for the communication from the server back to the clients. This is where the bulk of the server bandwidth kicks in because the information needs to be broadcast to all the clients.&lt;/p&gt;
&lt;p&gt;What happens now is that after every physics update on the server that occurs in response to an input rpc from a client, the server broadcasts out the physics state at the end of that physics update and the current input just received from the rpc.&lt;/p&gt;
&lt;p&gt;This is sent to all clients in the form of an unreliable rpc:&lt;/p&gt;
&lt;pre&gt;   void clientUpdate( float time, Input input, State state )
    {
        Vector difference = state.position - 
                            current.position;

        float distance = difference.length();

        if ( distance &amp;gt; 2.0f )
            current.position = state.position;
        else if ( distance &amp;gt; 0.1 )
            current.position += difference * 0.1f;

        current.velocity = velocity;

        current.input = input;
    }&lt;/pre&gt;
&lt;p&gt;What is being done here is this: if the two positions are significantly different (&amp;gt;2m apart) just snap to the corrected position, otherwise if the distance between the server position and the current position on the client is more than 10cms, move 10% of the distance between the current position and the correct position. Otherwise do nothing.&lt;/p&gt;
&lt;p&gt;Since server update rpcs are being broadcast continually from the server to the the clients, moving only a fraction towards the snap position has the effect of smoothing the correction out with what is called an exponentially smoothed moving average.&lt;/p&gt;
&lt;p&gt;This trades a bit of extra latency for smoothness because only moving some percent towards the snapped position means that the position will be a bit behind where it should really be. You don&amp;rsquo;t get anything for free. I recommend that you perform this smoothing for immediate quantities such as position and orientation, while directly snapping derivative quantities such as velocity, angular velocity because the effect of abruptly changing derivative quantities is not as noticeable.&lt;/p&gt;
&lt;p&gt;Of course, these are just rules of thumb. Make sure you experiment to find out what works best for your simulation.&lt;/p&gt;
&lt;h2 id=&#34;client-side-prediction&#34;&gt;Client-Side Prediction&lt;/h2&gt;
&lt;p&gt;So far we have a developed a solution for driving the physics on the server from client input, then broadcasting the physics to each of the clients so they can maintain a local approximation of the physics on the server. This works perfectly however it has one major disadvantage. Latency!&lt;/p&gt;
&lt;p&gt;When the user holds down the forward input it is only when that input makes a round trip to the server and back to the client that the client&amp;rsquo;s character starts moving forward locally. Those who remember the original Quake netcode would be familiar with this effect. The solution to this problem was discovered and first applied in the followup QuakeWorld and is called client side prediction. This technique completely eliminates movement lag for the client and has since become a standard technique used in first person shooter netcode.&lt;/p&gt;
&lt;p&gt;Client side prediction works by predicting physics ahead locally using the player&amp;rsquo;s input, simulating ahead without waiting for the server round trip. The server periodically sends corrections to the client which are required to ensure that the client stays in sync with the server physics. At all times the server is authoritative over the physics of the character so even if the client attempts to cheat all they are doing is fooling themselves locally while the server physics remains unaffected. Seeing as all game logic runs on the server according to server physics state, client side movement cheating is basically eliminated.&lt;/p&gt;
&lt;p&gt;The most complicated part of client side prediction is handling the correction from the server. This is difficult, because the corrections from the server arrive &lt;em&gt;in the past&lt;/em&gt; due to client/server communication latency. We need to apply this correction in the past, then calculate the resulting corrected position at present time on the client.&lt;/p&gt;
&lt;p&gt;The standard technique to do this is to store a circular buffer of saved moves on the client where each move in the buffer corresponds to an input rpc call sent from the client to the server:&lt;/p&gt;
&lt;pre&gt;   struct Move
    {
        double time;
        Input input;
        State state;
    };&lt;/pre&gt;
&lt;p&gt;When the client receives a correction it looks through the saved move buffer to compare its physics state at that time with the corrected physics state sent from the server. If the two physics states differ above some threshold then the client rewinds to the corrected physics state and time and replays the stored moves starting from the corrected state in the past, the result of this re-simulation being the corrected physics state at the current time on the client.&lt;/p&gt;
&lt;p&gt;Sometimes packet loss or out of order delivery occurs and the server input differs from that stored on the client. In this case the server snaps the client to the correct position automatically via rewind and replay. This snapping is quite noticeable to the player, so we reduce it with the same smoothing technique we used above for the other player characters. This smoothing is done &lt;i&gt;after&lt;/i&gt; recalculating the corrected position via rewind and replay.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;We can easily apply the client side prediction techniques used in first person shooters to network a physics simulation, but only if there is a clear ownership of objects by clients and these object interact mostly with a static world.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Glenn Fiedler&lt;/strong&gt; is the founder and CEO of &lt;strong&gt;&lt;a href=&#34;https://networknext.com&#34;&gt;Network Next&lt;/a&gt;&lt;/strong&gt;.&lt;br&gt;&lt;i&gt;Network Next is fixing the internet for games by creating a marketplace for premium network transit.&lt;/i&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Spring Physics</title>
      <link>https://gafferongames.com/post/spring_physics/</link>
      <pubDate>Fri, 03 Sep 2004 00:00:00 +0000</pubDate>
      
      <guid>https://gafferongames.com/post/spring_physics/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Hi, I&amp;rsquo;m &lt;a href=&#34;https://gafferongames.com&#34;&gt;Glenn Fiedler&lt;/a&gt; and welcome to &lt;strong&gt;&lt;a href=&#34;https://gafferongames.com/categories/game-physics/&#34;&gt;Game Physics&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In the &lt;a href=&#34;https://gafferongames.com/post/physics_in_3d/&#34;&gt;previous article&lt;/a&gt; we discussed how to simulate the motion of rigid bodies in 3D. Now we&amp;rsquo;re going to discuss how to implement spring physics.&lt;/p&gt;
&lt;p&gt;The physics behind springs is simple but extremely versatile and useful. You can use springs to link points together to model rope and string, cloth, and even blobs of jelly. Springs can also be used to implement basic collision response, and to create joints that constrain the motion of rigid bodies.&lt;/p&gt;
&lt;p&gt;The more physics programming you do, the more springs pop up. Many physical phenomenon boil down to spring-like forces being applied such as buoyancy in water. Springs are everywhere so lets discover how to simulate them!&lt;/p&gt;
&lt;h2 id=&#34;spring-and-dampers&#34;&gt;Spring and Dampers&lt;/h2&gt;
&lt;p&gt;The formula to use for simulating spring-like behavior is called &lt;a href=&#34;http://en.wikipedia.org/wiki/Hooke&#39;s_law&#34;&gt;Hooke&amp;rsquo;s Law&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;    &lt;strong&gt;F&lt;/strong&gt; = -k&lt;strong&gt;x&lt;/strong&gt;&lt;/pre&gt;
&lt;p&gt;Where &lt;strong&gt;x&lt;/strong&gt; is the vector displacement of the end of the spring from it&amp;rsquo;s equilibrium position,  and k is a constant describing the tightness of the spring. Larger values of k mean that the spring is tighter and will therefore stretch less per unit of force, smaller values mean the spring is looser and will stretch further.&lt;/p&gt;
&lt;p&gt;Newton&amp;rsquo;s third law says that every force has an equal and opposite force. If two objects a and b are connected together by a spring then the spring will apply one force which pulls object a towards object b, and an equal and opposite force pulling object b towards a. However, if you want to attach one object to a fixed point in space its you can apply the force of the object in one direction. This makes sense if you consider that point as having &lt;i&gt;infinite mass&lt;/i&gt;.&lt;/p&gt;
&lt;p&gt;Spring forces alone are not much use though. You need to combine them with dampers to have a realistic simulation. Damping simulates energy loss, and it is used in physics simulations to make sure that springs don&amp;rsquo;t oscillate forever but come to rest over time.&lt;/p&gt;
&lt;p&gt;A spring-damper system can be modeled as follows:&lt;/p&gt;
&lt;pre&gt;    &lt;strong&gt;F&lt;/strong&gt; = - k&lt;strong&gt;x&lt;/strong&gt; - b&lt;strong&gt;v&lt;/strong&gt;&lt;/pre&gt;
&lt;p&gt;Where b is the coefficient of damping and &lt;strong&gt;v&lt;/strong&gt; is the relative velocity between the two points connected by the spring. Larger values for b increase the amount of damping so the object comes to rest more quickly.&lt;/p&gt;
&lt;h2 id=&#34;variations-on-springs&#34;&gt;Variations on Springs&lt;/h2&gt;
&lt;p&gt;There are many different variations on spring-damper systems, but what I want to do is explain how to think generally in terms of what the forces are doing so that you can easily design spring and damper systems to achieve whatever effect you want.&lt;/p&gt;
&lt;p&gt;The first thing is that springs don&amp;rsquo;t only have to act to pull two points together so that they lie on top of each other. For example you can design spring forces that pull together or push apart two points apart so they maintain a desired separation distance from each other:&lt;/p&gt;
&lt;pre&gt;    &lt;strong&gt;F&lt;/strong&gt; = -k(|&lt;strong&gt;x&lt;/strong&gt;|-d)(&lt;strong&gt;x&lt;/strong&gt;/|&lt;strong&gt;x&lt;/strong&gt;|) - b&lt;strong&gt;v&lt;/strong&gt;&lt;/pre&gt;
&lt;p&gt;Where |&lt;strong&gt;x&lt;/strong&gt;| is the distance between the two points connected to the spring, d is the desired distance of separation, and &lt;strong&gt;x&lt;/strong&gt; / |&lt;strong&gt;x&lt;/strong&gt;| is the unit length direction vector between the two points: &lt;strong&gt;a&lt;/strong&gt; to &lt;strong&gt;b&lt;/strong&gt;, when applying the force to point &lt;strong&gt;a&lt;/strong&gt; and vice versa.&lt;/p&gt;
&lt;p&gt;The overall effect of the force equation above is to have a force which pushes the two points connected by the spring apart if they are closer than distance d, and bring the two points together if they are further than d apart. Notice how the force becomes exactly zero when the two points are at the target distance? If you tune the k and b parameters correctly you can have a nicely behaving spring that quickly brings the two points together smoothly over time and comes to rest at the solution point.&lt;/p&gt;
&lt;p&gt;But why apply springs to position only? If you want to accelerate a body over time such that it accelerates to a certain speed then you can calculate a spring force proportional to the difference between the current velocity and the target velocity, combined with a damping proportional to the current velocity so that it reaches its target over time instead of cycling about it. This is usually called a motor in physics simulation.&lt;/p&gt;
&lt;p&gt;We can even apply the same concept to drive the spinning of an object at a certain speed by applying a spring torque proportional to the difference between the current angular velocity and the desired angular velocity, coupled with a damper force proportional to the current angular velocity.&lt;/p&gt;
&lt;p&gt;Another commonly implemented spring constraint is to enforce a upright orientation of a body, for example, you could apply a spring torque proportional to the difference between the current orientation and an upright orientation, coupled with a damper proportional to angular velocity. Such a constraint is called a &amp;lsquo;stay upright constraint&amp;rsquo; and its often used for sci-fi hover racing games.&lt;/p&gt;
&lt;p&gt;As you can see, the applications of springs are limitless. The overall pattern is to design spring forces that will attract your physics simulation into the desired state and fade off to zero when this state is has been reached. In order to make sure that your physics objects don&amp;rsquo;t just oscillate around the solution but actually reach it, it is necessary to apply damping proportional to whatever physics state values are performing the evolution of the simulation towards the solution over time.&lt;/p&gt;
&lt;h2 id=&#34;attachment-using-a-spring&#34;&gt;Attachment using a Spring&lt;/h2&gt;
&lt;p&gt;So lets get started with an actual concrete implementation of using springs a simulation. The first thing we will implement is an attachment joint that will allow the user to click and drag a point on the cube to move it around. We will implement this by modeling a tight spring attachment between a target point and an attachment point on the body of the cube. This is effectively a ball and socket joint implemented using only spring forces and is implemented using the standard equation we are used to:&lt;/p&gt;
&lt;pre&gt;    &lt;strong&gt;F&lt;/strong&gt; = -k&lt;strong&gt;x&lt;/strong&gt; -b&lt;strong&gt;v&lt;/strong&gt;&lt;/pre&gt;
&lt;p&gt;Where x is the vector difference between the current target point and the attachment point on the object, and v is the point velocity at the attachment point on the object. The important thing is that this velocity v being the point velocity means that it incorporates both the linear motion of the object plus any velocity at the attachment point due to angular velocity. As was shown in the previous article we can calculate this point velocity at follows:&lt;/p&gt;
&lt;pre&gt;    &lt;strong&gt;v&lt;/strong&gt;&lt;sub&gt;point&lt;/sub&gt; = &lt;strong&gt;v&lt;/strong&gt;&lt;sub&gt;linear&lt;/sub&gt; + &lt;strong&gt;v&lt;/strong&gt;&lt;sub&gt;angular&lt;/sub&gt; &lt;em&gt;cross&lt;/em&gt; (&lt;strong&gt;p&lt;/strong&gt; - &lt;strong&gt;x&lt;/strong&gt;)&lt;/pre&gt;
&lt;p&gt;Where &lt;strong&gt;p&lt;/strong&gt; is the point on the rigid body and &lt;strong&gt;x&lt;/strong&gt; is the center of mass of the object. Secondly, this spring and damper force is not just applied linearly, but is applied at the attachment point on the object. This means that the spring force will apply both a linear force and a torque component as follows:&lt;/p&gt;
&lt;pre&gt;    &lt;strong&gt;F&lt;/strong&gt;&lt;sub&gt;linear&lt;/sub&gt; = &lt;strong&gt;F&lt;/strong&gt;
    &lt;strong&gt;F&lt;/strong&gt;&lt;sub&gt;torque&lt;/sub&gt; = &lt;strong&gt;F&lt;/strong&gt; cross (&lt;strong&gt;p&lt;/strong&gt; - &lt;strong&gt;x&lt;/strong&gt;)&lt;/pre&gt;
&lt;p&gt;The overall effect of this joint then is to bring the target and attachment points together while damping the motion of the object at the attachment point. This allows the object to move as long as remains still at the attachment. In other words the object is only allowed to move by rotating about the attachment point. Our simple ball and socket joint is now complete.&lt;/p&gt;
&lt;h2 id=&#34;collision-response-with-springs&#34;&gt;Collision Response with Springs&lt;/h2&gt;
&lt;p&gt;Next we will implement a basic collision response using springs. The trick here is to apply a spring and damper force that works against what we don&amp;rsquo;t want, eg. objects moving towards each other and penetrating other objects.&lt;/p&gt;
&lt;p&gt;So we have a collision detected and the usual information is returned to the physics system ready to apply collision response. This information is typically something like:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A unit length collision normal&lt;/li&gt;
&lt;li&gt;The penetration depth along the normal&lt;/li&gt;
&lt;li&gt;The physics state for each of the colliding objects at the time of collision&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All this information grouped together is called a contact. Processing collision geometry and returning a series of generic contacts is a great idea because it decouples your collision response from the gritty details of collision detection.&lt;/p&gt;
&lt;p&gt;Once we have all our contact information a simple collision response can be implemented by applying a spring-like force to the colliding objects to keep them apart:&lt;/p&gt;
&lt;pre&gt;    &lt;strong&gt;F&lt;/strong&gt; = &lt;strong&gt;n&lt;/strong&gt;kd - b&lt;strong&gt;n&lt;/strong&gt;(&lt;strong&gt;n&lt;/strong&gt;.&lt;strong&gt;v&lt;/strong&gt;)&lt;/pre&gt;
&lt;p&gt;Where k and b are the spring-damper coefficients, &lt;strong&gt;n&lt;/strong&gt; is the contact normal and &lt;strong&gt;v&lt;/strong&gt; is the relative velocity between the two objects at the point of collision. Effectively this equation calculates a spring force that pushes out along the contact normal while reducing the relative velocity of the objects towards each other at the contact point.&lt;/p&gt;
&lt;p&gt;Various different collision responses types can also be achieved using this equation, for example setting b to 0 gives a completely elastic collision response where all energy going into the collision returns in the bounce over time. Setting b to higher value tend to make the collision more inelastic because it removes more energy during the collision. Finally, by increasing and decreasing the spring constant k in concert with b you can make a collision that feels like anything from bouncing off a trampoline (low k and low b), to landing and sinking into quicksand (low k and high b), or landing with a splat on concrete (high k, high b).&lt;/p&gt;
&lt;h2 id=&#34;the-weakness-of-springs&#34;&gt;The Weakness of Springs&lt;/h2&gt;
&lt;p&gt;It seems we can achieve a large variety of different collision effects using only springs and easily make joints and constraints. Its not all good news however because springs come with their own set of weaknesses which I will now explain.&lt;/p&gt;
&lt;p&gt;The first weakness is that its difficult to tune the spring constants to get exactly the effect you want. For example, if you are attempting to model the real world physics of an object, you will need to experiment to find the spring k and b values that match the simulation. These values are usually dependent on other values of your simulation, such as the gravity constant, meaning that if you adjust gravity you&amp;rsquo;ll need to retune your springs to get the same effect.&lt;/p&gt;
&lt;p&gt;The next problem is that tighter the spring k you use, the more difficult it becomes to solve the differential equation. Using an RK4 integrator sure help with this, but even with RK4 there is a fundamental limit to how large you can make your spring k before your simulation will explode. At this point you need to either decrease your timestep or reduce your spring k.&lt;/p&gt;
&lt;p&gt;The final, and major weakness is that springs are reactive not predictive. This is a subtle point but a very important one. A joint or constraint implemented using springs only works by correcting errors after they occur, and collision response using springs requires allowing some amount of penetration before it acts to correct it and so forth. More advanced techniques exist which can solve for the forces required to constrain the physics simulation without inducing error, such as LCP solvers or iterative methods, but they are out of scope of this simple article.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NEXT ARTICLE:&lt;/strong&gt; &lt;a href=&#34;https://gafferongames.com/post/networked_physics_2004/&#34;&gt;Networked Physics (2004)&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Glenn Fiedler&lt;/strong&gt; is the founder and CEO of &lt;strong&gt;&lt;a href=&#34;https://networknext.com&#34;&gt;Network Next&lt;/a&gt;&lt;/strong&gt;.&lt;br&gt;&lt;i&gt;Network Next is fixing the internet for games by creating a marketplace for premium network transit.&lt;/i&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Physics in 3D</title>
      <link>https://gafferongames.com/post/physics_in_3d/</link>
      <pubDate>Thu, 02 Sep 2004 00:00:00 +0000</pubDate>
      
      <guid>https://gafferongames.com/post/physics_in_3d/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Hi, I&amp;rsquo;m &lt;a href=&#34;https://gafferongames.com&#34;&gt;Glenn Fiedler&lt;/a&gt; and welcome to &lt;strong&gt;&lt;a href=&#34;https://gafferongames.com/categories/game-physics/&#34;&gt;Game Physics&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In the &lt;a href=&#34;https://gafferongames.com/post/fix_your_timestep/&#34;&gt;previous article&lt;/a&gt; we discussed how to integrate our physics simulation forward at fixed delta time increments, regardless of display framerate.&lt;/p&gt;
&lt;p&gt;In this article we are going to simulate motion in three dimensions.&lt;/p&gt;
&lt;h2 id=&#34;rigid-bodies&#34;&gt;Rigid Bodies&lt;/h2&gt;
&lt;p&gt;We will concentrate on a type of object called a &lt;strong&gt;rigid body&lt;/strong&gt;. Rigid bodies cannot bend, compress or deform in any way. This makes their motion much easier to calculate.&lt;/p&gt;
&lt;p&gt;To simulate the motion of rigid bodies, we must study both rigid body kinematics and rigid body dynamics. Kinematics is the study of how an object moves in the absence of forces, while dynamics describes how an object reacts to them. Together they provide all the information you need to simulate the motion of a rigid body in three dimensions.&lt;/p&gt;
&lt;p&gt;Along the way I will show you how to integrate vector quantities, handle rotations in three dimensions and integrate to find the motion of your object as it moves and spins around the world.&lt;/p&gt;
&lt;h2 id=&#34;moving-in-the-third-dimension&#34;&gt;Moving in the Third Dimension&lt;/h2&gt;
&lt;p&gt;As long as we only have single floating point values for position and velocity our physics simulation is limited to motion in a single dimension, and a point moving from side to side on the screen is pretty boring!&lt;/p&gt;
&lt;p&gt;We want our object to be able to move in three dimensions: left and right, forward and back, up and down. If we apply the equations of motion to each dimension separately, we can integrate each dimension in turn to find the motion of the object in three dimensions.&lt;/p&gt;
&lt;p&gt;Or&amp;hellip; we could just use vectors.&lt;/p&gt;
&lt;p&gt;Vectors are a mathematical type representing an array of numbers. A three dimensional vector has three components x, y and z. Each component corresponds to a dimension. In this article x is left and right, y is up and down, and z is forward and back.&lt;/p&gt;
&lt;p&gt;In C++ we implement vectors using a struct as follows:&lt;/p&gt;
&lt;pre&gt;
    struct Vector
    {
         float x,y,z;
    };
&lt;/pre&gt;
&lt;p&gt;Addition of two vectors is defined as adding each component together. Multiplying a vector by a floating point number is the same as just multiplying each component. Lets add overloaded operators to the vector struct so that we can perform these operations in code as if vectors are a native type:&lt;/p&gt;
&lt;pre&gt;
    struct Vector
    {
         float x,y,z;

         Vector operator + ( const Vector &amp;amp;other )
         {
              Vector result;
              result.x = x + other.x;
              result.y = y + other.y;
              result.z = z + other.z;
              return result;
         }

         Vector operator*( float scalar )
         {
              Vector result;
              result.x = x * scalar;
              result.y = y * scalar;
              result.z = z * scalar;
              return result;
         }
    };
&lt;/pre&gt;
&lt;p&gt;Now instead of maintaining completely seperate equations of motion and integrating seperately for x, y and z, we convert our position, velocity, acceleration and force to vector quantities, then integrate the vectors directly using the equations of motion from the &lt;a href=&#34;https://gafferongames.com/post/integration_basics/&#34;&gt;first article&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;
    &lt;b&gt;F&lt;/b&gt; = m&lt;b&gt;a&lt;/b&gt;
    d&lt;b&gt;v&lt;/b&gt;/dt = &lt;b&gt;a&lt;/b&gt;
    d&lt;b&gt;x&lt;/b&gt;/dt = &lt;b&gt;v&lt;/b&gt;
&lt;/pre&gt;
&lt;p&gt;Notice how &lt;b&gt;F&lt;/b&gt;, &lt;b&gt;a&lt;/b&gt;, &lt;b&gt;v&lt;/b&gt; and &lt;b&gt;x&lt;/b&gt; are written in bold. This is the convention used to distinguish vector quantities from single value (scalar) quantities such as mass m and time t.&lt;/p&gt;
&lt;p&gt;Now that we have the equations of motion in vector form, how do we integrate them? The answer is exactly the same as we integrated single values. This is because we have already added overloaded operators for adding two vectors together, and multiplying a vector by a scalar, and this is all we need to be able to drop in vectors in place of floats and have everything just work.&lt;/p&gt;
&lt;p&gt;For example, here is a simple Euler integration for vector position from velocity:&lt;/p&gt;
&lt;pre&gt;
    position = position + velocity * dt;
&lt;/pre&gt;
&lt;p&gt;Notice how the overloaded operators make it look exactly the same as an Euler integration for a single value. But what is it really doing? Lets take a look at how we would implement vector integration without the overloaded operators:&lt;/p&gt;
&lt;pre&gt;
    position.x = position.x + velocity.x * dt;
    position.y = position.y + velocity.y * dt;
    position.z = position.z + velocity.z * dt;
&lt;/pre&gt;
&lt;p&gt;As you can see, its exactly the same as if we integrated each component of the vector separately! This is the cool thing about vectors. Whether we integrate vectors directly, or integrate each component separately, we are doing exactly the same thing.&lt;/p&gt;
&lt;h2 id=&#34;structuring-for-rk4&#34;&gt;Structuring for RK4&lt;/h2&gt;
&lt;p&gt;In the example programs from previous articles we drove the simulation from acceleration assuming unit mass. This kept the code nice and simple, but from now on every object will have its own mass in kilograms so the simulation needs be driven by forces instead.&lt;/p&gt;
&lt;p&gt;There are two ways we can do this. First, we can divide force by mass to get acceleration, then integrate this acceleration to get the velocity, and integrate velocity to get position.&lt;/p&gt;
&lt;p&gt;The second way is to integrate force directly to get momentum, then convert this momentum to velocity by dividing it by mass, then finally integrate velocity to get position. Remember that momentum is just velocity multiplied by mass:&lt;/p&gt;
&lt;pre&gt;
    d&lt;b&gt;p&lt;/b&gt;/dt = &lt;b&gt;F&lt;/b&gt;
    &lt;b&gt;v&lt;/b&gt; = &lt;b&gt;p&lt;/b&gt;/m
    d&lt;b&gt;x&lt;/b&gt;/dt = &lt;b&gt;v&lt;/b&gt;
&lt;/pre&gt;
&lt;p&gt;Both methods work, but the second way is more consistent with the way that we must approach rotation later in the article, so we&amp;rsquo;ll use that.&lt;/p&gt;
&lt;p&gt;When we switch to momentum we need to make sure that the velocity is recalculated after each integration by dividing momentum by mass. Doing this manually everywhere that momentum is changed would be error prone, so we now separate all our state quantities into primary, secondary and constant values, and add a method called &amp;lsquo;recalculate&amp;rsquo; to the State struct which is responsible for updating all the secondary values from the primary ones:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    struct State
    {
        // primary
        Vector position;
        Vector momentum;

        // secondary
        Vector velocity;

        // constant
        float mass;
        float inverseMass;

        void recalculate()
        {
            velocity = momentum * inverseMass;
        }
    };

    struct Derivative
    {
        Vector velocity;
        Vector force;
    };
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we make sure that recalculate is called whenever any of the primary values change, then our secondary values will always stay in sync. This may seem like overkill just to handle converting momentum to velocity, but as our simulation becomes more complex we will have many more secondary values, so it is important to design a system that handles this.&lt;/p&gt;
&lt;h2 id=&#34;spinning-around&#34;&gt;Spinning Around&lt;/h2&gt;
&lt;p&gt;So far we have covered linear motion, we can simulate an rigid body so that it moves in 3D space, but it cannot rotate yet.&lt;/p&gt;
&lt;p&gt;The good news is that rotational equivalents to force, momentum, velocity, position and mass exist, and once we understand how they work, integration of rotational physics state can be performed using our RK4 integrator.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s start off by talking about how rigid bodies rotate. Because our objects are rigid they cannot deform. This means that we can treat the linear and rotational parts of an object&amp;rsquo;s motion as being entirely separate: a linear component (position, velocity, momentum, mass) and a rotational component rotating about the center of mass.&lt;/p&gt;
&lt;p&gt;How do we represent how the object is rotating? If you think about it a bit, you&amp;rsquo;ll realize that for a rigid body rotation can only ever be around a single axis, so the first thing we need to know is what that axis is. We can represent this axis with a unit length vector. Next we need to know how fast the object is rotating about this axis in radians per second.&lt;/p&gt;
&lt;p&gt;If we know the center of mass of the object, the axis of rotation, and the speed of rotation then we have the all the information we need to describe how it is rotating.&lt;/p&gt;
&lt;p&gt;The standard way of representing rotation over time is by combining the axis and the speed of rotation into a single vector called angular velocity. The length of the angular velocity vector is the speed of rotation in radians while the direction of the vector indicates the axis of rotation. For example, an angular velocity of (2Pi,0,0) indicates a rotation about the x axis doing one revolution per second.&lt;/p&gt;
&lt;p&gt;But what direction is this rotation in? In the example source code I use a right handed coordinate system which is standard when using OpenGL. To find the direction of rotation just take your right hand and point your thumb down the axis, your fingers curl in the direction of rotation. If your 3D engine uses a left handed coordinate system then just use your left hand instead.&lt;/p&gt;
&lt;p&gt;Why do we combine the axis and rate of rotation into a single vector? Doing so gives us a single vector quantity that is easy to manipulate just like velocity for linear motion. We can easily add and subtract changes to angular velocity to change how the object is rotating just like we can add and subtract from linear velocity. If we stuck with a unit length vector and scalar for rotation speed then it would be much more complicated to apply these changes.&lt;/p&gt;
&lt;p&gt;But there is one very important difference between linear and angular velocity. Unlike linear velocity, there is no guarantee that angular velocity will remain constant over time in the absence of forces. In other words, angular momentum is conserved while angular velocity is not. This means that we cannot trust angular velocity as a primary value and we need to use angular momentum instead.&lt;/p&gt;
&lt;h2 id=&#34;angular-momentum-inertia-and-torque&#34;&gt;Angular Momentum, Inertia and Torque&lt;/h2&gt;
&lt;p&gt;Just as velocity and momentum are related by mass in linear motion, angular velocity and angular momentum are related by a quantity called the rotational inertia. This tensor is a measurement of how much effort it takes to spin an object around an axis. It depends on both the shape of the object and how much it weighs.&lt;/p&gt;
&lt;p&gt;In the general case, rotational inertia is represented by a 3x3 matrix called an inertia tensor. Here we make a simplifying assumption by discussing physics in the context of simulating a cube. Because of the symmetries of the cube, we only need a single value for the rotational inertia: 1/6 x size^2 x mass, where size is the length of the sides of the cube.&lt;/p&gt;
&lt;p&gt;Just as we integrate linear momentum from force, we integrate angular momentum directly from the rotational equivalent of force called torque. You can think of torque just like a force, except that when it is applied it induces a rotation around an axis in the direction of torque vector rather than accelerating the object linearly. For example, a torque of (1,0,0) would cause a stationary object to start rotating about the x axis.&lt;/p&gt;
&lt;p&gt;Once we have angular momentum integrated, we multiply it by the inverse of the rotational inertia to get the angular velocity, and using this angular velocity we integrate to get the rotational equivalent of position called orientation.&lt;/p&gt;
&lt;p&gt;However, as we will see, integrating orientation from angular velocity is a bit more complicated!&lt;/p&gt;
&lt;h2 id=&#34;orientation-in-3d&#34;&gt;Orientation in 3D&lt;/h2&gt;
&lt;p&gt;This complexity is due to the difficulty of representing orientations in three dimensions.&lt;/p&gt;
&lt;p&gt;In two dimensions orientations are easy, you just keep track of an angle in radians and you are done. In three dimensions it becomes much more complex. It turns out that you must either use 3x3 rotation matrices or quaternions to correctly represent the orientation of an object.&lt;/p&gt;
&lt;p&gt;For reasons of simplicity and efficiency I&amp;rsquo;m going to use quaternions to represent the orientation instead of matrices. This also gives us an easy way to interpolate between the previous and current physics orientation to get smooth framerate independent animation as per the time stepping scheme outlined in the &lt;a href=&#34;https://gafferongames.com/post/fix_your_timestep/&#34;&gt;previous article&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Now there are plenty of resources on the internet which explain what quaternions are and how unit length quaternions are used to represent rotations in three dimensions. Here is a particularly &lt;a href=&#34;http://www.sjbrown.co.uk/quaternions.html&#34;&gt;nice one&lt;/a&gt;. What you need to know however is that, effectively, unit quaternions represent an axis of rotation and an amount of rotation about that axis. This may seem similar to our angular velocity, but quaternions are four dimensional vectors instead of three, so mathematically they are actually quite different!&lt;/p&gt;
&lt;p&gt;We will represent quaternions in code as another struct:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    struct Quaternion
    {
        float w,x,y,z;
    };
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we define the rotation of a quaternion as being relative to an initial orientation of the object (what we will later call body coordinates) then we can use this quaternion to represent the orientation of the object at any point in time. Now that we have decided on the representation to use for orientation, we need to integrate it over time so that the object rotates according to the angular velocity.&lt;/p&gt;
&lt;h2 id=&#34;integrating-orientation&#34;&gt;Integrating Orientation&lt;/h2&gt;
&lt;p&gt;We are now presented with a problem. Orientation is a quaternion but angular velocity is a vector. How can we integrate orientation from angular velocity when the two quantities are in different mathematical forms?&lt;/p&gt;
&lt;p&gt;The solution is to convert angular velocity into a quaternion form, then to use this quaternion to integrate orientation. For lack of a better term I will call this time derivative of orientation &amp;ldquo;spin&amp;rdquo;. Exactly how to calculate this spin quaternion is described in detail &lt;a href=&#34;http://www-2.cs.cmu.edu/~baraff/sigcourse/notesd1.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here is the final result:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    d*q*/dt = spin = 0.5 *w* *q*
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Where &lt;strong&gt;q&lt;/strong&gt; is the current orientation quaternion, and &lt;strong&gt;w&lt;/strong&gt; is the current angular velocity in quaternion form (0,x,y,z) such that x, y, z are the components of the angular velocity vector. Note that the multiplication done between &lt;strong&gt;w&lt;/strong&gt; and &lt;strong&gt;q&lt;/strong&gt; is quaternion multiplication.&lt;/p&gt;
&lt;p&gt;To implement this in code we add spin as a new secondary quantity calculated from angular velocity in the recalculate method. We also add spin to the derivatives struct as it is the derivative of orientation:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    struct State
    {
        // primary
        Quaternion orientation;
        Vector angularMomentum;

        // secondary
        Quaternion spin;
        Vector angularVelocity;

        // constant
        float inertia;
        float inverseInertia;

        void recalculate()
        {
            angularVelocity = angularMomentum * 
                               inverseInertia;

            orientation.normalize();

            Quaternion q( 0, 
                          angularVelocity.x, 
                          angularVelocity.y, 
                          angularVelocity.z ) 

            spin = 0.5f * q * orientation;
        }
    };

    struct Derivatives
    {
        Quaternion spin;
        Vector torque;
    };
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Integrating a quaternion, just like integrating a vector, is as simple as doing the integration for each value separately. The only difference is that after integrating orientation we must renormalize the orientation quaternion to make it unit length, to ensure that it still represents a rotation.&lt;/p&gt;
&lt;p&gt;This is required because errors in integration accumulate over time and make the quaternion &amp;lsquo;drift&amp;rsquo; away from being unit length. I like to renormalize in the recalculate method for simplicity, but you can get away with doing it less frequently if cpu cycles are tight.&lt;/p&gt;
&lt;p&gt;Now in order to drive the rotation of the object, we need a method that can calculate the torque applied given the current rotational state and time just like the force method we use when integrating linear motion. eg:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    Vector torque( const State &amp;amp; state, double t )
    {
        return Vector(1,0,0) - state.angularVelocity * 0.1f;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This function returns an acceleration torque to induce a spin around the x axis, but also applies a damping over time so that at a certain speed the accelerating and damping will cancel each other out. This is done so that the rotation will reach a certain rate and stay constant instead of getting faster and faster over time.&lt;/p&gt;
&lt;h2 id=&#34;combining-linear-and-angular-motion&#34;&gt;Combining Linear and Angular Motion&lt;/h2&gt;
&lt;p&gt;Now that we are able to integrate linear and rotational effects, how can they be combined into one simulation? The answer is to just integrate the linear and rotational physics state separately and everything works out. This is because the objects we are simulating are rigid so we can decompose their motion into separate linear and rotational components. As far as integration is concerned, you can treat linear and angular effects as being completely independent of each other.&lt;/p&gt;
&lt;p&gt;Now that we have an object that is translating and rotating through three dimensional space, we need a way to keep track of where it is. We must now introduce the concepts of body coordinates and world coordinates.&lt;/p&gt;
&lt;p&gt;Think of body coordinates in terms of the object in a convenient layout, for example its center of mass would be at the origin (0,0,0) and it would be oriented in the simplest way possible. In the case of the simulation that accompanies this article, in body space the cube is oriented so that it lines up with the x, y and z axes and the center of the cube is at the origin.&lt;/p&gt;
&lt;p&gt;The important thing to understand is that the object remains stationary in body space, and is transformed into world space using a combination of translation and rotation operations which put it in the correct position and orientation for rendering. When you see the cube animating on screen it is because it is being drawn in world space using the body to world transformation.&lt;/p&gt;
&lt;p&gt;We have the raw materials to implement this transform from body coordinates into world coordinates in the position vector and the orientation quaternion. The trick to combining the two is to convert each of them into 4x4 matrix form which is capable of representing both rotation and translation. Then we combine the two transformations into a single matrix by multiplication. This combined matrix has the effect of first rotating the cube around the origin to get the correct orientation, then translating the cube to the correct position in world space. See &lt;a href=&#34;http://www.gamedev.net/reference/articles/article695.asp&#34;&gt;this article&lt;/a&gt; for details on how this is done.&lt;/p&gt;
&lt;p&gt;If we then invert this matrix we get one that has the opposite effect, it transforms points in world coordinates into the body coordinates of the object. Once we have both these matrices we have the ability to convert points from body to world coordinates and back again which is very handy. These two matrices become new secondary values calculated in the &amp;lsquo;recalculate&amp;rsquo; method from the orientation quaternion and position vector.&lt;/p&gt;
&lt;h2 id=&#34;forces-and-torques&#34;&gt;Forces and Torques&lt;/h2&gt;
&lt;p&gt;We can apply separate forces and torques to an object individually, but we know from real life that if we push an object it usually makes it both move and rotate. So how can we break down a force applied at a point on the object into a linear force which causes a change in momentum, and a torque which changes angular momentum?&lt;/p&gt;
&lt;p&gt;Given that our object is a rigid body, what actually happens here is that the entire force applied at the point is applied linearly, plus a torque is also generated based on the cross product of the force vector and the point on the object relative to the center of mass of the object:&lt;/p&gt;
&lt;pre&gt;
    &lt;b&gt;F&lt;/b&gt;&lt;sub&gt;linear&lt;/sub&gt; = &lt;b&gt;F&lt;/b&gt;
    &lt;b&gt;F&lt;/b&gt;&lt;sub&gt;torque&lt;/sub&gt; = &lt;b&gt;F&lt;/b&gt; x (&lt;b&gt;p&lt;/b&gt; - &lt;b&gt;x&lt;/b&gt;)
&lt;/pre&gt;
&lt;p&gt;Where &lt;b&gt;F&lt;/b&gt; is the force being applied at point &lt;b&gt;p&lt;/b&gt; in world coordinates, and &lt;b&gt;x&lt;/b&gt; is the center of mass of the object.&lt;/p&gt;
&lt;p&gt;This seems counterintuitive at first. Why is the force being applied twice? Once to linear and once to rotational motion?&lt;/p&gt;
&lt;p&gt;What is happening here is our everyday experience with objects clouding the true behavior of an object under ideal conditions.&lt;/p&gt;
&lt;p&gt;Remember your pushbike when you were a kid? You would have to change your tire and flip the bike upside down. You could spin the tire around by pushing on it. You don&amp;rsquo;t see any linear motion here, just rotation, so what is going on? The answer of course is that the axle of the wheel is counteracting the linear component of the force you applied, leaving only the rotational component. Not convinced? Imagine what would happen if you tried to ride your bike without an axle in your wheel&amp;hellip;&lt;/p&gt;
&lt;p&gt;Another example: consider a bowling ball lying on a slippery surface such as ice so that no significant friction is present. Now in your mind try to work out a way that you can apply a force at a single point on the surface of the bowling ball such that it will stay completely still while rotating on the spot. There is no way you can do this! Any point where you push would also make the bowling ball move linearly as well as rotate. To apply a pure rotation you&amp;rsquo;d have to push on both sides of the ball, canceling the linear component of your force out leaving only torque.&lt;/p&gt;
&lt;p&gt;So remember, whenever you apply a force to an object there will always be a linear force component which causes the object to accelerate linearly, as well as, depending on the direction of the force, a rotational component that causes the object to rotate.&lt;/p&gt;
&lt;h2 id=&#34;velocity-at-a-pointb&#34;&gt;Velocity at a Point&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The final piece of the puzzle is how to calculate the velocity of a single point in the rigid body. To do this we start with the linear velocity of the object, because all points must move with this velocity to keep it rigid, then add the velocity at the point due to rotation.&lt;/p&gt;
&lt;p&gt;This velocity due to rotation will not be constant for every point in the body if it is rotating, as each point in the body must be spinning around the axis of rotation. Combining the linear and angular velocities, the total velocity of a point in the rigid body is:&lt;/p&gt;
&lt;pre&gt;
    &lt;b&gt;v&lt;/b&gt;&lt;sub&gt;point&lt;/sub&gt; = &lt;b&gt;v&lt;/b&gt;&lt;sub&gt;linear&lt;/sub&gt; + &lt;b&gt;v&lt;/b&gt;&lt;sub&gt;angular&lt;/sub&gt; cross (&lt;b&gt;p&lt;/b&gt; - &lt;b&gt;x&lt;/b&gt;)
&lt;/pre&gt;
&lt;p&gt;Where &lt;b&gt;p&lt;/b&gt; is the point on the rigid body and &lt;b&gt;x&lt;/b&gt; is the center of mass of the object.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;We have covered the techniques required to simulate linear and rotational movement of a rigid body in three dimensions. By combining the linear and rotational physics into a single physics state and integrating, we can simulate the motion of a rigid body in three dimensions.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NEXT ARTICLE:&lt;/strong&gt; &lt;a href=&#34;https://gafferongames.com/post/spring_physics/&#34;&gt;Spring Physics&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Glenn Fiedler&lt;/strong&gt; is the founder and CEO of &lt;strong&gt;&lt;a href=&#34;https://networknext.com&#34;&gt;Network Next&lt;/a&gt;&lt;/strong&gt;.&lt;br&gt;&lt;i&gt;Network Next is fixing the internet for games by creating a marketplace for premium network transit.&lt;/i&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Fix Your Timestep!</title>
      <link>https://gafferongames.com/post/fix_your_timestep/</link>
      <pubDate>Thu, 10 Jun 2004 00:00:00 +0000</pubDate>
      
      <guid>https://gafferongames.com/post/fix_your_timestep/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Hi, I&amp;rsquo;m &lt;a href=&#34;https://gafferongames.com&#34;&gt;Glenn Fiedler&lt;/a&gt; and welcome to &lt;strong&gt;&lt;a href=&#34;https://gafferongames.com/categories/game-physics/&#34;&gt;Game Physics&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In the &lt;a href=&#34;https://gafferongames.com/post/integration_basics/&#34;&gt;previous article&lt;/a&gt; we discussed how to integrate the equations of motion using a numerical integrator. Integration sounds complicated, but it&amp;rsquo;s just a way to advance the your physics simulation forward by some small amount of time called &amp;ldquo;delta time&amp;rdquo; (or dt for short).&lt;/p&gt;
&lt;p&gt;But how to choose this delta time value? This may seem like a trivial subject but in fact there are many different ways to do it, each with their own strengths and weaknesses - so read on!&lt;/p&gt;
&lt;h2 id=&#34;fixed-delta-time&#34;&gt;Fixed delta time&lt;/h2&gt;
&lt;p&gt;The simplest way to step forward is with fixed delta time, like 1/60th of a second:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    double t = 0.0;
    double dt = 1.0 / 60.0;

    while ( !quit )
    {
        integrate( state, t, dt );
        render( state );
        t += dt;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In many ways this code is ideal. If you&amp;rsquo;re lucky enough to have your delta time match the display refresh rate, and you can ensure that your update loop takes less than one frame worth of real time, then you already have the perfect solution for updating your physics simulation and you can stop reading this article.&lt;/p&gt;
&lt;p&gt;But in the real world you may not know the display refresh rate ahead of time. VSYNC could be turned off, or you could be running on a slow computer which cannot update and render your frame fast enough to present it at 60fps.&lt;/p&gt;
&lt;p&gt;In these cases your simulation will run faster or slower than you intended.&lt;/p&gt;
&lt;h2 id=&#34;variable-delta-time&#34;&gt;Variable delta time&lt;/h2&gt;
&lt;p&gt;Fixing this &lt;em&gt;seems&lt;/em&gt; simple. Just measure how long the previous frame takes, then feed that value back in as the delta time for the next frame. This makes sense because of course, because if the computer is too slow to update at 60HZ and has to drop down to 30fps, you&amp;rsquo;ll automatically pass in 1/30 as delta time. Same thing for a display refresh rate of 75HZ instead of 60HZ or even the case where VSYNC is turned off on a fast computer:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    double t = 0.0;

    double currentTime = hires_time_in_seconds();

    while ( !quit )
    {
        double newTime = hires_time_in_seconds();
        double frameTime = newTime - currentTime;
        currentTime = newTime;

        integrate( state, t, frameTime );
        t += frameTime;

        render( state );
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But there is a huge problem with this approach which I will now explain. The problem is that the behavior of your physics simulation depends on the delta time you pass in. The effect could be subtle as your game having a slightly different &amp;ldquo;feel&amp;rdquo; depending on framerate or it could be as extreme as your spring simulation exploding to infinity, fast moving objects tunneling through walls and players falling through the floor!&lt;/p&gt;
&lt;p&gt;One thing is for certain though and that is that it&amp;rsquo;s utterly unrealistic to expect your simulation to correctly handle &lt;em&gt;any&lt;/em&gt; delta time passed into it. To understand why, consider what would happen if you passed in 1/10th of a second as delta time? How about one second? 10 seconds? 100? Eventually you&amp;rsquo;ll find a breaking point.&lt;/p&gt;
&lt;h2 id=&#34;semi-fixed-timestep&#34;&gt;Semi-fixed timestep&lt;/h2&gt;
&lt;p&gt;It&amp;rsquo;s much more realistic to say that your simulation is well behaved only if delta time is less than or equal to some maximum value. This is usually significantly easier in practice than attempting to make your simulation bulletproof at a wide range of delta time values.&lt;/p&gt;
&lt;p&gt;With this knowledge at hand, here&amp;rsquo;s a simple trick to ensure that you never pass in a delta time greater than the maximum value, while still running at the correct speed on different machines:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    double t = 0.0;
    double dt = 1 / 60.0;

    double currentTime = hires_time_in_seconds();

    while ( !quit )
    {
        double newTime = hires_time_in_seconds();
        double frameTime = newTime - currentTime;
        currentTime = newTime;
              
        while ( frameTime &amp;gt; 0.0 )
        {
            float deltaTime = min( frameTime, dt );
            integrate( state, t, deltaTime );
            frameTime -= deltaTime;
            t += deltaTime;
        }

        render( state );
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The benefit of this approach is that we now have an upper bound on delta time. It&amp;rsquo;s never larger than this value because if it is we subdivide the timestep. The disadvantage is that we&amp;rsquo;re now taking multiple steps per-display update including one additional step to consume any the remainder of frame time not divisible by dt. This is no problem if you are render bound, but if your simulation is the most expensive part of your frame you could run into the so called &amp;ldquo;spiral of death&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;What is the spiral of death? It&amp;rsquo;s what happens when your physics simulation can&amp;rsquo;t keep up with the steps it&amp;rsquo;s asked to take. For example, if your simulation is told: &amp;ldquo;OK, please simulate X seconds worth of physics&amp;rdquo; and if it takes Y seconds of real time to do so where Y &amp;gt; X, then it doesn&amp;rsquo;t take Einstein to realize that over time your simulation falls behind. It&amp;rsquo;s called the spiral of death because being behind causes your update to simulate more steps to catch up, which causes you to fall further behind, which causes you to simulate more steps&amp;hellip;&lt;/p&gt;
&lt;p&gt;So how do we avoid this? In order to ensure a stable update I recommend leaving some headroom. You really need to ensure that it takes &lt;em&gt;significantly less&lt;/em&gt; than X seconds of real time to update X seconds worth of physics simulation. If you can do this then your physics engine can &amp;ldquo;catch up&amp;rdquo; from any temporary spike by simulating more frames. Alternatively you can clamp at a maximum # of steps  per-frame and the simulation will appear to slow down under heavy load. Arguably this is better than spiraling to death, especially if the heavy load is just a temporary spike.&lt;/p&gt;
&lt;h2 id=&#34;free-the-physics&#34;&gt;Free the physics&lt;/h2&gt;
&lt;p&gt;Now let&amp;rsquo;s take it one step further. What if you want exact reproducibility from one run to the next given the same inputs? This comes in handy when trying to network your physics simulation using deterministic lockstep, but it&amp;rsquo;s also generally a nice thing to know that your simulation behaves exactly the same from one run to the next without any potential for different behavior depending on the render framerate.&lt;/p&gt;
&lt;p&gt;But you ask why is it necessary to have fully fixed delta time to do this? Surely the semi-fixed delta time with the small remainder step is &amp;ldquo;good enough&amp;rdquo;? And yes, you are right. It is &lt;em&gt;good enough&lt;/em&gt; in most cases but it is not &lt;em&gt;exactly the same&lt;/em&gt; due to to the limited precision of floating point arithmetic.&lt;/p&gt;
&lt;p&gt;What we want then is the best of both worlds: a fixed delta time value for the simulation plus the ability to render at different framerates. These two things seem completely at odds, and they are - unless we can find a way to decouple the simulation and rendering framerates.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s how to do it. Advance the physics simulation ahead in fixed dt time steps while also making sure that it keeps up with the timer values coming from the renderer so that the simulation advances at the correct rate. For example, if the display framerate is 50fps and the simulation runs at 100fps then we need to take two physics steps every display update. Easy.&lt;/p&gt;
&lt;p&gt;What if the display framerate is 200fps? Well in this case it we need to take half a physics step each display update, but we can&amp;rsquo;t do that, we must advance with constant dt. So we take one physics step every two display updates.&lt;/p&gt;
&lt;p&gt;Even trickier, what if the display framerate is 60fps, but we want our simulation to run at 100fps? There is no easy multiple. What if VSYNC is disabled and the display frame rate fluctuates from frame to frame?&lt;/p&gt;
&lt;p&gt;If you head just exploded don&amp;rsquo;t worry, all that is needed to solve this is to change your point of view. Instead of thinking that you have a certain amount of frame time you must simulate before rendering, flip your viewpoint upside down and think of it like this: the renderer &lt;strong&gt;produces time&lt;/strong&gt; and the simulation &lt;strong&gt;consumes it&lt;/strong&gt; in discrete dt sized steps.&lt;/p&gt;
&lt;p&gt;For example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    double t = 0.0;
    const double dt = 0.01;

    double currentTime = hires_time_in_seconds();
    double accumulator = 0.0;

    while ( !quit )
    {
        double newTime = hires_time_in_seconds();
        double frameTime = newTime - currentTime;
        currentTime = newTime;

        accumulator += frameTime;

        while ( accumulator &amp;gt;= dt )
        {
            integrate( state, t, dt );
            accumulator -= dt;
            t += dt;
        }

        render( state );
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice that unlike the semi-fixed timestep we only ever integrate with steps sized dt so it follows that in the common case we have some unsimulated time left over at the end of each frame. This left over time is passed on to the next frame via the accumulator variable and is not thrown away.&lt;/p&gt;
&lt;h2 id=&#34;the-final-touch&#34;&gt;The final touch&lt;/h2&gt;
&lt;p&gt;But what do to with this remaining time? It seems incorrect doesn&amp;rsquo;t it?&lt;/p&gt;
&lt;p&gt;To understand what is going on consider a situation where the display framerate is 60fps and the physics is running at 50fps. There is no nice multiple so the accumulator causes the simulation to alternate between mostly taking one and occasionally two physics steps per-frame when the remainders &amp;ldquo;accumulate&amp;rdquo; above dt.&lt;/p&gt;
&lt;p&gt;Now consider that the majority of render frames will have some small remainder of frame time left in the accumulator that cannot be simulated because it is less than dt. This means we&amp;rsquo;re displaying the state of the physics simulation at a time slightly different from the render time, causing a subtle but visually unpleasant stuttering of the physics simulation on the screen.&lt;/p&gt;
&lt;p&gt;One solution to this problem is to interpolate between the previous and current physics state based on how much time is left in the accumulator:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    double t = 0.0;
    double dt = 0.01;

    double currentTime = hires_time_in_seconds();
    double accumulator = 0.0;

    State previous;
    State current;

    while ( !quit )
    {
        double newTime = time();
        double frameTime = newTime - currentTime;
        if ( frameTime &amp;gt; 0.25 )
            frameTime = 0.25;
        currentTime = newTime;

        accumulator += frameTime;

        while ( accumulator &amp;gt;= dt )
        {
            previousState = currentState;
            integrate( currentState, t, dt );
            t += dt;
            accumulator -= dt;
        }

        const double alpha = accumulator / dt;

        State state = currentState * alpha + 
            previousState * ( 1.0 - alpha );

        render( state );
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This &lt;em&gt;looks&lt;/em&gt; complicated but here is a simple way to think about it. Any remainder in the accumulator is effectively a measure of just how much more time is required before another whole physics step can be taken. For example, a remainder of dt/2 means that we are currently halfway between the current physics step and the next. A remainder of dt*0.1 means that the update is 1/10th of the way between the current and the next state.&lt;/p&gt;
&lt;p&gt;We can use this remainder value to get a blending factor between the previous and current physics state simply by dividing by dt. This gives an alpha value in the range [0,1] which is used to perform a linear interpolation between the two physics states to get the current state to render. This interpolation is easy to do for single values and for vector state values. You can even use it with full 3D rigid body dynamics if you store your orientation as a quaternion and use a spherical linear interpolation (slerp) to blend between the previous and current orientations.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NEXT ARTICLE:&lt;/strong&gt; &lt;a href=&#34;https://gafferongames.com/post/physics_in_3d/&#34;&gt;Physics in 3D&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Glenn Fiedler&lt;/strong&gt; is the founder and CEO of &lt;strong&gt;&lt;a href=&#34;https://networknext.com&#34;&gt;Network Next&lt;/a&gt;&lt;/strong&gt;.&lt;br&gt;&lt;i&gt;Network Next is fixing the internet for games by creating a marketplace for premium network transit.&lt;/i&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Integration Basics</title>
      <link>https://gafferongames.com/post/integration_basics/</link>
      <pubDate>Tue, 01 Jun 2004 00:00:00 +0000</pubDate>
      
      <guid>https://gafferongames.com/post/integration_basics/</guid>
      <description>&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Hi, I&amp;rsquo;m &lt;a href=&#34;https://gafferongames.com&#34;&gt;Glenn Fiedler&lt;/a&gt; and welcome to &lt;strong&gt;&lt;a href=&#34;https://gafferongames.com/categories/game-physics/&#34;&gt;Game Physics&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;If you have ever wondered how the physics simulation in a computer game works then this series of articles will explain it for you. I assume you are proficient with C++ and have a basic grasp of physics and mathematics. Nothing else will be required if you pay attention and study the example source code.&lt;/p&gt;
&lt;p&gt;A physics simulation works by making many small predictions based on the laws of physics. These predictions are actually quite simple, and basically boil down to something like &amp;ldquo;the object is here, and is traveling this fast in that direction, so in a short amount of time it should be over there&amp;rdquo;. We perform these predictions using a mathematical technique called integration.&lt;/p&gt;
&lt;p&gt;Exactly how to implement this integration is the subject of this article.&lt;/p&gt;
&lt;h2 id=&#34;integrating-the-equations-of-motion&#34;&gt;Integrating the Equations of Motion&lt;/h2&gt;
&lt;p&gt;You may remember from high school or university physics that force equals mass times acceleration.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    F = ma
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can switch this around to see that acceleration is force divided by mass. This makes intuitive sense because heavier objects are harder to throw.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    a = F/m
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Acceleration is the rate of change in velocity over time:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    dv/dt = a = F/m
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Similarly, velocity is the rate of change in position over time:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    dx/dt = v
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This means if we know the current position and velocity of an object, and the forces that will be applied to it, we can integrate to find its position and velocity at some point in the future.&lt;/p&gt;
&lt;h2 id=&#34;numerical-integration&#34;&gt;Numerical Integration&lt;/h2&gt;
&lt;p&gt;For those who have not formally studied differential equations at university, take heart for you are in almost as good a position as those who have. This is because we&amp;rsquo;re not going to analytically solve the differential equations as you would do in first year mathematics. Instead, we are going to &lt;strong&gt;numerically integrate&lt;/strong&gt; to find the solution.&lt;/p&gt;
&lt;p&gt;Here is how numerical integration works. First, start at an initial position and velocity, then take a small step forward to find the velocity and position at a future time. Then repeat this, moving forward in small time steps, using the result of the previous calculation as the starting point for the next.&lt;/p&gt;
&lt;p&gt;But how do we find the change in velocity and position at each step?&lt;/p&gt;
&lt;p&gt;The answer lies in the &lt;strong&gt;equations of motion&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s call our current time &lt;strong&gt;t&lt;/strong&gt;, and the time step &lt;strong&gt;dt&lt;/strong&gt; or &amp;lsquo;delta time&amp;rsquo;.&lt;/p&gt;
&lt;p&gt;We can now put the equations of motion in a form that anyone can understand:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    acceleration = force / mass
    change in position = velocity * dt
    change in velocity = acceleration * dt
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This makes intuitive sense because if you&amp;rsquo;re in a car traveling 60 kilometers per-hour, in one hour you&amp;rsquo;ll be 60 kilometers further down the road. Similarly, a car accelerating 10 kilometers per-hour-per-second will be moving 100 kilometers per-hour faster after 10 seconds.&lt;/p&gt;
&lt;p&gt;Of course this logic only holds when acceleration and velocity are constant. But even when they&amp;rsquo;re not, it&amp;rsquo;s still a pretty decent approximation to start with.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s put this into code. Starting with a stationary object at the origin weighing one kilogram, we apply a constant force of 10 newtons and step forward with time steps of one second:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    double t = 0.0;
    float dt = 1.0f;

    float velocity = 0.0f;
    float position = 0.0f;
    float force = 10.0f;
    float mass = 1.0f;

    while ( t &amp;lt;= 10.0 )
    {
        position = position + velocity * dt;
        velocity = velocity + ( force / mass ) * dt;
        t += dt;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is the result:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    t=0:    position = 0      velocity = 0
    t=1:    position = 0      velocity = 10
    t=2:    position = 10     velocity = 20
    t=3:    position = 30     velocity = 30
    t=4:    position = 60     velocity = 40
    t=5:    position = 100    velocity = 50
    t=6:    position = 150    velocity = 60
    t=7:    position = 210    velocity = 70
    t=8:    position = 280    velocity = 80
    t=9:    position = 360    velocity = 90
    t=10:   position = 450    velocity = 100
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, at at each step we know both the position and velocity of the object. This is numerical integration.&lt;/p&gt;
&lt;h2 id=&#34;explicit-euler&#34;&gt;Explicit Euler&lt;/h2&gt;
&lt;p&gt;What we just did is a type of integration called &lt;strong&gt;explicit euler&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;To save you future embarrassment, I must point out now that Euler is pronounced &amp;ldquo;Oiler&amp;rdquo; not &amp;ldquo;yew-ler&amp;rdquo; as it is the last name of the Swiss mathematician &lt;a href=&#34;https://en.wikipedia.org/wiki/Leonhard_Euler&#34;&gt;Leonhard Euler&lt;/a&gt; who first discovered this technique.&lt;/p&gt;
&lt;p&gt;Euler integration is the most basic numerical integration technique. It is only 100% accurate when the rate of change is constant over the timestep.&lt;/p&gt;
&lt;p&gt;Since acceleration is constant in the example above, the integration of velocity is without error. However, we are also integrating velocity to get position, and velocity is increasing due to acceleration. This means there is error in the integrated position.&lt;/p&gt;
&lt;p&gt;Just how large is this error? Let&amp;rsquo;s find out!&lt;/p&gt;
&lt;p&gt;There is a closed form solution for how an object moves under constant acceleration. We can use this to compare our numerically integrated position with the exact result:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    s = ut + 0.5at^2
    s = 0.0*t + 0.5at^2
    s = 0.5(10)(10^2)
    s = 0.5(10)(100)
    s = 500 meters
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After 10 seconds, the object should have moved 500 meters, but explicit euler gives a result of 450 meters. That&amp;rsquo;s 50 meters off after just 10 seconds!&lt;/p&gt;
&lt;p&gt;This sounds really, really bad, but it&amp;rsquo;s not common for games to step physics forward with such large time steps. In fact, physics usually steps forward at something closer to the display framerate.&lt;/p&gt;
&lt;p&gt;Stepping forward with &lt;strong&gt;dt&lt;/strong&gt; = 1/100 yields a much better result:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    t=9.90:     position = 489.552155     velocity = 98.999062
    t=9.91:     position = 490.542145     velocity = 99.099060
    t=9.92:     position = 491.533142     velocity = 99.199059
    t=9.93:     position = 492.525146     velocity = 99.299057
    t=9.94:     position = 493.518127     velocity = 99.399055
    t=9.95:     position = 494.512115     velocity = 99.499054
    t=9.96:     position = 495.507111     velocity = 99.599052
    t=9.97:     position = 496.503113     velocity = 99.699051
    t=9.98:     position = 497.500092     velocity = 99.799049
    t=9.99:     position = 498.498077     velocity = 99.899048
    t=10.00:    position = 499.497070     velocity = 99.999046
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see, this is a pretty good result. Certainly good enough for a game.&lt;/p&gt;
&lt;h2 id=&#34;why-explicit-euler-is-not-always-so-great&#34;&gt;Why explicit euler is not (always) so great&lt;/h2&gt;
&lt;p&gt;With a small enough timestep explicit euler gives decent results for constant acceleration, but what about the case where acceleration isn&amp;rsquo;t constant?&lt;/p&gt;
&lt;p&gt;A good example of non-constant acceleration is a &lt;a href=&#34;https://ccrma.stanford.edu/CCRMA/Courses/152/vibrating_systems.html&#34;&gt;spring damper system&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In this system a mass is attached to a spring and its motion is damped by some kind of friction. There is a force proportional to the distance of the object that pulls it towards the origin, and a force proportional to the velocity of the object, but in the opposite direction, which slows it down.&lt;/p&gt;
&lt;p&gt;Now the acceleration is definitely not constant throughout the timestep, but is a continously changing function that is a combination of the position and velocity, which are themselves changing continuously over the timestep.&lt;/p&gt;
&lt;p&gt;This is an example of a &lt;a href=&#34;https://en.wikipedia.org/wiki/Harmonic_oscillator#Damped_harmonic_oscillator&#34;&gt;damped harmonic oscillator&lt;/a&gt;. It&amp;rsquo;s a well studied problem and there&amp;rsquo;s a closed form solution that we can use to check our numerically integrated result.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s start with an underdamped system where the mass oscillates about the origin while slowing down.&lt;/p&gt;
&lt;p&gt;Here are the input parameters to the mass spring system:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Mass: 1 kilogram&lt;/li&gt;
&lt;li&gt;Initial position: 1000 meters from origin&lt;/li&gt;
&lt;li&gt;Hooke&amp;rsquo;s law spring coefficient: k = 15&lt;/li&gt;
&lt;li&gt;Hooke&amp;rsquo;s law damping coefficient: b = 0.1&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And here is a graph of the exact solution:&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/game-physics/integration_basics_damped_exact_solution.png&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;When we apply explicit euler to integrate this system, we get the following result, which has been scaled down vertically to fit:&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/game-physics/integration_basics_damped_explicit_euler.png&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;Instead of damping and converging on the origin, it gains energy over time!&lt;/p&gt;
&lt;p&gt;This system is unstable when integrated with explicit euler and &lt;strong&gt;dt&lt;/strong&gt;=1/100.&lt;/p&gt;
&lt;p&gt;Unfortunately, since we&amp;rsquo;re already integrating with a small timestep, we don&amp;rsquo;t have a lot of practical options to improve the accuracy. Even if you reduce the timestep, there&amp;rsquo;s always a spring tightness k above which you&amp;rsquo;ll see this behavior.&lt;/p&gt;
&lt;h2 id=&#34;semi-implicit-euler&#34;&gt;Semi-implicit Euler&lt;/h2&gt;
&lt;p&gt;Another integrator to consider is &lt;a href=&#34;https://en.wikipedia.org/wiki/Semi-implicit_Euler_method&#34;&gt;semi-implicit euler&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Most commercial game physics engines use this integrator.&lt;/p&gt;
&lt;p&gt;Switching from explicit to semi-implicit euler is as simple as changing:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    position += velocity * dt;
    velocity += acceleration * dt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;to:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    velocity += acceleration * dt;
    position += velocity * dt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Applying the semi-implicit euler integrator with &lt;strong&gt;dt&lt;/strong&gt; = 1/100 to the spring damper system gives a stable result that is very close to the exact solution:&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/game-physics/integration_basics_damped_semi_implicit_euler.png&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;Even though semi-implicit euler has the same order of accuracy as explicit euler (order 1), we get a much better result when integrating the equations of motion because it is &lt;a href=&#34;https://en.wikipedia.org/wiki/Symplectic_integrator&#34;&gt;symplectic&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;many-different-integration-methods-exist&#34;&gt;Many different integration methods exist&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://web.mit.edu/10.001/Web/Course_Notes/Differential_Equations_Notes/node3.html&#34;&gt;Implicit euler&lt;/a&gt; is an integration technique that is well suited for simulating stiff equations that become unstable with other methods. The drawback is that it requires solving a system of equations per-timestep.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Verlet_integration&#34;&gt;Verlet integration&lt;/a&gt; provides greater accuracy than implicit euler and less memory usage when simulating a large number of particles is. This is a second order integrator which is also symplectic.&lt;/p&gt;
&lt;p&gt;There are a whole family of integrators called the &lt;strong&gt;Runge-Kutta methods&lt;/strong&gt;. Explicit euler is part of this family, but it also includes higher order integrators, the most classic of these being the Runge Kutta order 4 or simply &lt;strong&gt;RK4&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;This Runge Kutta family of integrators is named for the German physicists who discovered them: &lt;a href=&#34;https://en.wikipedia.org/wiki/Carl_David_Tolm%C3%A9_Runge&#34;&gt;Carl Runge&lt;/a&gt; and &lt;a href=&#34;https://en.wikipedia.org/wiki/Martin_Wilhelm_Kutta&#34;&gt;Martin Kutta&lt;/a&gt;. This means the &amp;lsquo;g&amp;rsquo; is hard and the &amp;lsquo;u&amp;rsquo; is a short &amp;lsquo;oo&amp;rsquo; sound. I am sorry to inform but this means we are talking about the &lt;em&gt;&amp;lsquo;roon-geh koo-ta&amp;rsquo;&lt;/em&gt; methods and not a &lt;em&gt;&amp;lsquo;runge cutter&amp;rsquo;&lt;/em&gt;, whatever that is :)&lt;/p&gt;
&lt;p&gt;The RK4 is a fourth order integrator, which means its accumulated error is on the order of the fourth derivative. This makes it very accurate. Much more accurate than explicit and implicit euler which are only first order.&lt;/p&gt;
&lt;p&gt;But although it&amp;rsquo;s more accurate, that&amp;rsquo;s not to say RK4 is automatically &amp;ldquo;the best&amp;rdquo; integrator, or that it is better than semi-implicit euler. It&amp;rsquo;s much more complicated than this.&lt;/p&gt;
&lt;p&gt;Regardless, it&amp;rsquo;s an interesting integrator and is well worth studying.&lt;/p&gt;
&lt;h2 id=&#34;implementing-rk4&#34;&gt;Implementing RK4&lt;/h2&gt;
&lt;p&gt;There are many great explanations of the mathematics behind RK4 already. For example: &lt;a href=&#34;https://en.wikipedia.org/wiki/Runge%E2%80%93Kutta_methods&#34;&gt;here&lt;/a&gt;, &lt;a href=&#34;http://web.mit.edu/10.001/Web/Course_Notes/Differential_Equations_Notes/node5.html&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://www.researchgate.net/publication/49587610_A_Simplified_Derivation_and_Analysis_of_Fourth_Order_Runge_Kutta_Method&#34;&gt;here&lt;/a&gt;. I highly encourage you to follow the derivation and understand how and why it works at a mathematical level. But, seeing as the target audience for this article are programmers, not mathematicians, we&amp;rsquo;re all about implementation, so let&amp;rsquo;s get started.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s define the state of an object as a struct in C++ so we have both position and velocity stored conveniently in one place:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    struct State
    {
        float x;      // position
        float v;      // velocity
    };
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We also need a struct to store the derivatives of the state values:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    struct Derivative
    {
        float dx;      // dx/dt = velocity
        float dv;      // dv/dt = acceleration
    };
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next we need a function to advance the physics state ahead from t to t+dt using one set of derivatives, and once there, recalculate the derivatives at this new state:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    Derivative evaluate( const State &amp;amp; initial, 
                         double t, 
                         float dt, 
                         const Derivative &amp;amp; d )
    {
        State state;
        state.x = initial.x + d.dx*dt;
        state.v = initial.v + d.dv*dt;

        Derivative output;
        output.dx = state.v;
        output.dv = acceleration( state, t+dt );
        return output;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The acceleration function is what drives the entire simulation. Let&amp;rsquo;s set it to the spring damper system and return the acceleration assuming unit mass:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    float acceleration( const State &amp;amp; state, double t )
    {
        const float k = 15.0f;
        const float b = 0.1f;
        return -k * state.x - b * state.v;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we get to the RK4 integration routine itself:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    void integrate( State &amp;amp; state, 
                    double t, 
                    float dt )
    {
        Derivative a,b,c,d;

        a = evaluate( state, t, 0.0f, Derivative() );
        b = evaluate( state, t, dt*0.5f, a );
        c = evaluate( state, t, dt*0.5f, b );
        d = evaluate( state, t, dt, c );

        float dxdt = 1.0f / 6.0f * 
            ( a.dx + 2.0f * ( b.dx + c.dx ) + d.dx );
        
        float dvdt = 1.0f / 6.0f * 
            ( a.dv + 2.0f * ( b.dv + c.dv ) + d.dv );

        state.x = state.x + dxdt * dt;
        state.v = state.v + dvdt * dt;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The RK4 integrator samples the derivative at four points to detect curvative. Notice how derivative a is used when calculating b, b is used when calculating c, and c into d. This feedback of the current derivative into the calculation of the next is what gives the RK4 integrator its accuracy.&lt;/p&gt;
&lt;p&gt;Importantly, each of these derivatives a,b,c and d will be &lt;em&gt;different&lt;/em&gt; when the rate of change in these quantities is a function of time or a function of the state itself. For example, in our spring damper system acceleration is a function of the current position and velocity which change throughout the timestep.&lt;/p&gt;
&lt;p&gt;Once the four derivatives have been evaluated, the best overall derivative is calculated as a weighted sum derived from the &lt;a href=&#34;https://en.wikipedia.org/wiki/Taylor_series&#34;&gt;taylor series&lt;/a&gt; expansion. This combined derivative is used to advance the position and velocity forward, just as we did with the explicit euler integrator.&lt;/p&gt;
&lt;h2 id=&#34;semi-implicit-euler-vs-rk4&#34;&gt;Semi-implicit euler vs. RK4&lt;/h2&gt;
&lt;p&gt;Now let&amp;rsquo;s put the RK4 integrator to the test.&lt;/p&gt;
&lt;p&gt;Since it is a higher order integrator (4th order vs. 1st order) it will be visibly more accurate than semi-implicit euler, right?&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/game-physics/integration_basics_damped_rk4_vs_semi_implicit_euler.png&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;&lt;strong&gt;Wrong&lt;/strong&gt;. Both integrators are so close to the exact result that it&amp;rsquo;s impossible to make out any difference at this scale. Both integrators are stable and track the exact solution very well with &lt;strong&gt;dt&lt;/strong&gt;=1/100.&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/game-physics/integration_basics_damped_rk4_vs_semi_implicit_euler_zoomed_in.png&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;Zooming in confirms that RK4 &lt;em&gt;is&lt;/em&gt; more accurate than semi-implicit euler, but is it really worth the complexity and extra runtime cost of RK4? It&amp;rsquo;s hard to say.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s push a bit harder and see if we can find a significant difference between the two integrators. Unfortunately, we can&amp;rsquo;t look at this system for long periods of time because it quickly damps down to zero, so let&amp;rsquo;s switch to a &lt;a href=&#34;https://en.wikipedia.org/wiki/Harmonic_oscillator#Simple_harmonic_oscillator&#34;&gt;simple harmonic oscillator&lt;/a&gt; which oscillates forever without any damping.&lt;/p&gt;
&lt;p&gt;Here&amp;rsquo;s the exact result we&amp;rsquo;re aiming for:&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/game-physics/integration_basics_undamped_exact_solution.png&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;To make it harder on the integrators, let&amp;rsquo;s increase delta time to 0.1 seconds.&lt;/p&gt;
&lt;p&gt;Next, we let the integrators run for 90 seconds and zoom in:&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/game-physics/integration_basics_undamped_rk4_vs_semi_implicit_euler.png&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;After 90 seconds the semi-implicit euler solution (orange) has drifted out of phase with the exact solution because it has a slightly different frequency, while the green line of RK4 matches the frequency, but is losing energy!&lt;/p&gt;
&lt;p&gt;We can see this more clearly by increasing the time step to 0.25 seconds.&lt;/p&gt;
&lt;p&gt;RK4 maintains the correct frequency but loses energy:&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/game-physics/integration_basics_undamped_rk4_5fps.png&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;While semi-implicit euler does a better job at conserving energy, on average:&lt;/p&gt;
&lt;img src=&#34;https://gafferongames.com/img/game-physics/integration_basics_undamped_semi_implicit_euler_5fps.png&#34; width=&#34;100%&#34;/&gt;
&lt;p&gt;But drifts out of phase. What an interesting result! As you can see it&amp;rsquo;s not simply the case that RK4 has a higher order of accuracy and is &amp;ldquo;better&amp;rdquo;. It&amp;rsquo;s much, much more nuanced than this.&lt;/p&gt;
&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Which integrator should you use in your game?&lt;/p&gt;
&lt;p&gt;My recommendation is &lt;strong&gt;semi-implicit euler&lt;/strong&gt;. It&amp;rsquo;s cheap and easy to implement, it&amp;rsquo;s much more stable than explicit euler, and it tends to preserve energy on average even when pushed near its limit.&lt;/p&gt;
&lt;p&gt;If you really do need more accuracy than semi-implicit euler, I recommend you look into higher order &lt;a href=&#34;https://en.wikipedia.org/wiki/Symplectic_integrator&#34;&gt;symplectic integrators&lt;/a&gt; designed for &lt;a href=&#34;https://en.wikipedia.org/wiki/Hamiltonian_system&#34;&gt;hamiltonian systems&lt;/a&gt;. This way you&amp;rsquo;ll discover more modern higher order integration techniques that are better suited to your simulation than RK4.&lt;/p&gt;
&lt;p&gt;And finally, if you are still doing this in your game:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    position += velocity * dt;
    velocity += acceleration * dt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Please take a moment to change it to this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    velocity += acceleration * dt;
    position += velocity * dt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You&amp;rsquo;ll be glad you did :)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;NEXT ARTICLE:&lt;/strong&gt; &lt;a href=&#34;https://gafferongames.com/post/fix_your_timestep/&#34;&gt;Fix Your Timestep!&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;Glenn Fiedler&lt;/strong&gt; is the founder and CEO of &lt;strong&gt;&lt;a href=&#34;https://networknext.com&#34;&gt;Network Next&lt;/a&gt;&lt;/strong&gt;.&lt;br&gt;&lt;i&gt;Network Next is fixing the internet for games by creating a marketplace for premium network transit.&lt;/i&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
